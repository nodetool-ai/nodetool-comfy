{
  "name": "nodetool-comfy",
  "description": "ComfyUI nodes for Nodetool",
  "version": "0.6.0",
  "authors": [
    "Matthias Georgi <matti.georgi@gmail.com>"
  ],
  "nodes": [
    {
      "title": "Empty Image",
      "description": "Generates an empty image.",
      "namespace": "comfy.generate",
      "node_type": "comfy.generate.EmptyImage",
      "layout": "default",
      "properties": [
        {
          "name": "width",
          "type": {
            "type": "int"
          },
          "default": 512,
          "title": "Width",
          "description": "The width of the empty image."
        },
        {
          "name": "height",
          "type": {
            "type": "int"
          },
          "default": 512,
          "title": "Height",
          "description": "The height of the empty image."
        },
        {
          "name": "batch_size",
          "type": {
            "type": "int"
          },
          "default": 1,
          "title": "Batch Size",
          "description": "The batch size for the empty images."
        },
        {
          "name": "color",
          "type": {
            "type": "int"
          },
          "default": 0,
          "title": "Color",
          "description": "The default color for the image, represented as an integer."
        }
      ],
      "outputs": [],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "width",
        "height",
        "batch_size",
        "color"
      ],
      "is_dynamic": false
    },
    {
      "title": "Comfy",
      "description": "A comfy node wraps around a comfy class and delegates processing to the actual\n    implementation. The comfy class is defined in the class variable _comfy_class.\n\n    Attributes:\n        _comfy_class (type): The comfy class wrapped by this node.",
      "namespace": "comfy.comfy_node",
      "node_type": "comfy.comfy_node.Comfy",
      "layout": "default",
      "properties": [],
      "outputs": [],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [],
      "is_dynamic": false
    },
    {
      "title": "IPAdapter Apply",
      "description": "The IPAdapter Apply node can be used to apply an IPAdapter to a model.",
      "namespace": "comfy.ipadapter",
      "node_type": "comfy.ipadapter.IPAdapterApply",
      "layout": "default",
      "properties": [
        {
          "name": "ipadapter",
          "type": {
            "type": "comfy.ip_adapter"
          },
          "default": {},
          "title": "Ipadapter",
          "description": "The IPAdapter to apply."
        },
        {
          "name": "clip_vision",
          "type": {
            "type": "comfy.clip_vision"
          },
          "default": {},
          "title": "Clip Vision",
          "description": "The CLIP vision to use."
        },
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {},
          "title": "Image",
          "description": "The image to use."
        },
        {
          "name": "model",
          "type": {
            "type": "comfy.unet"
          },
          "default": {},
          "title": "Model",
          "description": "The model to apply the IPAdapter to."
        },
        {
          "name": "weight",
          "type": {
            "type": "float"
          },
          "default": 1.0,
          "title": "Weight",
          "description": "The weight of the application."
        },
        {
          "name": "noise",
          "type": {
            "type": "float"
          },
          "default": 0.0,
          "title": "Noise",
          "description": "The amount of noise to apply."
        },
        {
          "name": "weight_type",
          "type": {
            "type": "enum",
            "values": [
              "original",
              "linear",
              "channel penalty"
            ],
            "type_name": "nodetool.nodes.comfy.ipadapter.WeightTypeEnum"
          },
          "default": "original",
          "title": "Weight Type",
          "description": "The type of weight to apply."
        },
        {
          "name": "start_at",
          "type": {
            "type": "float"
          },
          "default": 0.0,
          "title": "Start At",
          "description": "The starting point for applying the IPAdapter."
        },
        {
          "name": "end_at",
          "type": {
            "type": "float"
          },
          "default": 1.0,
          "title": "End At",
          "description": "The ending point for applying the IPAdapter."
        },
        {
          "name": "unfold_batch",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Unfold Batch",
          "description": "Whether to unfold the batch during the application."
        },
        {
          "name": "attn_mask",
          "type": {
            "type": "union",
            "type_args": [
              {
                "type": "comfy.mask"
              },
              {
                "type": "none"
              }
            ]
          },
          "title": "Attn Mask",
          "description": "The optional attention mask to use (if any)."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "comfy.unet"
          },
          "name": "unet"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "ipadapter",
        "clip_vision",
        "image",
        "model",
        "weight",
        "noise",
        "weight_type",
        "start_at",
        "end_at",
        "unfold_batch",
        "attn_mask"
      ],
      "is_dynamic": false
    },
    {
      "title": "IPAdapter Apply Encoded",
      "description": "The IPAdapter Apply Encoded node can be used to apply an encoded IPAdapter to a model.",
      "namespace": "comfy.ipadapter",
      "node_type": "comfy.ipadapter.IPAdapterApplyEncoded",
      "layout": "default",
      "properties": [
        {
          "name": "ipadapter",
          "type": {
            "type": "comfy.ip_adapter"
          },
          "default": {},
          "title": "Ipadapter",
          "description": "The IPAdapter to apply."
        },
        {
          "name": "clip_vision",
          "type": {
            "type": "comfy.clip_vision"
          },
          "default": {},
          "title": "Clip Vision",
          "description": "The CLIP vision to use."
        },
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {},
          "title": "Image",
          "description": "The image to use."
        },
        {
          "name": "model",
          "type": {
            "type": "comfy.unet"
          },
          "default": {},
          "title": "Model",
          "description": "The model to apply the IPAdapter to."
        },
        {
          "name": "weight",
          "type": {
            "type": "float"
          },
          "default": 1.0,
          "title": "Weight",
          "description": "The weight of the application."
        },
        {
          "name": "noise",
          "type": {
            "type": "float"
          },
          "default": 0.0,
          "title": "Noise",
          "description": "The amount of noise to apply."
        },
        {
          "name": "weight_type",
          "type": {
            "type": "enum",
            "values": [
              "original",
              "linear",
              "channel penalty"
            ],
            "type_name": "nodetool.nodes.comfy.ipadapter.WeightTypeEnum"
          },
          "default": "original",
          "title": "Weight Type",
          "description": "The type of weight to apply."
        },
        {
          "name": "start_at",
          "type": {
            "type": "float"
          },
          "default": 0.0,
          "title": "Start At",
          "description": "The starting point for applying the IPAdapter."
        },
        {
          "name": "end_at",
          "type": {
            "type": "float"
          },
          "default": 1.0,
          "title": "End At",
          "description": "The ending point for applying the IPAdapter."
        },
        {
          "name": "unfold_batch",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Unfold Batch",
          "description": "Whether to unfold the batch during the application."
        },
        {
          "name": "attn_mask",
          "type": {
            "type": "union",
            "type_args": [
              {
                "type": "comfy.mask"
              },
              {
                "type": "none"
              }
            ]
          },
          "title": "Attn Mask",
          "description": "The optional attention mask to use (if any)."
        },
        {
          "name": "embeds",
          "type": {
            "type": "comfy.embeds"
          },
          "default": {},
          "title": "Embeds",
          "description": "The encoded embeddings to apply."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "comfy.unet"
          },
          "name": "unet"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "ipadapter",
        "clip_vision",
        "image",
        "model",
        "weight",
        "noise",
        "weight_type",
        "start_at",
        "end_at",
        "unfold_batch",
        "attn_mask",
        "embeds"
      ],
      "is_dynamic": false
    },
    {
      "title": "IPAdapter Batch Embeds",
      "description": "The IPAdapter Batch Embeds node can be used to batch two sets of embeddings.",
      "namespace": "comfy.ipadapter",
      "node_type": "comfy.ipadapter.IPAdapterBatchEmbeds",
      "layout": "default",
      "properties": [
        {
          "name": "embed1",
          "type": {
            "type": "comfy.embeds"
          },
          "default": {},
          "title": "Embed1",
          "description": "The first set of embeddings."
        },
        {
          "name": "embed2",
          "type": {
            "type": "comfy.embeds"
          },
          "default": {},
          "title": "Embed2",
          "description": "The second set of embeddings."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "comfy.embeds"
          },
          "name": "embeds"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "embed1",
        "embed2"
      ],
      "is_dynamic": false
    },
    {
      "title": "IPAdapter Encoder",
      "description": "The IPAdapter Encoder node can be used to encode an image into an embedding that can be used to guide the diffusion model towards generating specific images.",
      "namespace": "comfy.ipadapter",
      "node_type": "comfy.ipadapter.IPAdapterEncoder",
      "layout": "default",
      "properties": [
        {
          "name": "clip_vision",
          "type": {
            "type": "comfy.clip_vision"
          },
          "default": {},
          "title": "Clip Vision",
          "description": "The CLIP vision to use."
        },
        {
          "name": "image_1",
          "type": {
            "type": "image"
          },
          "default": {},
          "title": "Image 1",
          "description": "The first image to encode."
        },
        {
          "name": "ipadapter_plus",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Ipadapter Plus",
          "description": "Whether to use IPAdapter+ enhancements."
        },
        {
          "name": "noise",
          "type": {
            "type": "float"
          },
          "default": 0.0,
          "title": "Noise",
          "description": "The amount of noise to apply."
        },
        {
          "name": "weight_1",
          "type": {
            "type": "float"
          },
          "default": 1.0,
          "title": "Weight 1",
          "description": "The weight for the first image."
        },
        {
          "name": "image_2",
          "type": {
            "type": "union",
            "type_args": [
              {
                "type": "image"
              },
              {
                "type": "none"
              }
            ]
          },
          "title": "Image 2",
          "description": "The second image to encode (optional)."
        },
        {
          "name": "image_3",
          "type": {
            "type": "union",
            "type_args": [
              {
                "type": "image"
              },
              {
                "type": "none"
              }
            ]
          },
          "title": "Image 3",
          "description": "The third image to encode (optional)."
        },
        {
          "name": "image_4",
          "type": {
            "type": "union",
            "type_args": [
              {
                "type": "image"
              },
              {
                "type": "none"
              }
            ]
          },
          "title": "Image 4",
          "description": "The fourth image to encode (optional)."
        },
        {
          "name": "weight_2",
          "type": {
            "type": "float"
          },
          "default": 1.0,
          "title": "Weight 2",
          "description": "The weight for the second image (optional)."
        },
        {
          "name": "weight_3",
          "type": {
            "type": "float"
          },
          "default": 1.0,
          "title": "Weight 3",
          "description": "The weight for the third image (optional)."
        },
        {
          "name": "weight_4",
          "type": {
            "type": "float"
          },
          "default": 1.0,
          "title": "Weight 4",
          "description": "The weight for the fourth image (optional)."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "comfy.embeds"
          },
          "name": "embeds"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "clip_vision",
        "image_1",
        "ipadapter_plus",
        "noise",
        "weight_1",
        "image_2",
        "image_3",
        "image_4",
        "weight_2",
        "weight_3",
        "weight_4"
      ],
      "is_dynamic": false
    },
    {
      "title": "IPAdapter Save Embeds",
      "description": "The IPAdapter Save Embeds node can be used to save an embedding to a file.",
      "namespace": "comfy.ipadapter",
      "node_type": "comfy.ipadapter.IPAdapterSaveEmbeds",
      "layout": "default",
      "properties": [
        {
          "name": "embeds",
          "type": {
            "type": "comfy.embeds"
          },
          "default": {},
          "title": "Embeds",
          "description": "The embeddings to save."
        },
        {
          "name": "filename_prefix",
          "type": {
            "type": "str"
          },
          "default": "embeds/IPAdapter",
          "title": "Filename Prefix",
          "description": "The prefix for the filename to save the embeddings."
        }
      ],
      "outputs": [],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "embeds",
        "filename_prefix"
      ],
      "is_dynamic": false
    },
    {
      "title": "Prep Image For Clip Vision",
      "description": "The Prep Image For Clip Vision node can be used to prepare an image for use with a CLIPVision model.",
      "namespace": "comfy.ipadapter",
      "node_type": "comfy.ipadapter.PrepImageForClipVision",
      "layout": "default",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {},
          "title": "Image",
          "description": "The image to prepare."
        },
        {
          "name": "interpolation",
          "type": {
            "type": "enum",
            "values": [
              "LANCZOS",
              "BICUBIC",
              "HAMMING",
              "BILINEAR",
              "BOX",
              "NEAREST"
            ],
            "type_name": "nodetool.nodes.comfy.ipadapter.InterpolationMethod"
          },
          "default": "LANCZOS",
          "title": "Interpolation",
          "description": "The interpolation method to use."
        },
        {
          "name": "crop_position",
          "type": {
            "type": "enum",
            "values": [
              "top",
              "bottom",
              "left",
              "right",
              "center",
              "pad"
            ],
            "type_name": "nodetool.nodes.comfy.ipadapter.CropPosition"
          },
          "default": "center",
          "title": "Crop Position",
          "description": "The crop position to use."
        },
        {
          "name": "sharpening",
          "type": {
            "type": "float"
          },
          "default": 0.0,
          "title": "Sharpening",
          "description": "The amount of sharpening to apply."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "image"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "image",
        "interpolation",
        "crop_position",
        "sharpening"
      ],
      "is_dynamic": false
    },
    {
      "title": "Load CLIP",
      "description": "Loads a CLIP model.",
      "namespace": "comfy.loaders",
      "node_type": "comfy.loaders.CLIPLoader",
      "layout": "default",
      "properties": [
        {
          "name": "clip_name",
          "type": {
            "type": "comfy.clip_file"
          },
          "default": {},
          "title": "Clip Name",
          "description": "The name of the CLIP to load."
        },
        {
          "name": "type",
          "type": {
            "type": "enum",
            "values": [
              "stable_diffusion",
              "stable_cascade",
              "sd3",
              "stable_audio",
              "mochi",
              "ltxv"
            ],
            "type_name": "nodetool.nodes.comfy.loaders.CLIPTypeEnum"
          },
          "default": "stable_diffusion",
          "title": "Type",
          "description": "The type of the CLIP model to load."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "comfy.clip"
          },
          "name": "clip"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "clip_name",
        "type"
      ],
      "is_dynamic": false
    },
    {
      "title": "CLIPVision Loader",
      "description": "Loads a CLIPVision model.",
      "namespace": "comfy.loaders",
      "node_type": "comfy.loaders.CLIPVisionLoader",
      "layout": "default",
      "properties": [
        {
          "name": "clip_name",
          "type": {
            "type": "comfy.clip_vision_file"
          },
          "default": {},
          "title": "Clip Name",
          "description": "The name of the CLIP vision model to load."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "comfy.clip_vision"
          },
          "name": "clip_vision"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "clip_name"
      ],
      "is_dynamic": false
    },
    {
      "title": "Load Checkpoint (Advanced)",
      "description": "Loads a checkpoint.",
      "namespace": "comfy.loaders",
      "node_type": "comfy.loaders.CheckpointLoader",
      "layout": "default",
      "properties": [
        {
          "name": "ckpt_name",
          "type": {
            "type": "comfy.checkpoint_file"
          },
          "default": {},
          "title": "Ckpt Name",
          "description": "The checkpoint to load."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "comfy.unet"
          },
          "name": "model"
        },
        {
          "type": {
            "type": "comfy.clip"
          },
          "name": "clip"
        },
        {
          "type": {
            "type": "comfy.vae"
          },
          "name": "vae"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "ckpt_name"
      ],
      "is_dynamic": false
    },
    {
      "title": "Load Checkpoint",
      "description": "Loads a checkpoint.",
      "namespace": "comfy.loaders",
      "node_type": "comfy.loaders.CheckpointLoaderSimple",
      "layout": "default",
      "properties": [
        {
          "name": "ckpt_name",
          "type": {
            "type": "comfy.checkpoint_file"
          },
          "default": {},
          "title": "Ckpt Name",
          "description": "The checkpoint to load."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "comfy.unet"
          },
          "name": "model"
        },
        {
          "type": {
            "type": "comfy.clip"
          },
          "name": "clip"
        },
        {
          "type": {
            "type": "comfy.vae"
          },
          "name": "vae"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "ckpt_name"
      ],
      "is_dynamic": false
    },
    {
      "title": "Load ControlNet Model",
      "description": "Loads a ControlNet model.",
      "namespace": "comfy.loaders",
      "node_type": "comfy.loaders.ControlNetLoader",
      "layout": "default",
      "properties": [
        {
          "name": "control_net_name",
          "type": {
            "type": "comfy.control_net_file"
          },
          "default": {},
          "title": "Control Net Name",
          "description": "The filename of the control net to load."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "comfy.control_net"
          },
          "name": "control_net"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "control_net_name"
      ],
      "is_dynamic": false
    },
    {
      "title": "Load Dual CLIP",
      "description": "Loads a dual CLIP model.",
      "namespace": "comfy.loaders",
      "node_type": "comfy.loaders.DualCLIPLoader",
      "layout": "default",
      "properties": [
        {
          "name": "clip_name1",
          "type": {
            "type": "comfy.clip_file"
          },
          "default": {},
          "title": "Clip Name1",
          "description": "The name of the CLIP to load."
        },
        {
          "name": "clip_name2",
          "type": {
            "type": "comfy.clip_file"
          },
          "default": {},
          "title": "Clip Name2",
          "description": "The name of the CLIP to load."
        },
        {
          "name": "type",
          "type": {
            "type": "enum",
            "values": [
              "sdxl",
              "sd3",
              "flux"
            ],
            "type_name": "nodetool.nodes.comfy.loaders.DualCLIPEnum"
          },
          "default": "sdxl",
          "title": "Type",
          "description": "The type of the dual CLIP model to load."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "comfy.clip"
          },
          "name": "clip"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "clip_name1",
        "clip_name2",
        "type"
      ],
      "is_dynamic": false
    },
    {
      "title": "Load GLIGEN Model",
      "description": "Loads a GLIGEN model.",
      "namespace": "comfy.loaders",
      "node_type": "comfy.loaders.GLIGENLoader",
      "layout": "default",
      "properties": [
        {
          "name": "gligen_name",
          "type": {
            "type": "comfy.gligen_file"
          },
          "default": {},
          "title": "Gligen Name",
          "description": "The GLIGEN checkpoint to load."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "comfy.gligen"
          },
          "name": "gligen"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "gligen_name"
      ],
      "is_dynamic": false
    },
    {
      "title": "Load CLIP from Huggingface",
      "description": "Loads a CLIP model from Huggingface.",
      "namespace": "comfy.loaders",
      "node_type": "comfy.loaders.HuggingFaceCLIPLoader",
      "layout": "default",
      "properties": [
        {
          "name": "model",
          "type": {
            "type": "hf.clip"
          },
          "default": {},
          "title": "Model",
          "description": "The CLIP model to load."
        },
        {
          "name": "type",
          "type": {
            "type": "enum",
            "values": [
              "stable_diffusion",
              "stable_cascade",
              "sd3",
              "stable_audio",
              "mochi",
              "ltxv"
            ],
            "type_name": "nodetool.nodes.comfy.loaders.CLIPTypeEnum"
          },
          "default": "stable_diffusion",
          "title": "Type",
          "description": "The type of the CLIP model to load."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "comfy.clip"
          },
          "name": "clip"
        }
      ],
      "the_model_info": {},
      "recommended_models": [
        {
          "type": "hf.clip",
          "repo_id": "Comfy-Org/mochi_preview_repackaged",
          "path": "split_files/text_encoders/t5xxl_fp16.safetensors"
        },
        {
          "type": "hf.clip",
          "repo_id": "Comfy-Org/mochi_preview_repackaged",
          "path": "split_files/text_encoders/t5xxl_fp8_e4m3fn_scaled.safetensors"
        },
        {
          "type": "hf.clip",
          "repo_id": "comfyanonymous/flux_text_encoders",
          "path": "clip_l.safetensors"
        },
        {
          "type": "hf.clip",
          "repo_id": "comfyanonymous/flux_text_encoders",
          "path": "t5xxl_fp16.safetensors"
        }
      ],
      "basic_fields": [
        "model",
        "type"
      ],
      "is_dynamic": false
    },
    {
      "title": "Load CLIP Vision from Huggingface",
      "description": "Loads a CLIPVision model from Huggingface.",
      "namespace": "comfy.loaders",
      "node_type": "comfy.loaders.HuggingFaceCLIPVisionLoader",
      "layout": "default",
      "properties": [
        {
          "name": "model",
          "type": {
            "type": "hf.clip_vision"
          },
          "default": {},
          "title": "Model",
          "description": "The CLIP vision model to load."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "comfy.clip_vision"
          },
          "name": "clip_vision"
        }
      ],
      "the_model_info": {},
      "recommended_models": [
        {
          "type": "hf.clip_vision",
          "repo_id": "Comfy-Org/sigclip_vision_384",
          "path": "sigclip_vision_patch14_384.safetensors"
        },
        {
          "type": "hf.clip_vision",
          "repo_id": "h94/IP-Adapter",
          "path": "models/image_encoder/model.safetensors"
        },
        {
          "type": "hf.clip_vision",
          "repo_id": "h94/IP-Adapter",
          "path": "sdxl_models/image_encoder/model.safetensors"
        }
      ],
      "basic_fields": [
        "model"
      ],
      "is_dynamic": false
    },
    {
      "title": "Load Checkpoint from Huggingface",
      "description": "Loads a checkpoint from Huggingface.",
      "namespace": "comfy.loaders",
      "node_type": "comfy.loaders.HuggingFaceCheckpointLoader",
      "layout": "default",
      "properties": [
        {
          "name": "model",
          "type": {
            "type": "hf.checkpoint_model"
          },
          "default": {},
          "title": "Model",
          "description": "The Stable Diffusion model to load."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "comfy.unet"
          },
          "name": "model"
        },
        {
          "type": {
            "type": "comfy.clip"
          },
          "name": "clip"
        },
        {
          "type": {
            "type": "comfy.vae"
          },
          "name": "vae"
        }
      ],
      "the_model_info": {},
      "recommended_models": [
        {
          "type": "hf.stable_diffusion",
          "repo_id": "SG161222/Realistic_Vision_V5.1_noVAE",
          "path": "Realistic_Vision_V5.1_fp16-no-ema.safetensors"
        },
        {
          "type": "hf.stable_diffusion",
          "repo_id": "digiplay/majicMIX_realistic_v7",
          "path": "majicmixRealistic_v7.safetensors"
        },
        {
          "type": "hf.stable_diffusion",
          "repo_id": "philz1337x/epicrealism",
          "path": "epicrealism_naturalSinRC1VAE.safetensors"
        },
        {
          "type": "hf.stable_diffusion",
          "repo_id": "Lykon/DreamShaper",
          "path": "DreamShaper_5_beta2_noVae_half_pruned.safetensors"
        },
        {
          "type": "hf.stable_diffusion",
          "repo_id": "Lykon/DreamShaper",
          "path": "DreamShaper_4BakedVae_fp16.safetensors"
        },
        {
          "type": "hf.stable_diffusion",
          "repo_id": "XpucT/Deliberate",
          "path": "Deliberate_v6.safetensors"
        },
        {
          "type": "hf.stable_diffusion",
          "repo_id": "XpucT/Deliberate",
          "path": "Deliberate_v6-inpainting.safetensors"
        },
        {
          "type": "hf.stable_diffusion",
          "repo_id": "Lykon/AbsoluteReality",
          "path": "AbsoluteReality_1.8.1_pruned.safetensors"
        },
        {
          "type": "hf.stable_diffusion",
          "repo_id": "Lykon/AbsoluteReality",
          "path": "AbsoluteReality_1.8.1_INPAINTING.inpainting.safetensors"
        },
        {
          "type": "hf.stable_diffusion",
          "repo_id": "gsdf/Counterfeit-V2.5",
          "path": "Counterfeit-V2.5_fp16.safetensors"
        },
        {
          "type": "hf.stable_diffusion_xl",
          "repo_id": "stabilityai/stable-diffusion-xl-base-1.0",
          "path": "sd_xl_base_1.0.safetensors"
        },
        {
          "type": "hf.stable_diffusion_xl",
          "repo_id": "stabilityai/stable-diffusion-xl-refiner-1.0",
          "path": "sd_xl_refiner_1.0.safetensors"
        },
        {
          "type": "hf.stable_diffusion_xl",
          "repo_id": "playgroundai/playground-v2.5-1024px-aesthetic",
          "path": "playground-v2.5-1024px-aesthetic.fp16.safetensors"
        },
        {
          "type": "hf.stable_diffusion_xl",
          "repo_id": "RunDiffusion/Juggernaut-XL-v9",
          "path": "Juggernaut-XL_v9_RunDiffusionPhoto_v2.safetensors"
        },
        {
          "type": "hf.stable_diffusion_xl",
          "repo_id": "dataautogpt3/ProteusV0.5",
          "path": "proteusV0.5.safetensors"
        },
        {
          "type": "hf.stable_diffusion_xl",
          "repo_id": "Lykon/dreamshaper-xl-lightning",
          "path": "DreamShaperXL_Lightning.safetensors"
        },
        {
          "type": "hf.stable_diffusion_xl",
          "repo_id": "Lykon/AAM_XL_AnimeMix",
          "path": "AAM_XL_Anime_Mix.safetensors"
        },
        {
          "type": "hf.stable_diffusion_xl",
          "repo_id": "stabilityai/sdxl-turbo",
          "path": "sd_xl_turbo_1.0_fp16.safetensors"
        },
        {
          "type": "hf.stable_diffusion_xl",
          "repo_id": "Lykon/dreamshaper-xl-v2-turbo",
          "path": "DreamShaperXL_Turbo_v2_1.safetensors"
        },
        {
          "type": "hf.stable_diffusion_3",
          "repo_id": "Comfy-Org/stable-diffusion-3.5-fp8",
          "path": "sd3.5_large_fp8_scaled.safetensors"
        },
        {
          "type": "hf.stable_diffusion_3",
          "repo_id": "Comfy-Org/stable-diffusion-3.5-fp8",
          "path": "sd3.5_medium_incl_clips_t5xxlfp8scaled.safetensors"
        },
        {
          "type": "hf.flux",
          "repo_id": "Comfy-Org/flux1-dev",
          "path": "flux1-dev-fp8.safetensors"
        },
        {
          "type": "hf.flux",
          "repo_id": "Comfy-Org/flux1-schnell",
          "path": "flux1-schnell-fp8.safetensors"
        },
        {
          "type": "hf.flux",
          "repo_id": "black-forest-labs/FLUX.1-Fill-dev",
          "path": "flux1-fill-dev.safetensors"
        },
        {
          "type": "hf.ltxv",
          "repo_id": "Lightricks/LTX-Video",
          "path": "ltx-video-2b-v0.9.safetensors"
        }
      ],
      "basic_fields": [
        "model"
      ],
      "is_dynamic": false
    },
    {
      "title": "Load ControlNet from Huggingface",
      "description": "Loads a ControlNet model from Huggingface.",
      "namespace": "comfy.loaders",
      "node_type": "comfy.loaders.HuggingFaceControlNetLoader",
      "layout": "default",
      "properties": [
        {
          "name": "model",
          "type": {
            "type": "hf.controlnet"
          },
          "default": {},
          "title": "Model",
          "description": "The ControlNet model to load."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "comfy.control_net"
          },
          "name": "control_net"
        }
      ],
      "the_model_info": {},
      "recommended_models": [
        {
          "type": "hf.controlnet",
          "repo_id": "lllyasviel/control_v11p_sd15_canny",
          "path": "diffusion_pytorch_model.fp16.safetensors"
        },
        {
          "type": "hf.controlnet",
          "repo_id": "lllyasviel/control_v11p_sd15_inpaint",
          "path": "diffusion_pytorch_model.fp16.safetensors"
        },
        {
          "type": "hf.controlnet",
          "repo_id": "lllyasviel/control_v11p_sd15_mlsd",
          "path": "diffusion_pytorch_model.fp16.safetensors"
        },
        {
          "type": "hf.controlnet",
          "repo_id": "lllyasviel/control_v11p_sd15_tile",
          "path": "diffusion_pytorch_model.fp16.safetensors"
        },
        {
          "type": "hf.controlnet",
          "repo_id": "lllyasviel/control_v11p_sd15_shuffle",
          "path": "diffusion_pytorch_model.fp16.safetensors"
        },
        {
          "type": "hf.controlnet",
          "repo_id": "lllyasviel/control_v11p_sd15_ip2p",
          "path": "diffusion_pytorch_model.fp16.safetensors"
        },
        {
          "type": "hf.controlnet",
          "repo_id": "lllyasviel/control_v11p_sd15_lineart",
          "path": "diffusion_pytorch_model.fp16.safetensors"
        },
        {
          "type": "hf.controlnet",
          "repo_id": "lllyasviel/control_v11p_sd15_lineart_anime",
          "path": "diffusion_pytorch_model.fp16.safetensors"
        },
        {
          "type": "hf.controlnet",
          "repo_id": "lllyasviel/control_v11p_sd15_scribble",
          "path": "diffusion_pytorch_model.fp16.safetensors"
        },
        {
          "type": "hf.controlnet",
          "repo_id": "lllyasviel/control_v11p_sd15_openpose",
          "path": "diffusion_pytorch_model.fp16.safetensors"
        },
        {
          "type": "hf.controlnet",
          "repo_id": "lllyasviel/control_v11p_sd15_scribble",
          "path": "diffusion_pytorch_model.fp16.safetensors"
        },
        {
          "type": "hf.controlnet",
          "repo_id": "lllyasviel/control_v11p_sd15_seg",
          "path": "diffusion_pytorch_model.fp16.safetensors"
        },
        {
          "type": "hf.controlnet",
          "repo_id": "lllyasviel/control_v11p_sd15_hed",
          "path": "diffusion_pytorch_model.fp16.safetensors"
        },
        {
          "type": "hf.controlnet",
          "repo_id": "lllyasviel/control_v11p_sd15_normalbae",
          "path": "diffusion_pytorch_model.fp16.safetensors"
        }
      ],
      "basic_fields": [
        "model"
      ],
      "is_dynamic": false
    },
    {
      "title": "Load Dual CLIP from Huggingface",
      "description": "Loads a dual CLIP model from Huggingface.",
      "namespace": "comfy.loaders",
      "node_type": "comfy.loaders.HuggingFaceDualCLIPLoader",
      "layout": "default",
      "properties": [
        {
          "name": "type",
          "type": {
            "type": "enum",
            "values": [
              "sdxl",
              "sd3",
              "flux"
            ],
            "type_name": "nodetool.nodes.comfy.loaders.DualCLIPEnum"
          },
          "default": "sdxl",
          "title": "Type",
          "description": "The type of the dual CLIP model to load."
        },
        {
          "name": "clip_model_1",
          "type": {
            "type": "hf.clip"
          },
          "default": {},
          "title": "Clip Model 1",
          "description": "The first CLIP model to load."
        },
        {
          "name": "clip_model_2",
          "type": {
            "type": "hf.clip"
          },
          "default": {},
          "title": "Clip Model 2",
          "description": "The second CLIP model to load."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "comfy.clip"
          },
          "name": "clip"
        }
      ],
      "the_model_info": {},
      "recommended_models": [
        {
          "type": "hf.clip",
          "repo_id": "Comfy-Org/mochi_preview_repackaged",
          "path": "split_files/text_encoders/t5xxl_fp16.safetensors"
        },
        {
          "type": "hf.clip",
          "repo_id": "Comfy-Org/mochi_preview_repackaged",
          "path": "split_files/text_encoders/t5xxl_fp8_e4m3fn_scaled.safetensors"
        },
        {
          "type": "hf.clip",
          "repo_id": "comfyanonymous/flux_text_encoders",
          "path": "clip_l.safetensors"
        },
        {
          "type": "hf.clip",
          "repo_id": "comfyanonymous/flux_text_encoders",
          "path": "t5xxl_fp16.safetensors"
        }
      ],
      "basic_fields": [
        "type",
        "clip_model_1",
        "clip_model_2"
      ],
      "is_dynamic": false
    },
    {
      "title": "Load IPAdapter from Huggingface",
      "description": "Loads an IPAdapter model from Huggingface.",
      "namespace": "comfy.loaders",
      "node_type": "comfy.loaders.HuggingFaceIPAdapterLoader",
      "layout": "default",
      "properties": [
        {
          "name": "ipadapter",
          "type": {
            "type": "hf.ip_adapter"
          },
          "default": {},
          "title": "Ipadapter",
          "description": "The IPAdapter to load."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "comfy.ip_adapter"
          },
          "name": "ipadapter"
        }
      ],
      "the_model_info": {},
      "recommended_models": [
        {
          "type": "hf.ip_adapter",
          "repo_id": "h94/IP-Adapter",
          "path": "models/ip-adapter_sd15.bin"
        },
        {
          "type": "hf.ip_adapter",
          "repo_id": "h94/IP-Adapter",
          "path": "models/ip-adapter_sd15_light.bin"
        },
        {
          "type": "hf.ip_adapter",
          "repo_id": "h94/IP-Adapter",
          "path": "models/ip-adapter_sd15_vit-G.bin"
        },
        {
          "type": "hf.ip_adapter",
          "repo_id": "h94/IP-Adapter",
          "path": "sdxl_models/ip-adapter_sdxl.bin"
        },
        {
          "type": "hf.ip_adapter",
          "repo_id": "h94/IP-Adapter",
          "path": "sdxl_models/ip-adapter_sdxl_vit-h.bin"
        },
        {
          "type": "hf.ip_adapter",
          "repo_id": "h94/IP-Adapter",
          "path": "sdxl_models/ip-adapter-plus_sdxl_vit-h.bin"
        }
      ],
      "basic_fields": [
        "ipadapter"
      ],
      "is_dynamic": false
    },
    {
      "title": "Load LoRA from Huggingface",
      "description": "Loads a LoRA model from Huggingface.",
      "namespace": "comfy.loaders",
      "node_type": "comfy.loaders.HuggingFaceLoraLoader",
      "layout": "default",
      "properties": [
        {
          "name": "model",
          "type": {
            "type": "comfy.unet"
          },
          "default": {},
          "title": "Model",
          "description": "The model to apply LoRA to."
        },
        {
          "name": "clip",
          "type": {
            "type": "comfy.clip"
          },
          "default": {},
          "title": "Clip",
          "description": "The CLIP model to apply LoRA to."
        },
        {
          "name": "lora",
          "type": {
            "type": "hf.lora_sd"
          },
          "default": {},
          "title": "Lora",
          "description": "The LoRA to load."
        },
        {
          "name": "strength_model",
          "type": {
            "type": "float"
          },
          "default": 1.0,
          "title": "Strength Model",
          "description": "The strength of the LoRA to apply to the model.",
          "min": -20.0,
          "max": 20.0
        },
        {
          "name": "strength_clip",
          "type": {
            "type": "float"
          },
          "default": 1.0,
          "title": "Strength Clip",
          "description": "The strength of the LoRA to apply to the CLIP.",
          "min": -20.0,
          "max": 20.0
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "comfy.unet"
          },
          "name": "model"
        },
        {
          "type": {
            "type": "comfy.clip"
          },
          "name": "clip"
        }
      ],
      "the_model_info": {},
      "recommended_models": [
        {
          "type": "hf.lora_sd",
          "repo_id": "danbrown/loras",
          "path": "2d_sprite.safetensors"
        },
        {
          "type": "hf.lora_sd",
          "repo_id": "danbrown/loras",
          "path": "ghibli_scenery.safetensors"
        },
        {
          "type": "hf.lora_sd",
          "repo_id": "danbrown/loras",
          "path": "add_detail.safetensors"
        },
        {
          "type": "hf.lora_sd",
          "repo_id": "danbrown/loras",
          "path": "colorwater.safetensors"
        },
        {
          "type": "hf.lora_sd",
          "repo_id": "danbrown/loras",
          "path": "sxz_game_assets.safetensors"
        },
        {
          "type": "hf.lora_sd",
          "repo_id": "danbrown/loras",
          "path": "3Danaglyph.safetensors"
        },
        {
          "type": "hf.lora_sd",
          "repo_id": "danbrown/loras",
          "path": "akiratoriyama_style.safetensors"
        },
        {
          "type": "hf.lora_sd",
          "repo_id": "danbrown/loras",
          "path": "animeoutlineV4.safetensors"
        },
        {
          "type": "hf.lora_sd",
          "repo_id": "danbrown/loras",
          "path": "aqua_konosuba.safetensors"
        },
        {
          "type": "hf.lora_sd",
          "repo_id": "danbrown/loras",
          "path": "arakihirohiko_style.safetensors"
        },
        {
          "type": "hf.lora_sd",
          "repo_id": "danbrown/loras",
          "path": "arcane_style.safetensors"
        },
        {
          "type": "hf.lora_sd",
          "repo_id": "danbrown/loras",
          "path": "canetaazul.safetensors"
        },
        {
          "type": "hf.lora_sd",
          "repo_id": "danbrown/loras",
          "path": "cyberpunk_tarot.safetensors"
        },
        {
          "type": "hf.lora_sd",
          "repo_id": "danbrown/loras",
          "path": "discoelysium_style.safetensors"
        },
        {
          "type": "hf.lora_sd",
          "repo_id": "danbrown/loras",
          "path": "esdeath_akamegakill.safetensors"
        },
        {
          "type": "hf.lora_sd",
          "repo_id": "danbrown/loras",
          "path": "fire_vfx.safetensors"
        },
        {
          "type": "hf.lora_sd",
          "repo_id": "danbrown/loras",
          "path": "flamingeye.safetensors"
        },
        {
          "type": "hf.lora_sd",
          "repo_id": "danbrown/loras",
          "path": "funnycreatures.safetensors"
        },
        {
          "type": "hf.lora_sd",
          "repo_id": "danbrown/loras",
          "path": "gacha_splash.safetensors"
        },
        {
          "type": "hf.lora_sd",
          "repo_id": "danbrown/loras",
          "path": "gigachad.safetensors"
        },
        {
          "type": "hf.lora_sd",
          "repo_id": "danbrown/loras",
          "path": "gyokai_style.safetensors"
        },
        {
          "type": "hf.lora_sd",
          "repo_id": "danbrown/loras",
          "path": "harold.safetensors"
        },
        {
          "type": "hf.lora_sd",
          "repo_id": "danbrown/loras",
          "path": "hiderohoribes_style.safetensors"
        },
        {
          "type": "hf.lora_sd",
          "repo_id": "danbrown/loras",
          "path": "ilyakuvshinov_style.safetensors"
        },
        {
          "type": "hf.lora_sd",
          "repo_id": "danbrown/loras",
          "path": "jacksparrow.safetensors"
        },
        {
          "type": "hf.lora_sd",
          "repo_id": "danbrown/loras",
          "path": "jimlee_style.safetensors"
        },
        {
          "type": "hf.lora_sd",
          "repo_id": "danbrown/loras",
          "path": "komowataharuka_chibiart.safetensors"
        },
        {
          "type": "hf.lora_sd",
          "repo_id": "danbrown/loras",
          "path": "lightning_vfx.safetensors"
        },
        {
          "type": "hf.lora_sd",
          "repo_id": "danbrown/loras",
          "path": "lucy_cyberpunk.safetensors"
        },
        {
          "type": "hf.lora_sd",
          "repo_id": "danbrown/loras",
          "path": "luisap_pixelart.safetensors"
        },
        {
          "type": "hf.lora_sd",
          "repo_id": "danbrown/loras",
          "path": "mumei_kabaneri.safetensors"
        },
        {
          "type": "hf.lora_sd",
          "repo_id": "danbrown/loras",
          "path": "myheroacademia_style.safetensors"
        },
        {
          "type": "hf.lora_sd",
          "repo_id": "danbrown/loras",
          "path": "neoartcore.safetensors"
        },
        {
          "type": "hf.lora_sd",
          "repo_id": "danbrown/loras",
          "path": "ochakouraraka.safetensors"
        },
        {
          "type": "hf.lora_sd",
          "repo_id": "danbrown/loras",
          "path": "onepiece_style.safetensors"
        },
        {
          "type": "hf.lora_sd",
          "repo_id": "danbrown/loras",
          "path": "paimon_genshinimpact.safetensors"
        },
        {
          "type": "hf.lora_sd",
          "repo_id": "danbrown/loras",
          "path": "peanutscomics_style.safetensors"
        },
        {
          "type": "hf.lora_sd",
          "repo_id": "danbrown/loras",
          "path": "pepefrog.safetensors"
        },
        {
          "type": "hf.lora_sd",
          "repo_id": "danbrown/loras",
          "path": "persona5_portraits.safetensors"
        },
        {
          "type": "hf.lora_sd",
          "repo_id": "danbrown/loras",
          "path": "persona5_style.safetensors"
        },
        {
          "type": "hf.lora_sd",
          "repo_id": "danbrown/loras",
          "path": "pixhell.safetensors"
        },
        {
          "type": "hf.lora_sd",
          "repo_id": "danbrown/loras",
          "path": "princesszelda.safetensors"
        },
        {
          "type": "hf.lora_sd",
          "repo_id": "danbrown/loras",
          "path": "satoshiuruchihara_style.safetensors"
        },
        {
          "type": "hf.lora_sd",
          "repo_id": "danbrown/loras",
          "path": "shinobu_demonslayer.safetensors"
        },
        {
          "type": "hf.lora_sd",
          "repo_id": "danbrown/loras",
          "path": "sokolov_style.safetensors"
        },
        {
          "type": "hf.lora_sd",
          "repo_id": "danbrown/loras",
          "path": "standingbackgroundv1.safetensors"
        },
        {
          "type": "hf.lora_sd",
          "repo_id": "danbrown/loras",
          "path": "sun_shadow_style.safetensors"
        },
        {
          "type": "hf.lora_sd",
          "repo_id": "danbrown/loras",
          "path": "thickeranimelines.safetensors"
        },
        {
          "type": "hf.lora_sd",
          "repo_id": "danbrown/loras",
          "path": "threesidedview.safetensors"
        },
        {
          "type": "hf.lora_sd",
          "repo_id": "danbrown/loras",
          "path": "twitch_emotes.safetensors"
        },
        {
          "type": "hf.lora_sd",
          "repo_id": "danbrown/loras",
          "path": "water_vfx.safetensors"
        },
        {
          "type": "hf.lora_sd",
          "repo_id": "danbrown/loras",
          "path": "wlop_style.safetensors"
        },
        {
          "type": "hf.lora_sd",
          "repo_id": "danbrown/loras",
          "path": "zerotwo_darling.safetensors"
        },
        {
          "type": "hf.lora_sdxl",
          "repo_id": "CiroN2022/toy-face",
          "path": "toy_face_sdxl.safetensors"
        },
        {
          "type": "hf.lora_sdxl",
          "repo_id": "nerijs/pixel-art-xl",
          "path": "pixel-art-xl.safetensors"
        },
        {
          "type": "hf.lora_sdxl",
          "repo_id": "goofyai/3d_render_style_xl",
          "path": "3d_render_style_xl.safetensors"
        },
        {
          "type": "hf.lora_sdxl",
          "repo_id": "artificialguybr/CuteCartoonRedmond-V2",
          "path": "CuteCartoonRedmond-CuteCartoon-CuteCartoonAF.safetensors"
        },
        {
          "type": "hf.lora_sdxl",
          "repo_id": "blink7630/graphic-novel-illustration",
          "path": "Graphic_Novel_Illustration-000007.safetensors"
        },
        {
          "type": "hf.lora_sdxl",
          "repo_id": "robert123231/coloringbookgenerator",
          "path": "ColoringBookRedmond-ColoringBook-ColoringBookAF.safetensors"
        },
        {
          "type": "hf.lora_sdxl",
          "repo_id": "Linaqruf/anime-detailer-xl-lora",
          "path": "anime-detailer-xl-lora.safetensors"
        }
      ],
      "basic_fields": [
        "model",
        "clip",
        "lora",
        "strength_model",
        "strength_clip"
      ],
      "is_dynamic": false
    },
    {
      "title": "Load Style Model from Huggingface",
      "description": "Loads a style model from HuggingFace.",
      "namespace": "comfy.loaders",
      "node_type": "comfy.loaders.HuggingFaceStyleModelLoader",
      "layout": "default",
      "properties": [
        {
          "name": "model",
          "type": {
            "type": "hf.style_model"
          },
          "default": {},
          "title": "Model",
          "description": "The style model to load."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "comfy.style_model"
          },
          "name": "style_model"
        }
      ],
      "the_model_info": {},
      "recommended_models": [
        {
          "type": "hf.style_model",
          "repo_id": "black-forest-labs/FLUX.1-Redux-dev",
          "path": "flux1-redux-dev.safetensors"
        }
      ],
      "basic_fields": [
        "model"
      ],
      "is_dynamic": false
    },
    {
      "title": "Load Diffusion Model from Huggingface",
      "description": "Loads a UNet model from Huggingface.",
      "namespace": "comfy.loaders",
      "node_type": "comfy.loaders.HuggingFaceUNetLoader",
      "layout": "default",
      "properties": [
        {
          "name": "model",
          "type": {
            "type": "hf.unet"
          },
          "default": {},
          "title": "Model",
          "description": "The UNet model to load."
        },
        {
          "name": "weight_dtype",
          "type": {
            "type": "enum",
            "values": [
              "default",
              "fp8_e4m3fn",
              "fp8_e4m3fn_fast",
              "fp8_e5m2"
            ],
            "type_name": "nodetool.nodes.comfy.loaders.WeightDataTypeEnum"
          },
          "default": "default",
          "title": "Weight Dtype",
          "description": "The weight data type to use."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "comfy.unet"
          },
          "name": "unet"
        }
      ],
      "the_model_info": {},
      "recommended_models": [
        {
          "type": "hf.unet",
          "repo_id": "Comfy-Org/mochi_preview_repackaged",
          "path": "split_files/diffusion_models/mochi_preview_bf16.safetensors"
        },
        {
          "type": "hf.unet",
          "repo_id": "Comfy-Org/mochi_preview_repackaged",
          "path": "split_files/diffusion_models/mochi_preview_fp8_scaled.safetensors"
        },
        {
          "type": "hf.unet",
          "repo_id": "black-forest-labs/FLUX.1-dev",
          "path": "flux1-dev.safetensors"
        },
        {
          "type": "hf.unet",
          "repo_id": "black-forest-labs/FLUX.1-schnell",
          "path": "flux1-schnell.safetensors"
        }
      ],
      "basic_fields": [
        "model",
        "weight_dtype"
      ],
      "is_dynamic": false
    },
    {
      "title": "Load VAE from Huggingface",
      "description": "Loads a VAE model from Huggingface.",
      "namespace": "comfy.loaders",
      "node_type": "comfy.loaders.HuggingFaceVAELoader",
      "layout": "default",
      "properties": [
        {
          "name": "model",
          "type": {
            "type": "hf.vae"
          },
          "default": {},
          "title": "Model",
          "description": "The VAE model to load."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "comfy.vae"
          },
          "name": "vae"
        }
      ],
      "the_model_info": {},
      "recommended_models": [
        {
          "type": "hf.vae",
          "repo_id": "Comfy-Org/mochi_preview_repackaged",
          "path": "split_files/vae/mochi_vae.safetensors"
        },
        {
          "type": "hf.vae",
          "repo_id": "black-forest-labs/FLUX.1-schnell",
          "path": "ae.safetensors"
        }
      ],
      "basic_fields": [
        "model"
      ],
      "is_dynamic": false
    },
    {
      "title": "Load IPAdapter",
      "description": "Loads an IPAdapter model.",
      "namespace": "comfy.loaders",
      "node_type": "comfy.loaders.IPAdapterModelLoader",
      "layout": "default",
      "properties": [
        {
          "name": "ipadapter_file",
          "type": {
            "type": "comfy.ip_adapter_file"
          },
          "default": {},
          "title": "Ipadapter File",
          "description": "List of available IPAdapter model names."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "comfy.ip_adapter"
          },
          "name": "ipadapter"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "ipadapter_file"
      ],
      "is_dynamic": false
    },
    {
      "title": "Image Only Checkpoint Loader (img2vid model)",
      "description": "Loads a checkpoint for img2vid.",
      "namespace": "comfy.loaders",
      "node_type": "comfy.loaders.ImageOnlyCheckpointLoader",
      "layout": "default",
      "properties": [
        {
          "name": "ckpt_name",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Ckpt Name",
          "description": "The name of the checkpoint to load."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "comfy.unet"
          },
          "name": "model"
        },
        {
          "type": {
            "type": "comfy.clip_vision"
          },
          "name": "clip_vision"
        },
        {
          "type": {
            "type": "comfy.vae"
          },
          "name": "vae"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "ckpt_name"
      ],
      "is_dynamic": false
    },
    {
      "title": "Lora Loader",
      "description": "Loads a LoRA model.",
      "namespace": "comfy.loaders",
      "node_type": "comfy.loaders.LoraLoader",
      "layout": "default",
      "properties": [
        {
          "name": "model",
          "type": {
            "type": "comfy.unet"
          },
          "default": {},
          "title": "Model",
          "description": "The model to apply Lora to."
        },
        {
          "name": "clip",
          "type": {
            "type": "comfy.clip"
          },
          "default": {},
          "title": "Clip",
          "description": "The CLIP model to apply Lora to."
        },
        {
          "name": "lora_name",
          "type": {
            "type": "comfy.lora_file"
          },
          "default": {},
          "title": "Lora Name",
          "description": "The name of the LoRA to load."
        },
        {
          "name": "strength_model",
          "type": {
            "type": "float"
          },
          "default": 1.0,
          "title": "Strength Model",
          "description": "The strength of the LoRA to apply to the model.",
          "min": -20.0,
          "max": 20.0
        },
        {
          "name": "strength_clip",
          "type": {
            "type": "float"
          },
          "default": 1.0,
          "title": "Strength Clip",
          "description": "The strength of the LoRA to apply to the CLIP.",
          "min": -20.0,
          "max": 20.0
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "comfy.unet"
          },
          "name": "model"
        },
        {
          "type": {
            "type": "comfy.clip"
          },
          "name": "clip"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "model",
        "clip",
        "lora_name",
        "strength_model",
        "strength_clip"
      ],
      "is_dynamic": false
    },
    {
      "title": "Lora Loader Model Only",
      "description": "Loads a LoRA model (model only).",
      "namespace": "comfy.loaders",
      "node_type": "comfy.loaders.LoraLoaderModelOnly",
      "layout": "default",
      "properties": [
        {
          "name": "model",
          "type": {
            "type": "comfy.unet"
          },
          "default": {},
          "title": "Model",
          "description": "The model to apply Lora to."
        },
        {
          "name": "lora_name",
          "type": {
            "type": "comfy.lora_file"
          },
          "default": {},
          "title": "Lora Name",
          "description": "The name of the LoRA to load."
        },
        {
          "name": "strength_model",
          "type": {
            "type": "float"
          },
          "default": 1.0,
          "title": "Strength Model",
          "description": "The strength of the LoRA to apply to the model.",
          "min": -20.0,
          "max": 20.0
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "comfy.unet"
          },
          "name": "model"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "model",
        "lora_name",
        "strength_model"
      ],
      "is_dynamic": false
    },
    {
      "title": "Load Style Model",
      "description": "Loads a style model.",
      "namespace": "comfy.loaders",
      "node_type": "comfy.loaders.StyleModelLoader",
      "layout": "default",
      "properties": [
        {
          "name": "style_model_name",
          "type": {
            "type": "comfy.style_model_file"
          },
          "default": {},
          "title": "Style Model Name",
          "description": "The name of the style model to load."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "comfy.style_model"
          },
          "name": "style_model"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "style_model_name"
      ],
      "is_dynamic": false
    },
    {
      "title": "Load Diffusion Model",
      "description": "Loads a UNet model.",
      "namespace": "comfy.loaders",
      "node_type": "comfy.loaders.UNETLoader",
      "layout": "default",
      "properties": [
        {
          "name": "unet_name",
          "type": {
            "type": "comfy.unet_file"
          },
          "default": {},
          "title": "Unet Name",
          "description": "The name of the UNet model to load."
        },
        {
          "name": "weight_dtype",
          "type": {
            "type": "enum",
            "values": [
              "default",
              "fp8_e4m3fn",
              "fp8_e4m3fn_fast",
              "fp8_e5m2"
            ],
            "type_name": "nodetool.nodes.comfy.loaders.WeightDataTypeEnum"
          },
          "default": "default",
          "title": "Weight Dtype",
          "description": "The weight data type to use."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "comfy.unet"
          },
          "name": "unet"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "unet_name",
        "weight_dtype"
      ],
      "is_dynamic": false
    },
    {
      "title": "Load Upscale Model",
      "description": "Loads an upscale model.",
      "namespace": "comfy.loaders",
      "node_type": "comfy.loaders.UpscaleModelLoader",
      "layout": "default",
      "properties": [
        {
          "name": "model_name",
          "type": {
            "type": "comfy.upscale_model_file"
          },
          "default": {},
          "title": "Model Name",
          "description": "The filename of the upscale model to load."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "comfy.upscale_model"
          },
          "name": "upscale_model"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "model_name"
      ],
      "is_dynamic": false
    },
    {
      "title": "Load VAE",
      "description": "Loads a VAE model.",
      "namespace": "comfy.loaders",
      "node_type": "comfy.loaders.VAELoader",
      "layout": "default",
      "properties": [
        {
          "name": "vae_name",
          "type": {
            "type": "comfy.vae_file"
          },
          "default": {},
          "title": "Vae Name",
          "description": "The name of the VAE to load."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "comfy.vae"
          },
          "name": "vae"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "vae_name"
      ],
      "is_dynamic": false
    },
    {
      "title": "un CLIPCheckpoint Loader",
      "description": "Loads a unCLIP checkpoint.",
      "namespace": "comfy.loaders",
      "node_type": "comfy.loaders.unCLIPCheckpointLoader",
      "layout": "default",
      "properties": [
        {
          "name": "ckpt_name",
          "type": {
            "type": "comfy.unclip_file"
          },
          "default": {},
          "title": "Ckpt Name",
          "description": "The checkpoint to load."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "comfy.unet"
          },
          "name": "model"
        },
        {
          "type": {
            "type": "comfy.clip"
          },
          "name": "clip"
        },
        {
          "type": {
            "type": "comfy.vae"
          },
          "name": "vae"
        },
        {
          "type": {
            "type": "comfy.clip_vision"
          },
          "name": "clip_vision"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "ckpt_name"
      ],
      "is_dynamic": false
    },
    {
      "title": "Note",
      "description": "",
      "namespace": "comfy.__init__",
      "node_type": "comfy.__init__.Note",
      "layout": "default",
      "properties": [],
      "outputs": [],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [],
      "is_dynamic": false
    },
    {
      "title": "Primitive",
      "description": "",
      "namespace": "comfy.__init__",
      "node_type": "comfy.__init__.Primitive",
      "layout": "default",
      "properties": [],
      "outputs": [
        {
          "type": {
            "type": "any"
          },
          "name": "output"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [],
      "is_dynamic": false
    },
    {
      "title": "Reroute",
      "description": "",
      "namespace": "comfy.__init__",
      "node_type": "comfy.__init__.Reroute",
      "layout": "default",
      "properties": [],
      "outputs": [
        {
          "type": {
            "type": "any"
          },
          "name": "output"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [],
      "is_dynamic": false
    },
    {
      "title": "Control Net",
      "description": "Generates images using Stable Diffusion with ControlNet for additional image control. Supports optional high-resolution upscaling while maintaining the same ControlNet strength.\n    image, controlnet, generative, stable diffusion, high-resolution, SD\n\n    Use cases:\n    - Generating images with specific structural guidance\n    - Creating images that follow edge maps or depth information\n    - Producing variations of images while maintaining certain features\n    - Enhancing image generation with additional control signals\n    - Creating high-resolution images with consistent controlled features",
      "namespace": "comfy.basic",
      "node_type": "comfy.basic.ControlNet",
      "layout": "default",
      "properties": [
        {
          "name": "model",
          "type": {
            "type": "hf.stable_diffusion"
          },
          "default": {},
          "title": "Model",
          "description": "The model to use."
        },
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to use."
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Negative Prompt",
          "description": "The negative prompt to use."
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": 0,
          "title": "Seed",
          "min": 0.0,
          "max": 1000000.0
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 7.0,
          "title": "Guidance Scale",
          "min": 1.0,
          "max": 30.0
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 30,
          "title": "Num Inference Steps",
          "min": 1.0,
          "max": 100.0
        },
        {
          "name": "width",
          "type": {
            "type": "int"
          },
          "default": 768,
          "title": "Width",
          "min": 64.0,
          "max": 2048.0
        },
        {
          "name": "height",
          "type": {
            "type": "int"
          },
          "default": 768,
          "title": "Height",
          "min": 64.0,
          "max": 2048.0
        },
        {
          "name": "scheduler",
          "type": {
            "type": "enum",
            "values": [
              "normal",
              "karras",
              "exponential",
              "sgm_uniform",
              "simple",
              "ddim_uniform",
              "beta",
              "linear_quadratic"
            ],
            "type_name": "nodetool.nodes.comfy.enums.Scheduler"
          },
          "default": "exponential",
          "title": "Scheduler"
        },
        {
          "name": "sampler",
          "type": {
            "type": "enum",
            "values": [
              "ddim",
              "ddpm",
              "dpm_2",
              "dpm_2_ancestral",
              "dpm_adaptive",
              "dpm_fast",
              "dpmpp_2m",
              "dpmpp_2m_sde",
              "dpmpp_2m_sde_gpu",
              "dpmpp_2s_ancestral",
              "dpmpp_3m_sde",
              "dpmpp_3m_sde_gpu",
              "dpmpp_sde",
              "dpmpp_sde_gpu",
              "euler",
              "euler_ancestral",
              "heun",
              "heunpp2",
              "lcm",
              "lms",
              "uni_pc",
              "uni_pc_bh2"
            ],
            "type_name": "nodetool.nodes.comfy.enums.Sampler"
          },
          "default": "euler_ancestral",
          "title": "Sampler"
        },
        {
          "name": "input_image",
          "type": {
            "type": "image"
          },
          "default": {},
          "title": "Input Image",
          "description": "Input image for img2img (optional)"
        },
        {
          "name": "mask_image",
          "type": {
            "type": "image"
          },
          "default": {},
          "title": "Mask Image",
          "description": "Mask image for img2img (optional)"
        },
        {
          "name": "grow_mask_by",
          "type": {
            "type": "int"
          },
          "default": 6,
          "title": "Grow Mask By",
          "min": 0.0,
          "max": 100.0
        },
        {
          "name": "denoise",
          "type": {
            "type": "float"
          },
          "default": 1.0,
          "title": "Denoise",
          "min": 0.0,
          "max": 1.0
        },
        {
          "name": "loras",
          "type": {
            "type": "list",
            "type_args": [
              {
                "type": "comfy.lora_config"
              }
            ]
          },
          "default": [],
          "title": "Loras",
          "description": "List of LoRA models to apply"
        },
        {
          "name": "controlnet",
          "type": {
            "type": "hf.controlnet"
          },
          "default": {},
          "title": "Controlnet",
          "description": "The ControlNet model to use."
        },
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {},
          "title": "Image",
          "description": "Canny edge detection image for ControlNet"
        },
        {
          "name": "strength",
          "type": {
            "type": "float"
          },
          "default": 1.0,
          "title": "Strength",
          "description": "Strength of ControlNet (used for both low and high resolution)",
          "min": 0.0,
          "max": 1.0
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "the_model_info": {},
      "recommended_models": [
        {
          "type": "hf.controlnet",
          "repo_id": "lllyasviel/control_v11p_sd15_canny",
          "path": "diffusion_pytorch_model.fp16.safetensors"
        },
        {
          "type": "hf.controlnet",
          "repo_id": "lllyasviel/control_v11p_sd15_inpaint",
          "path": "diffusion_pytorch_model.fp16.safetensors"
        },
        {
          "type": "hf.controlnet",
          "repo_id": "lllyasviel/control_v11p_sd15_mlsd",
          "path": "diffusion_pytorch_model.fp16.safetensors"
        },
        {
          "type": "hf.controlnet",
          "repo_id": "lllyasviel/control_v11p_sd15_tile",
          "path": "diffusion_pytorch_model.fp16.safetensors"
        },
        {
          "type": "hf.controlnet",
          "repo_id": "lllyasviel/control_v11p_sd15_shuffle",
          "path": "diffusion_pytorch_model.fp16.safetensors"
        },
        {
          "type": "hf.controlnet",
          "repo_id": "lllyasviel/control_v11p_sd15_ip2p",
          "path": "diffusion_pytorch_model.fp16.safetensors"
        },
        {
          "type": "hf.controlnet",
          "repo_id": "lllyasviel/control_v11p_sd15_lineart",
          "path": "diffusion_pytorch_model.fp16.safetensors"
        },
        {
          "type": "hf.controlnet",
          "repo_id": "lllyasviel/control_v11p_sd15_lineart_anime",
          "path": "diffusion_pytorch_model.fp16.safetensors"
        },
        {
          "type": "hf.controlnet",
          "repo_id": "lllyasviel/control_v11p_sd15_scribble",
          "path": "diffusion_pytorch_model.fp16.safetensors"
        },
        {
          "type": "hf.controlnet",
          "repo_id": "lllyasviel/control_v11p_sd15_openpose",
          "path": "diffusion_pytorch_model.fp16.safetensors"
        },
        {
          "type": "hf.controlnet",
          "repo_id": "lllyasviel/control_v11p_sd15_scribble",
          "path": "diffusion_pytorch_model.fp16.safetensors"
        },
        {
          "type": "hf.controlnet",
          "repo_id": "lllyasviel/control_v11p_sd15_seg",
          "path": "diffusion_pytorch_model.fp16.safetensors"
        },
        {
          "type": "hf.controlnet",
          "repo_id": "lllyasviel/control_v11p_sd15_hed",
          "path": "diffusion_pytorch_model.fp16.safetensors"
        },
        {
          "type": "hf.controlnet",
          "repo_id": "lllyasviel/control_v11p_sd15_normalbae",
          "path": "diffusion_pytorch_model.fp16.safetensors"
        }
      ],
      "basic_fields": [
        "model",
        "prompt",
        "negative_prompt",
        "seed",
        "guidance_scale",
        "num_inference_steps",
        "width",
        "height",
        "scheduler",
        "sampler",
        "input_image",
        "mask_image",
        "grow_mask_by",
        "denoise",
        "loras",
        "controlnet",
        "image",
        "strength"
      ],
      "is_dynamic": false
    },
    {
      "title": "Flux",
      "description": "Generates images from text prompts using the Flux model.\n    image, text-to-image, generative AI, flux\n\n    Use cases:\n    - Creating high-quality anime-style illustrations\n    - Generating detailed character artwork\n    - Producing images with specific artistic styles",
      "namespace": "comfy.basic",
      "node_type": "comfy.basic.Flux",
      "layout": "default",
      "properties": [
        {
          "name": "model",
          "type": {
            "type": "hf.flux"
          },
          "default": {},
          "title": "Model",
          "description": "The model to use."
        },
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to use."
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Negative Prompt",
          "description": "The negative prompt to use."
        },
        {
          "name": "width",
          "type": {
            "type": "int"
          },
          "default": 1024,
          "title": "Width",
          "min": 64.0,
          "max": 2048.0
        },
        {
          "name": "height",
          "type": {
            "type": "int"
          },
          "default": 1024,
          "title": "Height",
          "min": 64.0,
          "max": 2048.0
        },
        {
          "name": "batch_size",
          "type": {
            "type": "int"
          },
          "default": 1,
          "title": "Batch Size",
          "min": 1.0,
          "max": 16.0
        },
        {
          "name": "steps",
          "type": {
            "type": "int"
          },
          "default": 20,
          "title": "Steps",
          "min": 1.0,
          "max": 100.0
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 1.0,
          "title": "Guidance Scale",
          "min": 1.0,
          "max": 30.0
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": 0,
          "title": "Seed",
          "min": 0.0,
          "max": 1000000000.0
        },
        {
          "name": "denoise",
          "type": {
            "type": "float"
          },
          "default": 1.0,
          "title": "Denoise",
          "min": 0.0,
          "max": 1.0
        },
        {
          "name": "scheduler",
          "type": {
            "type": "enum",
            "values": [
              "normal",
              "karras",
              "exponential",
              "sgm_uniform",
              "simple",
              "ddim_uniform",
              "beta",
              "linear_quadratic"
            ],
            "type_name": "nodetool.nodes.comfy.enums.Scheduler"
          },
          "default": "simple",
          "title": "Scheduler"
        },
        {
          "name": "sampler",
          "type": {
            "type": "enum",
            "values": [
              "ddim",
              "ddpm",
              "dpm_2",
              "dpm_2_ancestral",
              "dpm_adaptive",
              "dpm_fast",
              "dpmpp_2m",
              "dpmpp_2m_sde",
              "dpmpp_2m_sde_gpu",
              "dpmpp_2s_ancestral",
              "dpmpp_3m_sde",
              "dpmpp_3m_sde_gpu",
              "dpmpp_sde",
              "dpmpp_sde_gpu",
              "euler",
              "euler_ancestral",
              "heun",
              "heunpp2",
              "lcm",
              "lms",
              "uni_pc",
              "uni_pc_bh2"
            ],
            "type_name": "nodetool.nodes.comfy.enums.Sampler"
          },
          "default": "euler",
          "title": "Sampler"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "the_model_info": {},
      "recommended_models": [
        {
          "type": "hf.unet",
          "repo_id": "black-forest-labs/FLUX.1-dev",
          "path": "flux1-dev.safetensors"
        },
        {
          "type": "hf.unet",
          "repo_id": "black-forest-labs/FLUX.1-schnell",
          "path": "flux1-schnell.safetensors"
        },
        {
          "type": "hf.vae",
          "repo_id": "black-forest-labs/FLUX.1-schnell",
          "path": "ae.safetensors"
        },
        {
          "type": "hf.clip",
          "repo_id": "comfyanonymous/flux_text_encoders",
          "path": "clip_l.safetensors"
        },
        {
          "type": "hf.clip",
          "repo_id": "comfyanonymous/flux_text_encoders",
          "path": "t5xxl_fp16.safetensors"
        }
      ],
      "basic_fields": [
        "model",
        "prompt",
        "negative_prompt",
        "width",
        "height",
        "batch_size",
        "steps",
        "guidance_scale",
        "seed",
        "denoise",
        "scheduler",
        "sampler"
      ],
      "is_dynamic": false
    },
    {
      "title": "Flux FP8",
      "description": "Generates images from text prompts using the Flux model.\n    image, text-to-image, generative AI, flux\n\n    Use cases:\n    - Creating high-quality anime-style illustrations\n    - Generating detailed character artwork\n    - Producing images with specific artistic styles",
      "namespace": "comfy.basic",
      "node_type": "comfy.basic.FluxFP8",
      "layout": "default",
      "properties": [
        {
          "name": "model",
          "type": {
            "type": "hf.flux"
          },
          "default": {},
          "title": "Model",
          "description": "The model to use."
        },
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to use."
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Negative Prompt",
          "description": "The negative prompt to use."
        },
        {
          "name": "width",
          "type": {
            "type": "int"
          },
          "default": 1024,
          "title": "Width",
          "min": 64.0,
          "max": 2048.0
        },
        {
          "name": "height",
          "type": {
            "type": "int"
          },
          "default": 1024,
          "title": "Height",
          "min": 64.0,
          "max": 2048.0
        },
        {
          "name": "batch_size",
          "type": {
            "type": "int"
          },
          "default": 1,
          "title": "Batch Size",
          "min": 1.0,
          "max": 16.0
        },
        {
          "name": "steps",
          "type": {
            "type": "int"
          },
          "default": 20,
          "title": "Steps",
          "min": 1.0,
          "max": 100.0
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 1.0,
          "title": "Guidance Scale",
          "min": 1.0,
          "max": 30.0
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": 0,
          "title": "Seed",
          "min": 0.0,
          "max": 1000000000.0
        },
        {
          "name": "denoise",
          "type": {
            "type": "float"
          },
          "default": 1.0,
          "title": "Denoise",
          "min": 0.0,
          "max": 1.0
        },
        {
          "name": "scheduler",
          "type": {
            "type": "enum",
            "values": [
              "normal",
              "karras",
              "exponential",
              "sgm_uniform",
              "simple",
              "ddim_uniform",
              "beta",
              "linear_quadratic"
            ],
            "type_name": "nodetool.nodes.comfy.enums.Scheduler"
          },
          "default": "simple",
          "title": "Scheduler"
        },
        {
          "name": "sampler",
          "type": {
            "type": "enum",
            "values": [
              "ddim",
              "ddpm",
              "dpm_2",
              "dpm_2_ancestral",
              "dpm_adaptive",
              "dpm_fast",
              "dpmpp_2m",
              "dpmpp_2m_sde",
              "dpmpp_2m_sde_gpu",
              "dpmpp_2s_ancestral",
              "dpmpp_3m_sde",
              "dpmpp_3m_sde_gpu",
              "dpmpp_sde",
              "dpmpp_sde_gpu",
              "euler",
              "euler_ancestral",
              "heun",
              "heunpp2",
              "lcm",
              "lms",
              "uni_pc",
              "uni_pc_bh2"
            ],
            "type_name": "nodetool.nodes.comfy.enums.Sampler"
          },
          "default": "euler",
          "title": "Sampler"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "the_model_info": {},
      "recommended_models": [
        {
          "type": "hf.flux",
          "repo_id": "Comfy-Org/flux1-dev",
          "path": "flux1-dev-fp8.safetensors"
        },
        {
          "type": "hf.flux",
          "repo_id": "Comfy-Org/flux1-schnell",
          "path": "flux1-schnell-fp8.safetensors"
        }
      ],
      "basic_fields": [
        "model",
        "prompt",
        "negative_prompt",
        "width",
        "height",
        "batch_size",
        "steps",
        "guidance_scale",
        "seed",
        "denoise",
        "scheduler",
        "sampler"
      ],
      "is_dynamic": false
    },
    {
      "title": "Lo RASelector",
      "description": "Selects up to 5 LoRA models to apply to a Stable Diffusion model.\n    lora, model customization, fine-tuning\n\n    Use cases:\n    - Combining multiple LoRA models for unique image styles\n    - Fine-tuning Stable Diffusion models with specific attributes\n    - Experimenting with different LoRA combinations",
      "namespace": "comfy.basic",
      "node_type": "comfy.basic.LoRASelector",
      "layout": "default",
      "properties": [
        {
          "name": "lora1",
          "type": {
            "type": "comfy.lora_file",
            "optional": true
          },
          "default": {},
          "title": "Lora1",
          "description": "First LoRA model"
        },
        {
          "name": "strength1",
          "type": {
            "type": "float",
            "optional": true
          },
          "default": 1.0,
          "title": "Strength1",
          "description": "Strength for first LoRA",
          "min": 0.0,
          "max": 2.0
        },
        {
          "name": "lora2",
          "type": {
            "type": "comfy.lora_file",
            "optional": true
          },
          "default": {},
          "title": "Lora2",
          "description": "Second LoRA model"
        },
        {
          "name": "strength2",
          "type": {
            "type": "float",
            "optional": true
          },
          "default": 1.0,
          "title": "Strength2",
          "description": "Strength for second LoRA",
          "min": 0.0,
          "max": 2.0
        },
        {
          "name": "lora3",
          "type": {
            "type": "comfy.lora_file",
            "optional": true
          },
          "default": {},
          "title": "Lora3",
          "description": "Third LoRA model"
        },
        {
          "name": "strength3",
          "type": {
            "type": "float",
            "optional": true
          },
          "default": 1.0,
          "title": "Strength3",
          "description": "Strength for third LoRA",
          "min": 0.0,
          "max": 2.0
        },
        {
          "name": "lora4",
          "type": {
            "type": "comfy.lora_file",
            "optional": true
          },
          "default": {},
          "title": "Lora4",
          "description": "Fourth LoRA model"
        },
        {
          "name": "strength4",
          "type": {
            "type": "float",
            "optional": true
          },
          "default": 1.0,
          "title": "Strength4",
          "description": "Strength for fourth LoRA",
          "min": 0.0,
          "max": 2.0
        },
        {
          "name": "lora5",
          "type": {
            "type": "comfy.lora_file",
            "optional": true
          },
          "default": {},
          "title": "Lora5",
          "description": "Fifth LoRA model"
        },
        {
          "name": "strength5",
          "type": {
            "type": "float",
            "optional": true
          },
          "default": 1.0,
          "title": "Strength5",
          "description": "Strength for fifth LoRA",
          "min": 0.0,
          "max": 2.0
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "list",
            "type_args": [
              {
                "type": "comfy.lora_config"
              }
            ]
          },
          "name": "output"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "lora1",
        "strength1",
        "lora2",
        "strength2",
        "lora3",
        "strength3",
        "lora4",
        "strength4",
        "lora5",
        "strength5"
      ],
      "is_dynamic": false
    },
    {
      "title": "Stable Diffusion",
      "description": "Generates images based on an input image and text prompts using Stable Diffusion. Works with 1.5 and XL models. Supports optional high-resolution upscaling.\n    image, image-to-image, generative AI, stable diffusion, high-resolution, SD1.5\n\n    Use cases:\n    - Modifying existing images based on text descriptions\n    - Applying artistic styles to photographs\n    - Generating variations of existing artwork or designs\n    - Enhancing or altering stock images for specific needs\n    - Creating high-resolution images from lower resolution inputs",
      "namespace": "comfy.basic",
      "node_type": "comfy.basic.StableDiffusion",
      "layout": "default",
      "properties": [
        {
          "name": "model",
          "type": {
            "type": "hf.stable_diffusion"
          },
          "default": {},
          "title": "Model",
          "description": "The model to use."
        },
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to use."
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Negative Prompt",
          "description": "The negative prompt to use."
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": 0,
          "title": "Seed",
          "min": 0.0,
          "max": 1000000.0
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 7.0,
          "title": "Guidance Scale",
          "min": 1.0,
          "max": 30.0
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 30,
          "title": "Num Inference Steps",
          "min": 1.0,
          "max": 100.0
        },
        {
          "name": "width",
          "type": {
            "type": "int"
          },
          "default": 768,
          "title": "Width",
          "min": 64.0,
          "max": 2048.0
        },
        {
          "name": "height",
          "type": {
            "type": "int"
          },
          "default": 768,
          "title": "Height",
          "min": 64.0,
          "max": 2048.0
        },
        {
          "name": "scheduler",
          "type": {
            "type": "enum",
            "values": [
              "normal",
              "karras",
              "exponential",
              "sgm_uniform",
              "simple",
              "ddim_uniform",
              "beta",
              "linear_quadratic"
            ],
            "type_name": "nodetool.nodes.comfy.enums.Scheduler"
          },
          "default": "exponential",
          "title": "Scheduler"
        },
        {
          "name": "sampler",
          "type": {
            "type": "enum",
            "values": [
              "ddim",
              "ddpm",
              "dpm_2",
              "dpm_2_ancestral",
              "dpm_adaptive",
              "dpm_fast",
              "dpmpp_2m",
              "dpmpp_2m_sde",
              "dpmpp_2m_sde_gpu",
              "dpmpp_2s_ancestral",
              "dpmpp_3m_sde",
              "dpmpp_3m_sde_gpu",
              "dpmpp_sde",
              "dpmpp_sde_gpu",
              "euler",
              "euler_ancestral",
              "heun",
              "heunpp2",
              "lcm",
              "lms",
              "uni_pc",
              "uni_pc_bh2"
            ],
            "type_name": "nodetool.nodes.comfy.enums.Sampler"
          },
          "default": "euler_ancestral",
          "title": "Sampler"
        },
        {
          "name": "input_image",
          "type": {
            "type": "image"
          },
          "default": {},
          "title": "Input Image",
          "description": "Input image for img2img (optional)"
        },
        {
          "name": "mask_image",
          "type": {
            "type": "image"
          },
          "default": {},
          "title": "Mask Image",
          "description": "Mask image for img2img (optional)"
        },
        {
          "name": "grow_mask_by",
          "type": {
            "type": "int"
          },
          "default": 6,
          "title": "Grow Mask By",
          "min": 0.0,
          "max": 100.0
        },
        {
          "name": "denoise",
          "type": {
            "type": "float"
          },
          "default": 1.0,
          "title": "Denoise",
          "min": 0.0,
          "max": 1.0
        },
        {
          "name": "loras",
          "type": {
            "type": "list",
            "type_args": [
              {
                "type": "comfy.lora_config"
              }
            ]
          },
          "default": [],
          "title": "Loras",
          "description": "List of LoRA models to apply"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "the_model_info": {},
      "recommended_models": [
        {
          "type": "hf.stable_diffusion",
          "repo_id": "SG161222/Realistic_Vision_V5.1_noVAE",
          "path": "Realistic_Vision_V5.1_fp16-no-ema.safetensors"
        },
        {
          "type": "hf.stable_diffusion",
          "repo_id": "digiplay/majicMIX_realistic_v7",
          "path": "majicmixRealistic_v7.safetensors"
        },
        {
          "type": "hf.stable_diffusion",
          "repo_id": "philz1337x/epicrealism",
          "path": "epicrealism_naturalSinRC1VAE.safetensors"
        },
        {
          "type": "hf.stable_diffusion",
          "repo_id": "Lykon/DreamShaper",
          "path": "DreamShaper_5_beta2_noVae_half_pruned.safetensors"
        },
        {
          "type": "hf.stable_diffusion",
          "repo_id": "Lykon/DreamShaper",
          "path": "DreamShaper_4BakedVae_fp16.safetensors"
        },
        {
          "type": "hf.stable_diffusion",
          "repo_id": "XpucT/Deliberate",
          "path": "Deliberate_v6.safetensors"
        },
        {
          "type": "hf.stable_diffusion",
          "repo_id": "XpucT/Deliberate",
          "path": "Deliberate_v6-inpainting.safetensors"
        },
        {
          "type": "hf.stable_diffusion",
          "repo_id": "Lykon/AbsoluteReality",
          "path": "AbsoluteReality_1.8.1_pruned.safetensors"
        },
        {
          "type": "hf.stable_diffusion",
          "repo_id": "Lykon/AbsoluteReality",
          "path": "AbsoluteReality_1.8.1_INPAINTING.inpainting.safetensors"
        },
        {
          "type": "hf.stable_diffusion",
          "repo_id": "gsdf/Counterfeit-V2.5",
          "path": "Counterfeit-V2.5_fp16.safetensors"
        }
      ],
      "basic_fields": [
        "model",
        "prompt",
        "negative_prompt",
        "seed",
        "guidance_scale",
        "num_inference_steps",
        "width",
        "height",
        "scheduler",
        "sampler",
        "input_image",
        "mask_image",
        "grow_mask_by",
        "denoise",
        "loras"
      ],
      "is_dynamic": false
    },
    {
      "title": "Stable Diffusion 3.5",
      "description": "Generates images using Stable Diffusion 3.5 model.\n    image, text-to-image, generative, SD3.5\n    Generates images using Stable Diffusion 3 model.\n    image, text-to-image, generative, SD3\n\n    Use cases:\n    - Creating high-quality images with the latest SD3 model\n    - Generating detailed and coherent images from text descriptions\n    - Producing images with improved composition and understanding",
      "namespace": "comfy.basic",
      "node_type": "comfy.basic.StableDiffusion3",
      "layout": "default",
      "properties": [
        {
          "name": "model",
          "type": {
            "type": "hf.stable_diffusion_3"
          },
          "default": {},
          "title": "Model",
          "description": "The model to use."
        },
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to use."
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Negative Prompt",
          "description": "The negative prompt to use."
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": 0,
          "title": "Seed",
          "min": 0.0,
          "max": 1000000.0
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 4.0,
          "title": "Guidance Scale",
          "min": 1.0,
          "max": 30.0
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 20,
          "title": "Num Inference Steps",
          "min": 1.0,
          "max": 100.0
        },
        {
          "name": "width",
          "type": {
            "type": "int"
          },
          "default": 768,
          "title": "Width",
          "min": 64.0,
          "max": 2048.0
        },
        {
          "name": "height",
          "type": {
            "type": "int"
          },
          "default": 768,
          "title": "Height",
          "min": 64.0,
          "max": 2048.0
        },
        {
          "name": "scheduler",
          "type": {
            "type": "enum",
            "values": [
              "normal",
              "karras",
              "exponential",
              "sgm_uniform",
              "simple",
              "ddim_uniform",
              "beta",
              "linear_quadratic"
            ],
            "type_name": "nodetool.nodes.comfy.enums.Scheduler"
          },
          "default": "exponential",
          "title": "Scheduler"
        },
        {
          "name": "sampler",
          "type": {
            "type": "enum",
            "values": [
              "ddim",
              "ddpm",
              "dpm_2",
              "dpm_2_ancestral",
              "dpm_adaptive",
              "dpm_fast",
              "dpmpp_2m",
              "dpmpp_2m_sde",
              "dpmpp_2m_sde_gpu",
              "dpmpp_2s_ancestral",
              "dpmpp_3m_sde",
              "dpmpp_3m_sde_gpu",
              "dpmpp_sde",
              "dpmpp_sde_gpu",
              "euler",
              "euler_ancestral",
              "heun",
              "heunpp2",
              "lcm",
              "lms",
              "uni_pc",
              "uni_pc_bh2"
            ],
            "type_name": "nodetool.nodes.comfy.enums.Sampler"
          },
          "default": "euler_ancestral",
          "title": "Sampler"
        },
        {
          "name": "input_image",
          "type": {
            "type": "image"
          },
          "default": {},
          "title": "Input Image",
          "description": "Input image for img2img (optional)"
        },
        {
          "name": "mask_image",
          "type": {
            "type": "image"
          },
          "default": {},
          "title": "Mask Image",
          "description": "Mask image for img2img (optional)"
        },
        {
          "name": "grow_mask_by",
          "type": {
            "type": "int"
          },
          "default": 6,
          "title": "Grow Mask By",
          "min": 0.0,
          "max": 100.0
        },
        {
          "name": "denoise",
          "type": {
            "type": "float"
          },
          "default": 1.0,
          "title": "Denoise",
          "min": 0.0,
          "max": 1.0
        },
        {
          "name": "loras",
          "type": {
            "type": "list",
            "type_args": [
              {
                "type": "comfy.lora_config"
              }
            ]
          },
          "default": [],
          "title": "Loras",
          "description": "List of LoRA models to apply"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "the_model_info": {},
      "recommended_models": [
        {
          "type": "hf.stable_diffusion_3",
          "repo_id": "Comfy-Org/stable-diffusion-3.5-fp8",
          "path": "sd3.5_large_fp8_scaled.safetensors"
        }
      ],
      "basic_fields": [
        "model",
        "prompt",
        "negative_prompt",
        "seed",
        "guidance_scale",
        "num_inference_steps",
        "width",
        "height",
        "scheduler",
        "sampler",
        "input_image",
        "mask_image",
        "grow_mask_by",
        "denoise",
        "loras"
      ],
      "is_dynamic": false
    },
    {
      "title": "Stable Diffusion XL",
      "description": "Generates images using Stable Diffusion XL model.\n    image, text-to-image, generative AI, SDXL\n\n    Use cases:\n    - Creating high-quality images with the latest SDXL models\n    - Generating detailed and coherent images from text descriptions\n    - Producing images with improved composition and understanding",
      "namespace": "comfy.basic",
      "node_type": "comfy.basic.StableDiffusionXL",
      "layout": "default",
      "properties": [
        {
          "name": "model",
          "type": {
            "type": "hf.stable_diffusion_xl"
          },
          "default": {},
          "title": "Model",
          "description": "The model to use."
        },
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to use."
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Negative Prompt",
          "description": "The negative prompt to use."
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": 0,
          "title": "Seed",
          "min": 0.0,
          "max": 1000000.0
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 7.0,
          "title": "Guidance Scale",
          "min": 1.0,
          "max": 30.0
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 30,
          "title": "Num Inference Steps",
          "min": 1.0,
          "max": 100.0
        },
        {
          "name": "width",
          "type": {
            "type": "int"
          },
          "default": 768,
          "title": "Width",
          "min": 64.0,
          "max": 2048.0
        },
        {
          "name": "height",
          "type": {
            "type": "int"
          },
          "default": 768,
          "title": "Height",
          "min": 64.0,
          "max": 2048.0
        },
        {
          "name": "scheduler",
          "type": {
            "type": "enum",
            "values": [
              "normal",
              "karras",
              "exponential",
              "sgm_uniform",
              "simple",
              "ddim_uniform",
              "beta",
              "linear_quadratic"
            ],
            "type_name": "nodetool.nodes.comfy.enums.Scheduler"
          },
          "default": "exponential",
          "title": "Scheduler"
        },
        {
          "name": "sampler",
          "type": {
            "type": "enum",
            "values": [
              "ddim",
              "ddpm",
              "dpm_2",
              "dpm_2_ancestral",
              "dpm_adaptive",
              "dpm_fast",
              "dpmpp_2m",
              "dpmpp_2m_sde",
              "dpmpp_2m_sde_gpu",
              "dpmpp_2s_ancestral",
              "dpmpp_3m_sde",
              "dpmpp_3m_sde_gpu",
              "dpmpp_sde",
              "dpmpp_sde_gpu",
              "euler",
              "euler_ancestral",
              "heun",
              "heunpp2",
              "lcm",
              "lms",
              "uni_pc",
              "uni_pc_bh2"
            ],
            "type_name": "nodetool.nodes.comfy.enums.Sampler"
          },
          "default": "euler_ancestral",
          "title": "Sampler"
        },
        {
          "name": "input_image",
          "type": {
            "type": "image"
          },
          "default": {},
          "title": "Input Image",
          "description": "Input image for img2img (optional)"
        },
        {
          "name": "mask_image",
          "type": {
            "type": "image"
          },
          "default": {},
          "title": "Mask Image",
          "description": "Mask image for img2img (optional)"
        },
        {
          "name": "grow_mask_by",
          "type": {
            "type": "int"
          },
          "default": 6,
          "title": "Grow Mask By",
          "min": 0.0,
          "max": 100.0
        },
        {
          "name": "denoise",
          "type": {
            "type": "float"
          },
          "default": 1.0,
          "title": "Denoise",
          "min": 0.0,
          "max": 1.0
        },
        {
          "name": "loras",
          "type": {
            "type": "list",
            "type_args": [
              {
                "type": "comfy.lora_config"
              }
            ]
          },
          "default": [],
          "title": "Loras",
          "description": "List of LoRA models to apply"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "the_model_info": {},
      "recommended_models": [
        {
          "type": "hf.stable_diffusion_xl",
          "repo_id": "stabilityai/stable-diffusion-xl-base-1.0",
          "path": "sd_xl_base_1.0.safetensors"
        },
        {
          "type": "hf.stable_diffusion_xl",
          "repo_id": "stabilityai/stable-diffusion-xl-refiner-1.0",
          "path": "sd_xl_refiner_1.0.safetensors"
        },
        {
          "type": "hf.stable_diffusion_xl",
          "repo_id": "playgroundai/playground-v2.5-1024px-aesthetic",
          "path": "playground-v2.5-1024px-aesthetic.fp16.safetensors"
        },
        {
          "type": "hf.stable_diffusion_xl",
          "repo_id": "RunDiffusion/Juggernaut-XL-v9",
          "path": "Juggernaut-XL_v9_RunDiffusionPhoto_v2.safetensors"
        },
        {
          "type": "hf.stable_diffusion_xl",
          "repo_id": "dataautogpt3/ProteusV0.5",
          "path": "proteusV0.5.safetensors"
        },
        {
          "type": "hf.stable_diffusion_xl",
          "repo_id": "Lykon/dreamshaper-xl-lightning",
          "path": "DreamShaperXL_Lightning.safetensors"
        },
        {
          "type": "hf.stable_diffusion_xl",
          "repo_id": "Lykon/AAM_XL_AnimeMix",
          "path": "AAM_XL_Anime_Mix.safetensors"
        },
        {
          "type": "hf.stable_diffusion_xl",
          "repo_id": "stabilityai/sdxl-turbo",
          "path": "sd_xl_turbo_1.0_fp16.safetensors"
        },
        {
          "type": "hf.stable_diffusion_xl",
          "repo_id": "Lykon/dreamshaper-xl-v2-turbo",
          "path": "DreamShaperXL_Turbo_v2_1.safetensors"
        }
      ],
      "basic_fields": [
        "model",
        "prompt",
        "negative_prompt",
        "seed",
        "guidance_scale",
        "num_inference_steps",
        "width",
        "height",
        "scheduler",
        "sampler",
        "input_image",
        "mask_image",
        "grow_mask_by",
        "denoise",
        "loras"
      ],
      "is_dynamic": false
    },
    {
      "title": "CLIPSet Last Layer",
      "description": "The CLIP Set Last Layer node can be used to set the CLIP output layer from which to take the text embeddings. Encoding text into an embedding happens by the text being transformed by various layers in the CLIP model. Although traditionally diffusion models are conditioned on the output of the last layer in CLIP, some diffusion models have been conditioned on earlier layers and might not work as well when using the output of the last layer.",
      "namespace": "comfy.conditioning",
      "node_type": "comfy.conditioning.CLIPSetLastLayer",
      "layout": "default",
      "properties": [
        {
          "name": "clip",
          "type": {
            "type": "comfy.clip"
          },
          "default": {},
          "title": "Clip",
          "description": "The CLIP model to modify."
        },
        {
          "name": "stop_at_clip_layer",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Stop At Clip Layer",
          "description": "The index of the last CLIP layer to use.",
          "min": -24.0,
          "max": -1.0
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "comfy.clip"
          },
          "name": "clip"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "clip",
        "stop_at_clip_layer"
      ],
      "is_dynamic": false
    },
    {
      "title": "CLIP Text Encode (Prompt)",
      "description": "The CLIP Text Encode node can be used to encode a text prompt using a CLIP model into an embedding that can be used to guide the diffusion model towards generating specific images.",
      "namespace": "comfy.conditioning",
      "node_type": "comfy.conditioning.CLIPTextEncode",
      "layout": "default",
      "properties": [
        {
          "name": "text",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Text",
          "description": "The prompt to use."
        },
        {
          "name": "clip",
          "type": {
            "type": "comfy.clip"
          },
          "default": {},
          "title": "Clip",
          "description": "The CLIP model to use."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "comfy.conditioning"
          },
          "name": "conditioning"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "text",
        "clip"
      ],
      "is_dynamic": false
    },
    {
      "title": "CLIPVision Encode",
      "description": "The CLIP Vision Encode node can be used to encode an image using a CLIP vision model into an embedding that can be used to guide unCLIP diffusion models or as input to style models.",
      "namespace": "comfy.conditioning",
      "node_type": "comfy.conditioning.CLIPVisionEncode",
      "layout": "default",
      "properties": [
        {
          "name": "clip_vision",
          "type": {
            "type": "comfy.clip_vision"
          },
          "default": {},
          "title": "Clip Vision",
          "description": "The CLIP vision model to use for encoding."
        },
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {},
          "title": "Image",
          "description": "The image to encode with the CLIP vision model."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "comfy.clip_vision_output"
          },
          "name": "clip_vision_output"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "clip_vision",
        "image"
      ],
      "is_dynamic": false
    },
    {
      "title": "Conditioning (Average)",
      "description": "The Conditioning (Average) node can be used to interpolate between two text embeddings according to a strength factor set in conditioning_to_strength.",
      "namespace": "comfy.conditioning",
      "node_type": "comfy.conditioning.ConditioningAverage",
      "layout": "default",
      "properties": [
        {
          "name": "conditioning_to",
          "type": {
            "type": "comfy.conditioning"
          },
          "default": {},
          "title": "Conditioning To",
          "description": "The target conditioning."
        },
        {
          "name": "conditioning_from",
          "type": {
            "type": "comfy.conditioning"
          },
          "default": {},
          "title": "Conditioning From",
          "description": "The source conditioning."
        },
        {
          "name": "conditioning_to_strength",
          "type": {
            "type": "float"
          },
          "default": 1.0,
          "title": "Conditioning To Strength",
          "description": "The strength of the target conditioning."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "comfy.conditioning"
          },
          "name": "conditioning"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "conditioning_to",
        "conditioning_from",
        "conditioning_to_strength"
      ],
      "is_dynamic": false
    },
    {
      "title": "Conditioning (Combine)",
      "description": "The Conditioning (Combine) node can be used to combine multiple conditionings by averaging the predicted noise of the diffusion model. Note that this is different from the Conditioning (Average) node. Here outputs of the diffusion model conditioned on different conditionings (i.e. all parts that make up the conditioning) are averaged out, while the Conditioning (Average) node interpolates the text embeddings that are stored inside the conditioning.",
      "namespace": "comfy.conditioning",
      "node_type": "comfy.conditioning.ConditioningCombine",
      "layout": "default",
      "properties": [
        {
          "name": "conditioning_1",
          "type": {
            "type": "comfy.conditioning"
          },
          "default": {},
          "title": "Conditioning 1",
          "description": "The first conditioning input."
        },
        {
          "name": "conditioning_2",
          "type": {
            "type": "comfy.conditioning"
          },
          "default": {},
          "title": "Conditioning 2",
          "description": "The second conditioning input."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "comfy.conditioning"
          },
          "name": "conditioning"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "conditioning_1",
        "conditioning_2"
      ],
      "is_dynamic": false
    },
    {
      "title": "Conditioning (Concat)",
      "description": "The Conditioning (Concat) node can be used to concatenate two conditionings. This allows for combining different conditioning inputs sequentially, which can be useful for creating more complex guidance for the diffusion model.",
      "namespace": "comfy.conditioning",
      "node_type": "comfy.conditioning.ConditioningConcat",
      "layout": "default",
      "properties": [
        {
          "name": "conditioning_to",
          "type": {
            "type": "comfy.conditioning"
          },
          "default": {},
          "title": "Conditioning To",
          "description": "The conditioning to concatenate to."
        },
        {
          "name": "conditioning_from",
          "type": {
            "type": "comfy.conditioning"
          },
          "default": {},
          "title": "Conditioning From",
          "description": "The conditioning to concatenate from."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "comfy.conditioning"
          },
          "name": "conditioning"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "conditioning_to",
        "conditioning_from"
      ],
      "is_dynamic": false
    },
    {
      "title": "Conditioning (Set Area)",
      "description": "The Conditioning (Set Area) node can be used to limit a conditioning to a specified area of the image. Together with the Conditioning (Combine) node this can be used to add more control over the composition of the final image.",
      "namespace": "comfy.conditioning",
      "node_type": "comfy.conditioning.ConditioningSetArea",
      "layout": "default",
      "properties": [
        {
          "name": "conditioning",
          "type": {
            "type": "comfy.conditioning"
          },
          "default": {},
          "title": "Conditioning",
          "description": "The conditioning to modify."
        },
        {
          "name": "width",
          "type": {
            "type": "int"
          },
          "default": 64,
          "title": "Width",
          "description": "The width of the area.",
          "min": 64.0,
          "max": 16384.0
        },
        {
          "name": "height",
          "type": {
            "type": "int"
          },
          "default": 64,
          "title": "Height",
          "description": "The height of the area.",
          "min": 64.0,
          "max": 16384.0
        },
        {
          "name": "x",
          "type": {
            "type": "int"
          },
          "default": 0,
          "title": "X",
          "description": "The x-coordinate of the top-left corner of the area.",
          "min": 0.0,
          "max": 16384.0
        },
        {
          "name": "y",
          "type": {
            "type": "int"
          },
          "default": 0,
          "title": "Y",
          "description": "The y-coordinate of the top-left corner of the area.",
          "min": 0.0,
          "max": 16384.0
        },
        {
          "name": "strength",
          "type": {
            "type": "float"
          },
          "default": 1.0,
          "title": "Strength",
          "description": "The strength of the conditioning in the set area.",
          "min": 0.0,
          "max": 10.0
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "comfy.conditioning"
          },
          "name": "conditioning"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "conditioning",
        "width",
        "height",
        "x",
        "y",
        "strength"
      ],
      "is_dynamic": false
    },
    {
      "title": "Conditioning (Set Area with Percentage)",
      "description": "",
      "namespace": "comfy.conditioning",
      "node_type": "comfy.conditioning.ConditioningSetAreaPercentage",
      "layout": "default",
      "properties": [
        {
          "name": "conditioning",
          "type": {
            "type": "comfy.conditioning"
          },
          "default": {},
          "title": "Conditioning",
          "description": "The conditioning to modify."
        },
        {
          "name": "width",
          "type": {
            "type": "float"
          },
          "default": 1.0,
          "title": "Width",
          "description": "The width of the area as a percentage of the total width.",
          "min": 0.0,
          "max": 1.0
        },
        {
          "name": "height",
          "type": {
            "type": "float"
          },
          "default": 1.0,
          "title": "Height",
          "description": "The height of the area as a percentage of the total height.",
          "min": 0.0,
          "max": 1.0
        },
        {
          "name": "x",
          "type": {
            "type": "float"
          },
          "default": 0.0,
          "title": "X",
          "description": "The x-coordinate of the top-left corner of the area as a percentage.",
          "min": 0.0,
          "max": 1.0
        },
        {
          "name": "y",
          "type": {
            "type": "float"
          },
          "default": 0.0,
          "title": "Y",
          "description": "The y-coordinate of the top-left corner of the area as a percentage.",
          "min": 0.0,
          "max": 1.0
        },
        {
          "name": "strength",
          "type": {
            "type": "float"
          },
          "default": 1.0,
          "title": "Strength",
          "description": "The strength of the conditioning in the set area.",
          "min": 0.0,
          "max": 10.0
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "comfy.conditioning"
          },
          "name": "conditioning"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "conditioning",
        "width",
        "height",
        "x",
        "y",
        "strength"
      ],
      "is_dynamic": false
    },
    {
      "title": "Conditioning (Set Mask)",
      "description": "The Conditioning (Set Mask) node can be used to limit a conditioning to a specified mask. Together with the Conditioning (Combine) node this can be used to add more control over the composition of the final image.",
      "namespace": "comfy.conditioning",
      "node_type": "comfy.conditioning.ConditioningSetMask",
      "layout": "default",
      "properties": [
        {
          "name": "conditioning",
          "type": {
            "type": "comfy.conditioning"
          },
          "default": {},
          "title": "Conditioning",
          "description": "The conditioning to modify."
        },
        {
          "name": "mask",
          "type": {
            "type": "comfy.mask"
          },
          "default": {},
          "title": "Mask",
          "description": "The mask to use for setting the conditioning."
        },
        {
          "name": "strength",
          "type": {
            "type": "float"
          },
          "default": 1.0,
          "title": "Strength",
          "description": "The strength of the conditioning within the mask.",
          "min": 0.0,
          "max": 10.0
        },
        {
          "name": "set_cond_area",
          "type": {
            "type": "enum",
            "values": [
              "default",
              "mask bounds"
            ],
            "type_name": "nodetool.nodes.comfy.conditioning.SetConditioningAreaEnum"
          },
          "default": "default",
          "title": "Set Cond Area",
          "description": "Method to determine the area for setting conditioning."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "comfy.conditioning"
          },
          "name": "conditioning"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "conditioning",
        "mask",
        "strength",
        "set_cond_area"
      ],
      "is_dynamic": false
    },
    {
      "title": "Conditioning (Set Timestep Range)",
      "description": "",
      "namespace": "comfy.conditioning",
      "node_type": "comfy.conditioning.ConditioningSetTimestepRange",
      "layout": "default",
      "properties": [
        {
          "name": "conditioning",
          "type": {
            "type": "comfy.conditioning"
          },
          "default": {},
          "title": "Conditioning",
          "description": "The conditioning to set timestep range."
        },
        {
          "name": "start",
          "type": {
            "type": "float"
          },
          "default": 0.0,
          "title": "Start",
          "description": "The start of the timestep range.",
          "min": 0.0,
          "max": 1.0
        },
        {
          "name": "end",
          "type": {
            "type": "float"
          },
          "default": 1.0,
          "title": "End",
          "description": "The end of the timestep range.",
          "min": 0.0,
          "max": 1.0
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "comfy.conditioning"
          },
          "name": "conditioning"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "conditioning",
        "start",
        "end"
      ],
      "is_dynamic": false
    },
    {
      "title": "Conditioning (Zero Out)",
      "description": "The Conditioning (Zero Out) node can be used to zero out a conditioning. This effectively removes the influence of the conditioning on the diffusion process, which can be useful for creating areas of the image that are not influenced by the prompt or other conditioning inputs.",
      "namespace": "comfy.conditioning",
      "node_type": "comfy.conditioning.ConditioningZeroOut",
      "layout": "default",
      "properties": [
        {
          "name": "conditioning",
          "type": {
            "type": "comfy.conditioning"
          },
          "default": {},
          "title": "Conditioning",
          "description": "The conditioning to be zeroed out."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "comfy.conditioning"
          },
          "name": "conditioning"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "conditioning"
      ],
      "is_dynamic": false
    },
    {
      "title": "Apply ControlNet",
      "description": "The Apply ControlNet node can be used to provide further visual guidance to a diffusion model. Unlike unCLIP embeddings, controlnets and T2I adaptors work on any model. By chaining together multiple nodes it is possible to guide the diffusion model using multiple controlNets or T2I adaptors. This can be useful to e.g. hint at the diffusion model where the edges in the final image should be by providing an image containing edge detections along with a controlNet trained on edge detection images to this node.",
      "namespace": "comfy.conditioning",
      "node_type": "comfy.conditioning.ControlNetApply",
      "layout": "default",
      "properties": [
        {
          "name": "conditioning",
          "type": {
            "type": "comfy.conditioning"
          },
          "default": {},
          "title": "Conditioning",
          "description": "The conditioning to apply."
        },
        {
          "name": "control_net",
          "type": {
            "type": "comfy.control_net"
          },
          "default": {},
          "title": "Control Net",
          "description": "The control net to apply."
        },
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": "",
          "title": "Image",
          "description": "The image to apply to."
        },
        {
          "name": "strength",
          "type": {
            "type": "float"
          },
          "default": 1.0,
          "title": "Strength",
          "description": "The strength of the controlnet."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "comfy.conditioning"
          },
          "name": "conditioning"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "conditioning",
        "control_net",
        "image",
        "strength"
      ],
      "is_dynamic": false
    },
    {
      "title": "Apply ControlNet (Advanced)",
      "description": "The Apply ControlNet (Advanced) node provides more fine-grained control over the application of a ControlNet to the diffusion process. It allows for separate positive and negative conditioning, as well as control over the strength and range of application of the ControlNet.",
      "namespace": "comfy.conditioning",
      "node_type": "comfy.conditioning.ControlNetApplyAdvanced",
      "layout": "default",
      "properties": [
        {
          "name": "positive",
          "type": {
            "type": "comfy.conditioning"
          },
          "default": {},
          "title": "Positive",
          "description": "The positive conditioning to apply."
        },
        {
          "name": "negative",
          "type": {
            "type": "comfy.conditioning"
          },
          "default": {},
          "title": "Negative",
          "description": "The negative conditioning to apply."
        },
        {
          "name": "control_net",
          "type": {
            "type": "comfy.control_net"
          },
          "default": {},
          "title": "Control Net",
          "description": "The ControlNet to use."
        },
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {},
          "title": "Image",
          "description": "The image to apply conditioning adjustments to."
        },
        {
          "name": "strength",
          "type": {
            "type": "float"
          },
          "default": 1.0,
          "title": "Strength",
          "description": "The strength of conditioning.",
          "min": 0.0,
          "max": 10.0
        },
        {
          "name": "start_percent",
          "type": {
            "type": "float"
          },
          "default": 0.0,
          "title": "Start Percent",
          "description": "The start percentage from which to apply conditioning.",
          "min": 0.0,
          "max": 1.0
        },
        {
          "name": "end_percent",
          "type": {
            "type": "float"
          },
          "default": 1.0,
          "title": "End Percent",
          "description": "The end percentage until which to apply conditioning.",
          "min": 0.0,
          "max": 1.0
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "comfy.conditioning"
          },
          "name": "conditioning"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "positive",
        "negative",
        "control_net",
        "image",
        "strength",
        "start_percent",
        "end_percent"
      ],
      "is_dynamic": false
    },
    {
      "title": "GLIGENText Box Apply",
      "description": "The GLIGEN Textbox Apply node can be used to provide further spatial guidance to a diffusion model, guiding it to generate the specified parts of the prompt in a specific region of the image. Although the text input will accept any text, GLIGEN works best if the input to it is an object that is part of the text prompt.",
      "namespace": "comfy.conditioning",
      "node_type": "comfy.conditioning.GLIGENTextBoxApply",
      "layout": "default",
      "properties": [
        {
          "name": "conditioning_to",
          "type": {
            "type": "comfy.conditioning"
          },
          "default": {},
          "title": "Conditioning To",
          "description": "The input conditioning to modify."
        },
        {
          "name": "clip",
          "type": {
            "type": "comfy.clip"
          },
          "default": {},
          "title": "Clip",
          "description": "The CLIP instance to use."
        },
        {
          "name": "gligen_textbox_model",
          "type": {
            "type": "comfy.gligen"
          },
          "default": {},
          "title": "Gligen Textbox Model",
          "description": "The GLIGEN textbox model to apply."
        },
        {
          "name": "text",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Text",
          "description": "The text to apply."
        },
        {
          "name": "width",
          "type": {
            "type": "int"
          },
          "default": 64,
          "title": "Width",
          "description": "The width of the text box.",
          "min": 8.0,
          "max": 16384.0
        },
        {
          "name": "height",
          "type": {
            "type": "int"
          },
          "default": 64,
          "title": "Height",
          "description": "The height of the text box.",
          "min": 8.0,
          "max": 16384.0
        },
        {
          "name": "x",
          "type": {
            "type": "int"
          },
          "default": 0,
          "title": "X",
          "description": "The x position of the text box.",
          "min": 0.0,
          "max": 16384.0
        },
        {
          "name": "y",
          "type": {
            "type": "int"
          },
          "default": 0,
          "title": "Y",
          "description": "The y position of the text box.",
          "min": 0.0,
          "max": 16384.0
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "comfy.conditioning"
          },
          "name": "conditioning"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "conditioning_to",
        "clip",
        "gligen_textbox_model",
        "text",
        "width",
        "height",
        "x",
        "y"
      ],
      "is_dynamic": false
    },
    {
      "title": "Inpaint Model Conditioning",
      "description": "The Inpaint Model Conditioning node prepares conditioning for inpainting models by combining the input image, mask, and conditioning information.",
      "namespace": "comfy.conditioning",
      "node_type": "comfy.conditioning.InpaintModelConditioning",
      "layout": "default",
      "properties": [
        {
          "name": "positive",
          "type": {
            "type": "comfy.conditioning"
          },
          "default": {},
          "title": "Positive",
          "description": "The positive conditioning to apply."
        },
        {
          "name": "negative",
          "type": {
            "type": "comfy.conditioning"
          },
          "default": {},
          "title": "Negative",
          "description": "The negative conditioning to apply."
        },
        {
          "name": "vae",
          "type": {
            "type": "comfy.vae"
          },
          "default": {},
          "title": "Vae",
          "description": "The VAE model to use."
        },
        {
          "name": "pixels",
          "type": {
            "type": "image"
          },
          "default": {},
          "title": "Pixels",
          "description": "The input image to inpaint."
        },
        {
          "name": "mask",
          "type": {
            "type": "comfy.mask"
          },
          "default": {},
          "title": "Mask",
          "description": "The mask indicating areas to inpaint."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "comfy.conditioning"
          },
          "name": "positive"
        },
        {
          "type": {
            "type": "comfy.conditioning"
          },
          "name": "negative"
        },
        {
          "type": {
            "type": "comfy.latent"
          },
          "name": "latent"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "positive",
        "negative",
        "vae",
        "pixels",
        "mask"
      ],
      "is_dynamic": false
    },
    {
      "title": "LTXV Conditioning",
      "description": "Sets frame rate in the conditioning for LTXV video models.\n    conditioning, ltxv, frame rate\n\n    Use cases:\n    - Specify frame rate for video models\n    - Adjust temporal aspects of video generation\n    - Prepare conditioning for LTXV models",
      "namespace": "comfy.conditioning",
      "node_type": "comfy.conditioning.LTXVConditioning",
      "layout": "default",
      "properties": [
        {
          "name": "positive",
          "type": {
            "type": "comfy.conditioning"
          },
          "default": {},
          "title": "Positive",
          "description": "Positive conditioning."
        },
        {
          "name": "negative",
          "type": {
            "type": "comfy.conditioning"
          },
          "default": {},
          "title": "Negative",
          "description": "Negative conditioning."
        },
        {
          "name": "frame_rate",
          "type": {
            "type": "float"
          },
          "default": 25.0,
          "title": "Frame Rate",
          "description": "Frame rate for video generation.",
          "min": 0.0,
          "max": 1000.0
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "comfy.conditioning"
          },
          "name": "positive"
        },
        {
          "type": {
            "type": "comfy.conditioning"
          },
          "name": "negative"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "positive",
        "negative",
        "frame_rate"
      ],
      "is_dynamic": false
    },
    {
      "title": "LTXV Image to Video",
      "description": "Converts an input image to a video latent, applying conditioning.\n    image, video, latent, ltxv\n\n    Use cases:\n    - Initialize video generation from an image\n    - Prepare conditioning for LTXV video models\n    - Transition from image to video in latent space",
      "namespace": "comfy.conditioning",
      "node_type": "comfy.conditioning.LTXVImgToVideo",
      "layout": "default",
      "properties": [
        {
          "name": "positive",
          "type": {
            "type": "comfy.conditioning"
          },
          "default": {},
          "title": "Positive",
          "description": "Positive conditioning."
        },
        {
          "name": "negative",
          "type": {
            "type": "comfy.conditioning"
          },
          "default": {},
          "title": "Negative",
          "description": "Negative conditioning."
        },
        {
          "name": "vae",
          "type": {
            "type": "comfy.vae"
          },
          "default": {},
          "title": "Vae",
          "description": "VAE model to use."
        },
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {},
          "title": "Image",
          "description": "Input image."
        },
        {
          "name": "width",
          "type": {
            "type": "int"
          },
          "default": 768,
          "title": "Width",
          "description": "Width of the output video.",
          "min": 64.0,
          "max": 16384.0
        },
        {
          "name": "height",
          "type": {
            "type": "int"
          },
          "default": 512,
          "title": "Height",
          "description": "Height of the output video.",
          "min": 64.0,
          "max": 16384.0
        },
        {
          "name": "length",
          "type": {
            "type": "int"
          },
          "default": 97,
          "title": "Length",
          "description": "Length (frames) of the video.",
          "min": 9.0,
          "max": 16384.0
        },
        {
          "name": "batch_size",
          "type": {
            "type": "int"
          },
          "default": 1,
          "title": "Batch Size",
          "description": "Batch size.",
          "min": 1.0,
          "max": 4096.0
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "comfy.conditioning"
          },
          "name": "positive"
        },
        {
          "type": {
            "type": "comfy.conditioning"
          },
          "name": "negative"
        },
        {
          "type": {
            "type": "comfy.latent"
          },
          "name": "latent"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "positive",
        "negative",
        "vae",
        "image",
        "width",
        "height",
        "length",
        "batch_size"
      ],
      "is_dynamic": false
    },
    {
      "title": "SVD img 2 vid Conditioning",
      "description": "The SVD Image to Video Conditioning node prepares conditioning for transforming a single image into a video sequence. It utilizes CLIP vision encoding and VAE processing to create appropriate conditioning for video generation models.",
      "namespace": "comfy.conditioning",
      "node_type": "comfy.conditioning.SVD_img2vid_Conditioning",
      "layout": "default",
      "properties": [
        {
          "name": "clip_vision",
          "type": {
            "type": "comfy.clip_vision"
          },
          "default": {},
          "title": "Clip Vision",
          "description": "The CLIP vision model to use."
        },
        {
          "name": "init_image",
          "type": {
            "type": "image"
          },
          "default": {},
          "title": "Init Image",
          "description": "The initial image to condition on."
        },
        {
          "name": "vae",
          "type": {
            "type": "comfy.vae"
          },
          "default": {},
          "title": "Vae",
          "description": "The VAE model to use."
        },
        {
          "name": "width",
          "type": {
            "type": "int"
          },
          "default": 1024,
          "title": "Width",
          "description": "The width of the output.",
          "min": 16.0,
          "max": 16384.0
        },
        {
          "name": "height",
          "type": {
            "type": "int"
          },
          "default": 576,
          "title": "Height",
          "description": "The height of the output.",
          "min": 16.0,
          "max": 16384.0
        },
        {
          "name": "video_frames",
          "type": {
            "type": "int"
          },
          "default": 14,
          "title": "Video Frames",
          "description": "The number of video frames to generate.",
          "min": 1.0,
          "max": 4096.0
        },
        {
          "name": "motion_bucket_id",
          "type": {
            "type": "int"
          },
          "default": 127,
          "title": "Motion Bucket Id",
          "description": "The motion bucket ID.",
          "min": 1.0,
          "max": 1023.0
        },
        {
          "name": "fps",
          "type": {
            "type": "int"
          },
          "default": 6,
          "title": "Fps",
          "description": "Frames per second.",
          "min": 1.0,
          "max": 1024.0
        },
        {
          "name": "augmentation_level",
          "type": {
            "type": "float"
          },
          "default": 0.0,
          "title": "Augmentation Level",
          "description": "The level of augmentation to apply.",
          "min": 0.0,
          "max": 10.0
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "comfy.conditioning"
          },
          "name": "positive"
        },
        {
          "type": {
            "type": "comfy.conditioning"
          },
          "name": "negative"
        },
        {
          "type": {
            "type": "comfy.latent"
          },
          "name": "latent"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "clip_vision",
        "init_image",
        "vae",
        "width",
        "height",
        "video_frames",
        "motion_bucket_id",
        "fps",
        "augmentation_level"
      ],
      "is_dynamic": false
    },
    {
      "title": "Apply Style Model",
      "description": "The Style Model Apply node applies a style model to the conditioning using CLIP vision output,\n    allowing for style transfer effects in the generation process.",
      "namespace": "comfy.conditioning",
      "node_type": "comfy.conditioning.StyleModelApply",
      "layout": "default",
      "properties": [
        {
          "name": "conditioning",
          "type": {
            "type": "comfy.conditioning"
          },
          "default": {},
          "title": "Conditioning",
          "description": "The conditioning to modify."
        },
        {
          "name": "style_model",
          "type": {
            "type": "comfy.style_model"
          },
          "default": {},
          "title": "Style Model",
          "description": "The style model to apply."
        },
        {
          "name": "clip_vision_output",
          "type": {
            "type": "comfy.clip_vision_output"
          },
          "default": {},
          "title": "Clip Vision Output",
          "description": "The CLIP vision output to use for styling."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "comfy.conditioning"
          },
          "name": "conditioning"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "conditioning",
        "style_model",
        "clip_vision_output"
      ],
      "is_dynamic": false
    },
    {
      "title": "un CLIPConditioning",
      "description": "The unCLIP Conditioning node can be used to incorporate CLIP vision output into the conditioning process. This allows for image-guided generation, where the content and style of an input image can influence the output of the diffusion model.",
      "namespace": "comfy.conditioning",
      "node_type": "comfy.conditioning.unCLIPConditioning",
      "layout": "default",
      "properties": [
        {
          "name": "conditioning",
          "type": {
            "type": "comfy.conditioning"
          },
          "default": {},
          "title": "Conditioning",
          "description": "The conditioning to modify."
        },
        {
          "name": "clip_vision_output",
          "type": {
            "type": "comfy.clip_vision_output"
          },
          "default": {},
          "title": "Clip Vision Output",
          "description": "The CLIP vision output to associate."
        },
        {
          "name": "strength",
          "type": {
            "type": "float"
          },
          "default": 1.0,
          "title": "Strength",
          "description": "The strength of the association with the CLIP vision output.",
          "min": -10.0,
          "max": 10.0
        },
        {
          "name": "noise_augmentation",
          "type": {
            "type": "float"
          },
          "default": 0.0,
          "title": "Noise Augmentation",
          "description": "The amount of noise augmentation to apply.",
          "min": 0.0,
          "max": 1.0
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "comfy.conditioning"
          },
          "name": "conditioning"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "conditioning",
        "clip_vision_output",
        "strength",
        "noise_augmentation"
      ],
      "is_dynamic": false
    },
    {
      "title": "CLIP Text Encode Flux",
      "description": "The CLIP Text Encode Flux node can be used to encode a text prompt using a CLIP model into an embedding that can be used to guide the diffusion model towards generating specific images.",
      "namespace": "comfy.flux",
      "node_type": "comfy.flux.CLIPTextEncodeFlux",
      "layout": "default",
      "properties": [
        {
          "name": "clip",
          "type": {
            "type": "comfy.clip"
          },
          "default": {},
          "title": "Clip",
          "description": "The CLIP model to use for encoding."
        },
        {
          "name": "clip_l",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Clip L",
          "description": "The text to encode."
        },
        {
          "name": "t5xxl",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "T5Xxl",
          "description": "The text to encode."
        },
        {
          "name": "guidance",
          "type": {
            "type": "float"
          },
          "default": 3.5,
          "title": "Guidance",
          "description": "The guidance value to use for encoding."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "comfy.conditioning"
          },
          "name": "conditioning"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "clip",
        "clip_l",
        "t5xxl",
        "guidance"
      ],
      "is_dynamic": false
    },
    {
      "title": "Flux Guidance",
      "description": "The Flux Guidance node can be used to append guidance to a conditioning.",
      "namespace": "comfy.flux",
      "node_type": "comfy.flux.FluxGuidance",
      "layout": "default",
      "properties": [
        {
          "name": "conditioning",
          "type": {
            "type": "comfy.conditioning"
          },
          "default": {},
          "title": "Conditioning",
          "description": "The conditioning to append guidance to."
        },
        {
          "name": "guidance",
          "type": {
            "type": "float"
          },
          "default": 3.5,
          "title": "Guidance",
          "description": "The guidance value to append."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "comfy.conditioning"
          },
          "name": "conditioning"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "conditioning",
        "guidance"
      ],
      "is_dynamic": false
    },
    {
      "title": "Hyper Tile",
      "description": "",
      "namespace": "comfy._for_testing",
      "node_type": "comfy._for_testing.HyperTile",
      "layout": "default",
      "properties": [
        {
          "name": "model",
          "type": {
            "type": "comfy.unet"
          },
          "default": {},
          "title": "Model",
          "description": "The model to use for generating hyper-tiles."
        },
        {
          "name": "tile_size",
          "type": {
            "type": "int"
          },
          "default": 256,
          "title": "Tile Size",
          "description": "The size of the tile to generate."
        },
        {
          "name": "swap_size",
          "type": {
            "type": "int"
          },
          "default": 2,
          "title": "Swap Size",
          "description": "The swap size used during generation."
        },
        {
          "name": "max_depth",
          "type": {
            "type": "int"
          },
          "default": 0,
          "title": "Max Depth",
          "description": "The maximum depth for tiling."
        },
        {
          "name": "scale_depth",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Scale Depth",
          "description": "Whether to scale the depth progressively."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "comfy.unet"
          },
          "name": "unet"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "model",
        "tile_size",
        "swap_size",
        "max_depth",
        "scale_depth"
      ],
      "is_dynamic": false
    },
    {
      "title": "CLIP Text Encode SD3",
      "description": "Encodes text using CLIP for the SD3 model.",
      "namespace": "comfy.advanced.loaders",
      "node_type": "comfy.advanced.loaders.CLIPTextEncodeSD3",
      "layout": "default",
      "properties": [
        {
          "name": "clip",
          "type": {
            "type": "comfy.clip"
          },
          "default": {},
          "title": "Clip",
          "description": "The CLIP model to use for encoding."
        },
        {
          "name": "clip_l",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Clip L",
          "description": "The local text to encode."
        },
        {
          "name": "clip_g",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Clip G",
          "description": "The global text to encode."
        },
        {
          "name": "t5xxl",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "T5Xxl",
          "description": "The T5-XXL text to encode."
        },
        {
          "name": "empty_padding",
          "type": {
            "type": "enum",
            "values": [
              "none",
              "empty_prompt"
            ],
            "type_name": "nodetool.nodes.comfy.advanced.loaders.EmptyPaddingEnum"
          },
          "default": "none",
          "title": "Empty Padding",
          "description": "The empty padding method."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "comfy.conditioning"
          },
          "name": "conditioning"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "clip",
        "clip_l",
        "clip_g",
        "t5xxl",
        "empty_padding"
      ],
      "is_dynamic": false
    },
    {
      "title": "ControlNet Apply SD3",
      "description": "Applies a ControlNet to the image.",
      "namespace": "comfy.advanced.loaders",
      "node_type": "comfy.advanced.loaders.ControlNetApplySD3",
      "layout": "default",
      "properties": [
        {
          "name": "positive",
          "type": {
            "type": "comfy.conditioning"
          },
          "default": {},
          "title": "Positive",
          "description": "The positive conditioning."
        },
        {
          "name": "negative",
          "type": {
            "type": "comfy.conditioning"
          },
          "default": {},
          "title": "Negative",
          "description": "The negative conditioning."
        },
        {
          "name": "control_net",
          "type": {
            "type": "comfy.control_net"
          },
          "default": {},
          "title": "Control Net",
          "description": "The ControlNet to apply."
        },
        {
          "name": "vae",
          "type": {
            "type": "comfy.vae"
          },
          "default": {},
          "title": "Vae",
          "description": "The VAE to use."
        },
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {},
          "title": "Image",
          "description": "The image to apply the ControlNet to."
        },
        {
          "name": "strength",
          "type": {
            "type": "float"
          },
          "default": 1.0,
          "title": "Strength",
          "description": "The strength of the ControlNet application.",
          "min": 0.0,
          "max": 10.0
        },
        {
          "name": "start_percent",
          "type": {
            "type": "float"
          },
          "default": 0.0,
          "title": "Start Percent",
          "description": "The start percentage for the ControlNet application.",
          "min": 0.0,
          "max": 1.0
        },
        {
          "name": "end_percent",
          "type": {
            "type": "float"
          },
          "default": 1.0,
          "title": "End Percent",
          "description": "The end percentage for the ControlNet application.",
          "min": 0.0,
          "max": 1.0
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "comfy.conditioning"
          },
          "name": "positive"
        },
        {
          "type": {
            "type": "comfy.conditioning"
          },
          "name": "negative"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "positive",
        "negative",
        "control_net",
        "vae",
        "image",
        "strength",
        "start_percent",
        "end_percent"
      ],
      "is_dynamic": false
    },
    {
      "title": "Triple CLIP Loader",
      "description": "Loads three CLIP models.",
      "namespace": "comfy.advanced.loaders",
      "node_type": "comfy.advanced.loaders.TripleCLIPLoader",
      "layout": "default",
      "properties": [
        {
          "name": "clip_name1",
          "type": {
            "type": "str"
          },
          "title": "Clip Name1",
          "description": "The name of the first CLIP model to load."
        },
        {
          "name": "clip_name2",
          "type": {
            "type": "str"
          },
          "title": "Clip Name2",
          "description": "The name of the second CLIP model to load."
        },
        {
          "name": "clip_name3",
          "type": {
            "type": "str"
          },
          "title": "Clip Name3",
          "description": "The name of the third CLIP model to load."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "comfy.clip"
          },
          "name": "clip"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "clip_name1",
        "clip_name2",
        "clip_name3"
      ],
      "is_dynamic": false
    },
    {
      "title": "Model Sampling Aura Flow",
      "description": "Patches a model for Aura Flow sampling.\n    advanced, model, sampling, aura, flow\n\n    Use cases:\n    - Apply Aura Flow sampling to a model\n    - Adjust shift parameters for Aura Flow sampling",
      "namespace": "comfy.advanced.model",
      "node_type": "comfy.advanced.model.ModelSamplingAuraFlow",
      "layout": "default",
      "properties": [
        {
          "name": "model",
          "type": {
            "type": "comfy.unet"
          },
          "default": {},
          "title": "Model",
          "description": "The model to patch."
        },
        {
          "name": "shift",
          "type": {
            "type": "float"
          },
          "default": 1.73,
          "title": "Shift",
          "description": "The shift parameter.",
          "min": 0.0,
          "max": 100.0
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "comfy.unet"
          },
          "name": "model"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "model",
        "shift"
      ],
      "is_dynamic": false
    },
    {
      "title": "Model Sampling Base",
      "description": "",
      "namespace": "comfy.advanced.model",
      "node_type": "comfy.advanced.model.ModelSamplingBase",
      "layout": "default",
      "properties": [],
      "outputs": [
        {
          "type": {
            "type": "comfy.unet"
          },
          "name": "model"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [],
      "is_dynamic": false
    },
    {
      "title": "Model Sampling Continuous EDM",
      "description": "Patches a model for continuous EDM sampling.\n    advanced, model, sampling, edm, continuous\n\n    Use cases:\n    - Apply continuous EDM sampling to a model\n    - Adjust sigma parameters for continuous EDM sampling",
      "namespace": "comfy.advanced.model",
      "node_type": "comfy.advanced.model.ModelSamplingContinuousEDM",
      "layout": "default",
      "properties": [
        {
          "name": "model",
          "type": {
            "type": "comfy.unet"
          },
          "default": {},
          "title": "Model",
          "description": "The model to patch."
        },
        {
          "name": "sampling",
          "type": {
            "type": "enum",
            "values": [
              "v_prediction",
              "edm_playground_v2.5",
              "eps"
            ],
            "type_name": "nodetool.nodes.comfy.advanced.model.SamplingEnumEDM"
          },
          "default": "v_prediction",
          "title": "Sampling",
          "description": "The sampling method to use."
        },
        {
          "name": "sigma_max",
          "type": {
            "type": "float"
          },
          "default": 120.0,
          "title": "Sigma Max",
          "description": "The maximum sigma value.",
          "min": 0.0,
          "max": 1000.0
        },
        {
          "name": "sigma_min",
          "type": {
            "type": "float"
          },
          "default": 0.002,
          "title": "Sigma Min",
          "description": "The minimum sigma value.",
          "min": 0.0,
          "max": 1000.0
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "comfy.unet"
          },
          "name": "model"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "model",
        "sampling",
        "sigma_max",
        "sigma_min"
      ],
      "is_dynamic": false
    },
    {
      "title": "Model Sampling Continuous V",
      "description": "Patches a model for continuous V sampling.\n    advanced, model, sampling, v, continuous\n\n    Use cases:\n    - Apply continuous V sampling to a model\n    - Adjust sigma parameters for continuous V sampling",
      "namespace": "comfy.advanced.model",
      "node_type": "comfy.advanced.model.ModelSamplingContinuousV",
      "layout": "default",
      "properties": [
        {
          "name": "model",
          "type": {
            "type": "comfy.unet"
          },
          "default": {},
          "title": "Model",
          "description": "The model to patch."
        },
        {
          "name": "sampling",
          "type": {
            "type": "enum",
            "values": [
              "v_prediction",
              "edm_playground_v2.5",
              "eps"
            ],
            "type_name": "nodetool.nodes.comfy.advanced.model.SamplingEnumEDM"
          },
          "default": "v_prediction",
          "title": "Sampling",
          "description": "The sampling method to use."
        },
        {
          "name": "sigma_max",
          "type": {
            "type": "float"
          },
          "default": 500.0,
          "title": "Sigma Max",
          "description": "The maximum sigma value.",
          "min": 0.0,
          "max": 1000.0
        },
        {
          "name": "sigma_min",
          "type": {
            "type": "float"
          },
          "default": 0.03,
          "title": "Sigma Min",
          "description": "The minimum sigma value.",
          "min": 0.0,
          "max": 1000.0
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "comfy.unet"
          },
          "name": "model"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "model",
        "sampling",
        "sigma_max",
        "sigma_min"
      ],
      "is_dynamic": false
    },
    {
      "title": "Model Sampling Discrete",
      "description": "Patches a model for discrete sampling.\n    advanced, model, sampling, discrete\n\n    Use cases:\n    - Apply different sampling methods to a model\n    - Enable zero SNR sampling",
      "namespace": "comfy.advanced.model",
      "node_type": "comfy.advanced.model.ModelSamplingDiscrete",
      "layout": "default",
      "properties": [
        {
          "name": "model",
          "type": {
            "type": "comfy.unet"
          },
          "default": {},
          "title": "Model",
          "description": "The model to patch."
        },
        {
          "name": "sampling",
          "type": {
            "type": "enum",
            "values": [
              "eps",
              "v_prediction",
              "lcm",
              "x0"
            ],
            "type_name": "nodetool.nodes.comfy.advanced.model.SamplingEnum"
          },
          "default": "eps",
          "title": "Sampling",
          "description": "The sampling method to use."
        },
        {
          "name": "zsnr",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Zsnr",
          "description": "Whether to use zero SNR."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "comfy.unet"
          },
          "name": "model"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "model",
        "sampling",
        "zsnr"
      ],
      "is_dynamic": false
    },
    {
      "title": "Model Sampling Flux",
      "description": "Patches a model for Flux sampling.\n    advanced, model, sampling, flux\n\n    Use cases:\n    - Apply Flux sampling to a model\n    - Adjust shift parameters for Flux sampling",
      "namespace": "comfy.advanced.model",
      "node_type": "comfy.advanced.model.ModelSamplingFlux",
      "layout": "default",
      "properties": [
        {
          "name": "model",
          "type": {
            "type": "comfy.unet"
          },
          "default": {},
          "title": "Model",
          "description": "The model to patch."
        },
        {
          "name": "max_shift",
          "type": {
            "type": "float"
          },
          "default": 1.15,
          "title": "Max Shift",
          "description": "The maximum shift parameter.",
          "min": 0.0,
          "max": 100.0
        },
        {
          "name": "base_shift",
          "type": {
            "type": "float"
          },
          "default": 0.5,
          "title": "Base Shift",
          "description": "The base shift parameter.",
          "min": 0.0,
          "max": 100.0
        },
        {
          "name": "width",
          "type": {
            "type": "int"
          },
          "default": 1024,
          "title": "Width",
          "description": "The width of the image.",
          "min": 16.0,
          "max": 16384.0
        },
        {
          "name": "height",
          "type": {
            "type": "int"
          },
          "default": 1024,
          "title": "Height",
          "description": "The height of the image.",
          "min": 16.0,
          "max": 16384.0
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "comfy.unet"
          },
          "name": "model"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "model",
        "max_shift",
        "base_shift",
        "width",
        "height"
      ],
      "is_dynamic": false
    },
    {
      "title": "Model Sampling LTXV",
      "description": "Patches a model for LTXV sampling.\n    advanced, model, sampling, ltxv\n\n    Use cases:\n    - Modify a model for LTXV sampling\n    - Adjust shift parameters based on latent tokens\n    - Enable advanced sampling techniques",
      "namespace": "comfy.advanced.model",
      "node_type": "comfy.advanced.model.ModelSamplingLTXV",
      "layout": "default",
      "properties": [
        {
          "name": "model",
          "type": {
            "type": "comfy.unet"
          },
          "title": "Model",
          "description": "The model to patch."
        },
        {
          "name": "max_shift",
          "type": {
            "type": "float"
          },
          "default": 2.05,
          "title": "Max Shift",
          "description": "Maximum shift parameter.",
          "min": 0.0,
          "max": 100.0
        },
        {
          "name": "base_shift",
          "type": {
            "type": "float"
          },
          "default": 0.95,
          "title": "Base Shift",
          "description": "Base shift parameter.",
          "min": 0.0,
          "max": 100.0
        },
        {
          "name": "latent",
          "type": {
            "type": "comfy.latent"
          },
          "title": "Latent",
          "description": "Optional latent input."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "comfy.unet"
          },
          "name": "model"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "model",
        "max_shift",
        "base_shift",
        "latent"
      ],
      "is_dynamic": false
    },
    {
      "title": "Model Sampling SD3",
      "description": "Patches a model for SD3 sampling.\n    advanced, model, sampling, sd3\n\n    Use cases:\n    - Apply SD3 sampling to a model\n    - Adjust shift parameters for SD3 sampling",
      "namespace": "comfy.advanced.model",
      "node_type": "comfy.advanced.model.ModelSamplingSD3",
      "layout": "default",
      "properties": [
        {
          "name": "model",
          "type": {
            "type": "comfy.unet"
          },
          "default": {},
          "title": "Model",
          "description": "The model to patch."
        },
        {
          "name": "shift",
          "type": {
            "type": "float"
          },
          "default": 3.0,
          "title": "Shift",
          "description": "The shift parameter.",
          "min": 0.0,
          "max": 100.0
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "comfy.unet"
          },
          "name": "model"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "model",
        "shift"
      ],
      "is_dynamic": false
    },
    {
      "title": "Model Sampling Stable Cascade",
      "description": "Patches a model for stable cascade sampling.\n    advanced, model, sampling, stable, cascade\n\n    Use cases:\n    - Apply stable cascade sampling to a model\n    - Adjust shift parameters for stable cascade sampling",
      "namespace": "comfy.advanced.model",
      "node_type": "comfy.advanced.model.ModelSamplingStableCascade",
      "layout": "default",
      "properties": [
        {
          "name": "model",
          "type": {
            "type": "comfy.unet"
          },
          "default": {},
          "title": "Model",
          "description": "The model to patch."
        },
        {
          "name": "shift",
          "type": {
            "type": "float"
          },
          "default": 2.0,
          "title": "Shift",
          "description": "The shift parameter.",
          "min": 0.0,
          "max": 100.0
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "comfy.unet"
          },
          "name": "model"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "model",
        "shift"
      ],
      "is_dynamic": false
    },
    {
      "title": "Rescale CFG",
      "description": "Patches a model for rescale CFG.\n    advanced, model, rescale, cfg\n\n    Use cases:\n    - Adjust the CFG multiplier for a model\n    - Apply rescale CFG to a model",
      "namespace": "comfy.advanced.model",
      "node_type": "comfy.advanced.model.RescaleCFG",
      "layout": "default",
      "properties": [
        {
          "name": "model",
          "type": {
            "type": "comfy.unet"
          },
          "default": {},
          "title": "Model",
          "description": "The model to patch."
        },
        {
          "name": "multiplier",
          "type": {
            "type": "float"
          },
          "default": 0.7,
          "title": "Multiplier",
          "description": "The rescale multiplier.",
          "min": 0.0,
          "max": 1.0
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "comfy.unet"
          },
          "name": "model"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "model",
        "multiplier"
      ],
      "is_dynamic": false
    },
    {
      "title": "CLIPText Encode SDXL",
      "description": "Encodes text using CLIP for the base SDXL model.\n    clip, text, encode, sdxl, base\n\n    Use cases:\n    - Prepare text prompts for base SDXL model\n    - Handle separate global and local text prompts\n    - Generate conditionings with specific crop and target dimensions",
      "namespace": "comfy.advanced.conditioning",
      "node_type": "comfy.advanced.conditioning.CLIPTextEncodeSDXL",
      "layout": "default",
      "properties": [
        {
          "name": "width",
          "type": {
            "type": "int"
          },
          "default": 1024,
          "title": "Width",
          "description": "The width to use.",
          "max": 2048.0
        },
        {
          "name": "height",
          "type": {
            "type": "int"
          },
          "default": 1024,
          "title": "Height",
          "description": "The height to use.",
          "max": 2048.0
        },
        {
          "name": "crop_w",
          "type": {
            "type": "int"
          },
          "default": 0,
          "title": "Crop W",
          "description": "The crop width to use.",
          "max": 2048.0
        },
        {
          "name": "crop_h",
          "type": {
            "type": "int"
          },
          "default": 0,
          "title": "Crop H",
          "description": "The crop height to use.",
          "max": 2048.0
        },
        {
          "name": "target_width",
          "type": {
            "type": "int"
          },
          "default": 1024,
          "title": "Target Width",
          "description": "The target width to use.",
          "max": 2048.0
        },
        {
          "name": "target_height",
          "type": {
            "type": "int"
          },
          "default": 1024,
          "title": "Target Height",
          "description": "The target height to use.",
          "max": 2048.0
        },
        {
          "name": "text_g",
          "type": {
            "type": "str"
          },
          "default": "CLIP_G",
          "title": "Text G",
          "description": "The global text to encode."
        },
        {
          "name": "text_l",
          "type": {
            "type": "str"
          },
          "default": "CLIP_L",
          "title": "Text L",
          "description": "The local text to encode."
        },
        {
          "name": "clip",
          "type": {
            "type": "comfy.clip"
          },
          "default": {},
          "title": "Clip",
          "description": "The CLIP to use."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "comfy.conditioning"
          },
          "name": "conditioning"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "width",
        "height",
        "crop_w",
        "crop_h",
        "target_width",
        "target_height",
        "text_g",
        "text_l",
        "clip"
      ],
      "is_dynamic": false
    },
    {
      "title": "CLIPText Encode SDXLRefiner",
      "description": "Encodes text using CLIP for the SDXL refiner model.\n    clip, text, encode, sdxl, refiner\n\n    Use cases:\n    - Prepare text prompts for SDXL refiner model\n    - Incorporate aesthetic scores in text encoding\n    - Generate conditionings for high-resolution image refinement",
      "namespace": "comfy.advanced.conditioning",
      "node_type": "comfy.advanced.conditioning.CLIPTextEncodeSDXLRefiner",
      "layout": "default",
      "properties": [
        {
          "name": "ascore",
          "type": {
            "type": "float"
          },
          "default": 6.0,
          "title": "Ascore",
          "description": "The ascore to use."
        },
        {
          "name": "width",
          "type": {
            "type": "int"
          },
          "default": 1024,
          "title": "Width",
          "description": "The width to use.",
          "max": 2048.0
        },
        {
          "name": "height",
          "type": {
            "type": "int"
          },
          "default": 1024,
          "title": "Height",
          "description": "The height to use.",
          "max": 2048.0
        },
        {
          "name": "text",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Text",
          "description": "The text to encode."
        },
        {
          "name": "clip",
          "type": {
            "type": "comfy.clip"
          },
          "default": {},
          "title": "Clip",
          "description": "The CLIP to use."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "comfy.conditioning"
          },
          "name": "conditioning"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "ascore",
        "width",
        "height",
        "text",
        "clip"
      ],
      "is_dynamic": false
    },
    {
      "title": "Preprocess Image",
      "description": "",
      "namespace": "comfy.controlnet.__init__",
      "node_type": "comfy.controlnet.__init__.PreprocessImage",
      "layout": "default",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {},
          "title": "Image",
          "description": "The image to preprocess."
        },
        {
          "name": "resolution",
          "type": {
            "type": "int"
          },
          "default": 512,
          "title": "Resolution",
          "description": "The width of the image to generate.",
          "min": 64.0,
          "max": 16384.0
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "image"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "image",
        "resolution"
      ],
      "is_dynamic": false
    },
    {
      "title": "Anime Line Art Preprocessor",
      "description": "Preprocesses an image for anime lineart.",
      "namespace": "comfy.controlnet.line_extractors",
      "node_type": "comfy.controlnet.line_extractors.AnimeLineArtPreprocessor",
      "layout": "default",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {},
          "title": "Image",
          "description": "The image to preprocess."
        },
        {
          "name": "resolution",
          "type": {
            "type": "int"
          },
          "default": 512,
          "title": "Resolution",
          "description": "The width of the image to generate.",
          "min": 64.0,
          "max": 16384.0
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "image"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "image",
        "resolution"
      ],
      "is_dynamic": false
    },
    {
      "title": "Any Line Preprocessor",
      "description": "Preprocesses an image for any lineart.",
      "namespace": "comfy.controlnet.line_extractors",
      "node_type": "comfy.controlnet.line_extractors.AnyLinePreprocessor",
      "layout": "default",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {},
          "title": "Image",
          "description": "The image to preprocess."
        },
        {
          "name": "resolution",
          "type": {
            "type": "int"
          },
          "default": 512,
          "title": "Resolution",
          "description": "The width of the image to generate.",
          "min": 64.0,
          "max": 16384.0
        },
        {
          "name": "merge_with_lineart",
          "type": {
            "type": "str"
          },
          "default": "lineart_standard",
          "title": "Merge With Lineart",
          "description": "The lineart to merge with."
        },
        {
          "name": "lineart_lower_bound",
          "type": {
            "type": "float"
          },
          "default": 0,
          "title": "Lineart Lower Bound",
          "description": "The lower bound for lineart."
        },
        {
          "name": "lineart_upper_bound",
          "type": {
            "type": "float"
          },
          "default": 1,
          "title": "Lineart Upper Bound",
          "description": "The upper bound for lineart."
        },
        {
          "name": "object_min_size",
          "type": {
            "type": "int"
          },
          "default": 36,
          "title": "Object Min Size",
          "description": "The minimum size for objects."
        },
        {
          "name": "object_connectivity",
          "type": {
            "type": "int"
          },
          "default": 1,
          "title": "Object Connectivity",
          "description": "The connectivity for objects."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "image"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "image",
        "resolution",
        "merge_with_lineart",
        "lineart_lower_bound",
        "lineart_upper_bound",
        "object_min_size",
        "object_connectivity"
      ],
      "is_dynamic": false
    },
    {
      "title": "Binary Preprocessor",
      "description": "",
      "namespace": "comfy.controlnet.line_extractors",
      "node_type": "comfy.controlnet.line_extractors.BinaryPreprocessor",
      "layout": "default",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {},
          "title": "Image",
          "description": "The image to preprocess."
        },
        {
          "name": "resolution",
          "type": {
            "type": "int"
          },
          "default": 512,
          "title": "Resolution",
          "description": "The width of the image to generate.",
          "min": 64.0,
          "max": 16384.0
        },
        {
          "name": "bin_threshold",
          "type": {
            "type": "int"
          },
          "default": 100,
          "title": "Bin Threshold",
          "description": "The threshold for the binary image.",
          "min": 0.0,
          "max": 255.0
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "image"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "image",
        "resolution",
        "bin_threshold"
      ],
      "is_dynamic": false
    },
    {
      "title": "Canny Edge Preprocessor",
      "description": "Preprocesses an image for canny edge detection.",
      "namespace": "comfy.controlnet.line_extractors",
      "node_type": "comfy.controlnet.line_extractors.CannyEdgePreprocessor",
      "layout": "default",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {},
          "title": "Image",
          "description": "The image to preprocess."
        },
        {
          "name": "resolution",
          "type": {
            "type": "int"
          },
          "default": 512,
          "title": "Resolution",
          "description": "The width of the image to generate.",
          "min": 64.0,
          "max": 16384.0
        },
        {
          "name": "low_threshold",
          "type": {
            "type": "int"
          },
          "default": 100,
          "title": "Low Threshold",
          "description": "The low threshold to use."
        },
        {
          "name": "high_threshold",
          "type": {
            "type": "int"
          },
          "default": 200,
          "title": "High Threshold",
          "description": "The high threshold to use."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "image"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "image",
        "resolution",
        "low_threshold",
        "high_threshold"
      ],
      "is_dynamic": false
    },
    {
      "title": "Diffusion Edge Preprocessor",
      "description": "Preprocesses an image for diffusion edge detection.",
      "namespace": "comfy.controlnet.line_extractors",
      "node_type": "comfy.controlnet.line_extractors.DiffusionEdge_Preprocessor",
      "layout": "default",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {},
          "title": "Image",
          "description": "The image to preprocess."
        },
        {
          "name": "resolution",
          "type": {
            "type": "int"
          },
          "default": 512,
          "title": "Resolution",
          "description": "The width of the image to generate.",
          "min": 64.0,
          "max": 16384.0
        },
        {
          "name": "environment",
          "type": {
            "type": "enum",
            "values": [
              "indoor",
              "urban",
              "neutral"
            ],
            "type_name": "nodetool.nodes.comfy.controlnet.line_extractors.DiffusionEdge_Preprocessor_Environment"
          },
          "default": "indoor",
          "title": "Environment",
          "description": "The environment to use."
        },
        {
          "name": "patch_batch_size",
          "type": {
            "type": "int"
          },
          "default": 4,
          "title": "Patch Batch Size",
          "description": "The patch batch size to use.",
          "min": 1.0,
          "max": 16.0
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "image"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "image",
        "resolution",
        "environment",
        "patch_batch_size"
      ],
      "is_dynamic": false
    },
    {
      "title": "HEDPreprocessor",
      "description": "Preprocesses an image for HED lineart.",
      "namespace": "comfy.controlnet.line_extractors",
      "node_type": "comfy.controlnet.line_extractors.HEDPreprocessor",
      "layout": "default",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {},
          "title": "Image",
          "description": "The image to preprocess."
        },
        {
          "name": "resolution",
          "type": {
            "type": "int"
          },
          "default": 512,
          "title": "Resolution",
          "description": "The width of the image to generate.",
          "min": 64.0,
          "max": 16384.0
        },
        {
          "name": "safe",
          "type": {
            "type": "enum",
            "values": [
              "enable",
              "disable"
            ],
            "type_name": "nodetool.nodes.comfy.controlnet.line_extractors.SafeMode"
          },
          "default": "enable",
          "title": "Safe",
          "description": "Whether to use safe mode."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "image"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "image",
        "resolution",
        "safe"
      ],
      "is_dynamic": false
    },
    {
      "title": "Lineart Preprocessor",
      "description": "",
      "namespace": "comfy.controlnet.line_extractors",
      "node_type": "comfy.controlnet.line_extractors.LineartPreprocessor",
      "layout": "default",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {},
          "title": "Image",
          "description": "The image to preprocess."
        },
        {
          "name": "resolution",
          "type": {
            "type": "int"
          },
          "default": 512,
          "title": "Resolution",
          "description": "The width of the image to generate.",
          "min": 64.0,
          "max": 16384.0
        },
        {
          "name": "coarse",
          "type": {
            "type": "enum",
            "values": [
              "enable",
              "disable"
            ],
            "type_name": "nodetool.nodes.comfy.comfy_node.EnableDisable"
          },
          "default": "disable",
          "title": "Coarse",
          "description": "Whether to use coarse lineart."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "image"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "image",
        "resolution",
        "coarse"
      ],
      "is_dynamic": false
    },
    {
      "title": "Lineart Standard Preprocessor",
      "description": "Preprocesses an image for standard lineart.",
      "namespace": "comfy.controlnet.line_extractors",
      "node_type": "comfy.controlnet.line_extractors.LineartStandardPreprocessor",
      "layout": "default",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {},
          "title": "Image",
          "description": "The image to preprocess."
        },
        {
          "name": "resolution",
          "type": {
            "type": "int"
          },
          "default": 512,
          "title": "Resolution",
          "description": "The width of the image to generate.",
          "min": 64.0,
          "max": 16384.0
        },
        {
          "name": "guassian_sigma",
          "type": {
            "type": "float"
          },
          "default": 6.0,
          "title": "Guassian Sigma",
          "description": "The Gaussian sigma value for preprocessing."
        },
        {
          "name": "intensity_threshold",
          "type": {
            "type": "int"
          },
          "default": 8,
          "title": "Intensity Threshold",
          "description": "The intensity threshold value for preprocessing."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "image"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "image",
        "resolution",
        "guassian_sigma",
        "intensity_threshold"
      ],
      "is_dynamic": false
    },
    {
      "title": "Manga 2 Anime Line Art Preprocessor",
      "description": "Preprocesses an image for manga to anime lineart.",
      "namespace": "comfy.controlnet.line_extractors",
      "node_type": "comfy.controlnet.line_extractors.Manga2Anime_LineArt_Preprocessor",
      "layout": "default",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {},
          "title": "Image",
          "description": "The image to preprocess."
        },
        {
          "name": "resolution",
          "type": {
            "type": "int"
          },
          "default": 512,
          "title": "Resolution",
          "description": "The width of the image to generate.",
          "min": 64.0,
          "max": 16384.0
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "image"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "image",
        "resolution"
      ],
      "is_dynamic": false
    },
    {
      "title": "Pi Di Net Preprocessor",
      "description": "Preprocesses an image for PiDiNet lineart.",
      "namespace": "comfy.controlnet.line_extractors",
      "node_type": "comfy.controlnet.line_extractors.PiDiNetPreprocessor",
      "layout": "default",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {},
          "title": "Image",
          "description": "The image to preprocess."
        },
        {
          "name": "resolution",
          "type": {
            "type": "int"
          },
          "default": 512,
          "title": "Resolution",
          "description": "The width of the image to generate.",
          "min": 64.0,
          "max": 16384.0
        },
        {
          "name": "safe",
          "type": {
            "type": "enum",
            "values": [
              "enable",
              "disable"
            ],
            "type_name": "nodetool.nodes.comfy.comfy_node.EnableDisable"
          },
          "default": "enable",
          "title": "Safe"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "image"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "image",
        "resolution",
        "safe"
      ],
      "is_dynamic": false
    },
    {
      "title": "Scribble Preprocessor",
      "description": "Preprocesses an image for scribble lineart.",
      "namespace": "comfy.controlnet.line_extractors",
      "node_type": "comfy.controlnet.line_extractors.ScribblePreprocessor",
      "layout": "default",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {},
          "title": "Image",
          "description": "The image to preprocess."
        },
        {
          "name": "resolution",
          "type": {
            "type": "int"
          },
          "default": 512,
          "title": "Resolution",
          "description": "The width of the image to generate.",
          "min": 64.0,
          "max": 16384.0
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "image"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "image",
        "resolution"
      ],
      "is_dynamic": false
    },
    {
      "title": "Scribble XDo GPreprocessor",
      "description": "Preprocesses an image for scribble lineart.",
      "namespace": "comfy.controlnet.line_extractors",
      "node_type": "comfy.controlnet.line_extractors.ScribbleXDoGPreprocessor",
      "layout": "default",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {},
          "title": "Image",
          "description": "The image to preprocess."
        },
        {
          "name": "resolution",
          "type": {
            "type": "int"
          },
          "default": 512,
          "title": "Resolution",
          "description": "The width of the image to generate.",
          "min": 64.0,
          "max": 16384.0
        },
        {
          "name": "threshold",
          "type": {
            "type": "float"
          },
          "default": 32,
          "title": "Threshold",
          "min": 1.0,
          "max": 64.0
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "image"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "image",
        "resolution",
        "threshold"
      ],
      "is_dynamic": false
    },
    {
      "title": "Anime Face Sem Seg Preprocessor",
      "description": "AnimeFace semantic segmentation preprocessor.",
      "namespace": "comfy.controlnet.semantic_segmentation",
      "node_type": "comfy.controlnet.semantic_segmentation.AnimeFace_SemSegPreprocessor",
      "layout": "default",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {},
          "title": "Image",
          "description": "The image to preprocess."
        },
        {
          "name": "resolution",
          "type": {
            "type": "int"
          },
          "default": 512,
          "title": "Resolution",
          "description": "The width of the image to generate.",
          "min": 512.0,
          "max": 512.0
        },
        {
          "name": "remove_background_using_abgr",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Remove Background Using Abgr",
          "description": "Whether to remove the background."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "image"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "image",
        "resolution",
        "remove_background_using_abgr"
      ],
      "is_dynamic": false
    },
    {
      "title": "One Former COCOSem Seg Preprocessor",
      "description": "OneFormer COCO semantic segmentation preprocessor.",
      "namespace": "comfy.controlnet.semantic_segmentation",
      "node_type": "comfy.controlnet.semantic_segmentation.OneFormerCOCOSemSegPreprocessor",
      "layout": "default",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {},
          "title": "Image",
          "description": "The image to preprocess."
        },
        {
          "name": "resolution",
          "type": {
            "type": "int"
          },
          "default": 512,
          "title": "Resolution",
          "description": "The width of the image to generate.",
          "min": 64.0,
          "max": 16384.0
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "image"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "image",
        "resolution"
      ],
      "is_dynamic": false
    },
    {
      "title": "One Former ADE 20 K Sem Seg Preprocessor",
      "description": "OneFormer ADE20K semantic segmentation preprocessor.",
      "namespace": "comfy.controlnet.semantic_segmentation",
      "node_type": "comfy.controlnet.semantic_segmentation.OneFormer_ADE20K_SemSegPreprocessor",
      "layout": "default",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {},
          "title": "Image",
          "description": "The image to preprocess."
        },
        {
          "name": "resolution",
          "type": {
            "type": "int"
          },
          "default": 512,
          "title": "Resolution",
          "description": "The width of the image to generate.",
          "min": 64.0,
          "max": 16384.0
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "image"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "image",
        "resolution"
      ],
      "is_dynamic": false
    },
    {
      "title": "SAMPreprocessor",
      "description": "SAM preprocessor.",
      "namespace": "comfy.controlnet.semantic_segmentation",
      "node_type": "comfy.controlnet.semantic_segmentation.SAMPreprocessor",
      "layout": "default",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {},
          "title": "Image",
          "description": "The image to preprocess."
        },
        {
          "name": "resolution",
          "type": {
            "type": "int"
          },
          "default": 512,
          "title": "Resolution",
          "description": "The width of the image to generate.",
          "min": 64.0,
          "max": 16384.0
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "image"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "image",
        "resolution"
      ],
      "is_dynamic": false
    },
    {
      "title": "Uniformer Sem Seg Preprocessor",
      "description": "Uniformer semantic segmentation preprocessor.",
      "namespace": "comfy.controlnet.semantic_segmentation",
      "node_type": "comfy.controlnet.semantic_segmentation.UniformerSemSegPreprocessor",
      "layout": "default",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {},
          "title": "Image",
          "description": "The image to preprocess."
        },
        {
          "name": "resolution",
          "type": {
            "type": "int"
          },
          "default": 512,
          "title": "Resolution",
          "description": "The width of the image to generate.",
          "min": 64.0,
          "max": 16384.0
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "image"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "image",
        "resolution"
      ],
      "is_dynamic": false
    },
    {
      "title": "DWPose Preprocessor",
      "description": "Estimates poses from an image.\n    controlnet, faces_and_poses, dw_pose",
      "namespace": "comfy.controlnet.faces_and_poses",
      "node_type": "comfy.controlnet.faces_and_poses.DWPose_Preprocessor",
      "layout": "default",
      "properties": [
        {
          "name": "detect_hand",
          "type": {
            "type": "enum",
            "values": [
              "enable",
              "disable"
            ],
            "type_name": "nodetool.nodes.comfy.controlnet.faces_and_poses.Toggle"
          },
          "default": "enable",
          "title": "Detect Hand",
          "description": "Toggle to enable or disable hand detection."
        },
        {
          "name": "detect_body",
          "type": {
            "type": "enum",
            "values": [
              "enable",
              "disable"
            ],
            "type_name": "nodetool.nodes.comfy.controlnet.faces_and_poses.Toggle"
          },
          "default": "enable",
          "title": "Detect Body",
          "description": "Toggle to enable or disable body detection."
        },
        {
          "name": "detect_face",
          "type": {
            "type": "enum",
            "values": [
              "enable",
              "disable"
            ],
            "type_name": "nodetool.nodes.comfy.controlnet.faces_and_poses.Toggle"
          },
          "default": "enable",
          "title": "Detect Face",
          "description": "Toggle to enable or disable face detection."
        },
        {
          "name": "bbox_detector",
          "type": {
            "type": "enum",
            "values": [
              "yolox_l.torchscript.pt",
              "yolox_l.onnx",
              "yolo_nas_l_fp16.onnx",
              "yolo_nas_m_fp16.onnx",
              "yolo_nas_s_fp16.onnx"
            ],
            "type_name": "nodetool.nodes.comfy.controlnet.faces_and_poses.BBoxDetectorModel"
          },
          "default": "yolox_l.torchscript.pt",
          "title": "Bbox Detector",
          "description": "The bounding box detector model to use."
        },
        {
          "name": "pose_estimator",
          "type": {
            "type": "enum",
            "values": [
              "dw-ll_ucoco_384_bs5.torchscript.pt",
              "dw-ll_ucoco_384.onnx",
              "dw-ll_ucoco.onnx"
            ],
            "type_name": "nodetool.nodes.comfy.controlnet.faces_and_poses.PoseEstimatorModel"
          },
          "default": "dw-ll_ucoco_384_bs5.torchscript.pt",
          "title": "Pose Estimator",
          "description": "The pose estimator model to use."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "type"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "detect_hand",
        "detect_body",
        "detect_face",
        "bbox_detector",
        "pose_estimator"
      ],
      "is_dynamic": false
    },
    {
      "title": "Dense Pose Preprocessor",
      "description": "Estimates dense poses from an image.\n    controlnet, faces_and_poses, densepose",
      "namespace": "comfy.controlnet.faces_and_poses",
      "node_type": "comfy.controlnet.faces_and_poses.DensePosePreprocessor",
      "layout": "default",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {},
          "title": "Image",
          "description": "The image to preprocess."
        },
        {
          "name": "resolution",
          "type": {
            "type": "int"
          },
          "default": 512,
          "title": "Resolution",
          "description": "The width of the image to generate.",
          "min": 64.0,
          "max": 16384.0
        },
        {
          "name": "model",
          "type": {
            "type": "enum",
            "values": [
              "densepose_r50_fpn_dl.torchscript",
              "densepose_r101_fpn_dl.torchscript"
            ],
            "type_name": "nodetool.nodes.comfy.comfy_node.DensePoseModel"
          },
          "default": "densepose_r50_fpn_dl.torchscript",
          "title": "Model",
          "description": "The model to use."
        },
        {
          "name": "cmap",
          "type": {
            "type": "enum",
            "values": [
              "Viridis (MagicAnimate)",
              "Parula (CivitAI)"
            ],
            "type_name": "nodetool.nodes.comfy.controlnet.faces_and_poses.DensePoseCMap"
          },
          "default": "Viridis (MagicAnimate)",
          "title": "Cmap",
          "description": "The color map to use."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "image"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "image",
        "resolution",
        "model",
        "cmap"
      ],
      "is_dynamic": false
    },
    {
      "title": "Openpose Preprocessor",
      "description": "Estimates poses from an image.\n    controlnet, faces_and_poses, openpose",
      "namespace": "comfy.controlnet.faces_and_poses",
      "node_type": "comfy.controlnet.faces_and_poses.OpenposePreprocessor",
      "layout": "default",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {},
          "title": "Image",
          "description": "The image to preprocess."
        },
        {
          "name": "resolution",
          "type": {
            "type": "int"
          },
          "default": 512,
          "title": "Resolution",
          "description": "The width of the image to generate.",
          "min": 64.0,
          "max": 16384.0
        },
        {
          "name": "detect_hand",
          "type": {
            "type": "enum",
            "values": [
              "enable",
              "disable"
            ],
            "type_name": "nodetool.nodes.comfy.comfy_node.EnableDisable"
          },
          "default": "enable",
          "title": "Detect Hand",
          "description": "Whether to detect hands."
        },
        {
          "name": "detect_body",
          "type": {
            "type": "enum",
            "values": [
              "enable",
              "disable"
            ],
            "type_name": "nodetool.nodes.comfy.comfy_node.EnableDisable"
          },
          "default": "enable",
          "title": "Detect Body",
          "description": "Whether to detect bodies."
        },
        {
          "name": "detect_face",
          "type": {
            "type": "enum",
            "values": [
              "enable",
              "disable"
            ],
            "type_name": "nodetool.nodes.comfy.comfy_node.EnableDisable"
          },
          "default": "enable",
          "title": "Detect Face",
          "description": "Whether to detect faces."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "image"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "image",
        "resolution",
        "detect_hand",
        "detect_body",
        "detect_face"
      ],
      "is_dynamic": false
    },
    {
      "title": "Color Preprocessor",
      "description": "Color preprocessor.",
      "namespace": "comfy.controlnet.t2i",
      "node_type": "comfy.controlnet.t2i.ColorPreprocessor",
      "layout": "default",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {},
          "title": "Image",
          "description": "The image to preprocess."
        },
        {
          "name": "resolution",
          "type": {
            "type": "int"
          },
          "default": 512,
          "title": "Resolution",
          "description": "The width of the image to generate.",
          "min": 64.0,
          "max": 16384.0
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "image"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "image",
        "resolution"
      ],
      "is_dynamic": false
    },
    {
      "title": "Shuffle Preprocessor",
      "description": "Shuffle preprocessor.",
      "namespace": "comfy.controlnet.t2i",
      "node_type": "comfy.controlnet.t2i.ShufflePreprocessor",
      "layout": "default",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {},
          "title": "Image",
          "description": "The image to preprocess."
        },
        {
          "name": "resolution",
          "type": {
            "type": "int"
          },
          "default": 512,
          "title": "Resolution",
          "description": "The width of the image to generate.",
          "min": 64.0,
          "max": 16384.0
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "image"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "image",
        "resolution"
      ],
      "is_dynamic": false
    },
    {
      "title": "Image Intensity",
      "description": "Detect the intensity of an image.",
      "namespace": "comfy.controlnet.others",
      "node_type": "comfy.controlnet.others.ImageIntensityDetector",
      "layout": "default",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {},
          "title": "Image",
          "description": "The image to preprocess."
        },
        {
          "name": "resolution",
          "type": {
            "type": "int"
          },
          "default": 512,
          "title": "Resolution",
          "description": "The width of the image to generate.",
          "min": 64.0,
          "max": 16384.0
        },
        {
          "name": "gamma_correction",
          "type": {
            "type": "float"
          },
          "default": 1.0,
          "title": "Gamma Correction",
          "description": "The gamma correction value.",
          "min": 0.1,
          "max": 2.0
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "image"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "image",
        "resolution",
        "gamma_correction"
      ],
      "is_dynamic": false
    },
    {
      "title": "Image Luminance",
      "description": "Detect the luminance of an image.",
      "namespace": "comfy.controlnet.others",
      "node_type": "comfy.controlnet.others.ImageLuminanceDetector",
      "layout": "default",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {},
          "title": "Image",
          "description": "The image to preprocess."
        },
        {
          "name": "resolution",
          "type": {
            "type": "int"
          },
          "default": 512,
          "title": "Resolution",
          "description": "The width of the image to generate.",
          "min": 64.0,
          "max": 16384.0
        },
        {
          "name": "gamma_correction",
          "type": {
            "type": "float"
          },
          "default": 1.0,
          "title": "Gamma Correction",
          "description": "The gamma correction value.",
          "min": 0.1,
          "max": 2.0
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "image"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "image",
        "resolution",
        "gamma_correction"
      ],
      "is_dynamic": false
    },
    {
      "title": "Tile Preprocessor",
      "description": "Tile preprocessor.",
      "namespace": "comfy.controlnet.others",
      "node_type": "comfy.controlnet.others.TilePreprocessor",
      "layout": "default",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {},
          "title": "Image",
          "description": "The image to preprocess."
        },
        {
          "name": "resolution",
          "type": {
            "type": "int"
          },
          "default": 512,
          "title": "Resolution",
          "description": "The width of the image to generate.",
          "min": 64.0,
          "max": 16384.0
        },
        {
          "name": "pyrUp_iters",
          "type": {
            "type": "int"
          },
          "default": 3,
          "title": "Pyrup Iters",
          "description": "The number of times to apply pyrUp.",
          "min": 1.0,
          "max": 10.0
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "image"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "image",
        "resolution",
        "pyrUp_iters"
      ],
      "is_dynamic": false
    },
    {
      "title": "BAE Normal Map Preprocessor",
      "description": "BAE normal map detection preprocessor.",
      "namespace": "comfy.controlnet.normal_and_depth",
      "node_type": "comfy.controlnet.normal_and_depth.BAE_Normal_Map_Preprocessor",
      "layout": "default",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {},
          "title": "Image",
          "description": "The image to preprocess."
        },
        {
          "name": "resolution",
          "type": {
            "type": "int"
          },
          "default": 512,
          "title": "Resolution",
          "description": "The width of the image to generate.",
          "min": 64.0,
          "max": 16384.0
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "image"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "image",
        "resolution"
      ],
      "is_dynamic": false
    },
    {
      "title": "DSINE Normal Map Preprocessor",
      "description": "DSINE normal map preprocessor.",
      "namespace": "comfy.controlnet.normal_and_depth",
      "node_type": "comfy.controlnet.normal_and_depth.DSINE_Normal_Map_Preprocessor",
      "layout": "default",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {},
          "title": "Image",
          "description": "The image to preprocess."
        },
        {
          "name": "resolution",
          "type": {
            "type": "int"
          },
          "default": 512,
          "title": "Resolution",
          "description": "The width of the image to generate.",
          "min": 64.0,
          "max": 16384.0
        },
        {
          "name": "fov",
          "type": {
            "type": "float"
          },
          "default": 60.0,
          "title": "Fov",
          "description": "The field of view to use.",
          "min": 0.0,
          "max": 365.0
        },
        {
          "name": "iterations",
          "type": {
            "type": "int"
          },
          "default": 5,
          "title": "Iterations",
          "description": "The number of iterations to use.",
          "min": 1.0,
          "max": 20.0
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "image"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "image",
        "resolution",
        "fov",
        "iterations"
      ],
      "is_dynamic": false
    },
    {
      "title": "Depth Anything V 2 Preprocessor",
      "description": "Depth Anything V2 preprocessor.",
      "namespace": "comfy.controlnet.normal_and_depth",
      "node_type": "comfy.controlnet.normal_and_depth.DepthAnythingV2Preprocessor",
      "layout": "default",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {},
          "title": "Image",
          "description": "The image to preprocess."
        },
        {
          "name": "resolution",
          "type": {
            "type": "int"
          },
          "default": 512,
          "title": "Resolution",
          "description": "The width of the image to generate.",
          "min": 64.0,
          "max": 16384.0
        },
        {
          "name": "ckpt_name",
          "type": {
            "type": "enum",
            "values": [
              "depth_anything_v2_vitl.pth",
              "depth_anything_v2_vitb.pth",
              "depth_anything_v2_vits.pth"
            ],
            "type_name": "nodetool.nodes.comfy.controlnet.normal_and_depth.DepthAnythingModel"
          },
          "default": "depth_anything_v2_vits.pth",
          "title": "Ckpt Name",
          "description": "The checkpoint name to use."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "image"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "image",
        "resolution",
        "ckpt_name"
      ],
      "is_dynamic": false
    },
    {
      "title": "Inpaint Preprocessor",
      "description": "",
      "namespace": "comfy.controlnet.normal_and_depth",
      "node_type": "comfy.controlnet.normal_and_depth.InpaintPreprocessor",
      "layout": "default",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {},
          "title": "Image",
          "description": "The image to inpaint."
        },
        {
          "name": "resolution",
          "type": {
            "type": "int"
          },
          "default": 512,
          "title": "Resolution",
          "description": "The width of the image to generate.",
          "min": 64.0,
          "max": 16384.0
        },
        {
          "name": "mask",
          "type": {
            "type": "comfy.mask"
          },
          "default": {},
          "title": "Mask",
          "description": "The mask to use for inpainting."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "image"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "image",
        "resolution",
        "mask"
      ],
      "is_dynamic": false
    },
    {
      "title": "Le Re SDepth Map Preprocessor",
      "description": "Preprocesses an image for LeReS depth map detection.",
      "namespace": "comfy.controlnet.normal_and_depth",
      "node_type": "comfy.controlnet.normal_and_depth.LeReSDepthMapPreprocessor",
      "layout": "default",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {},
          "title": "Image",
          "description": "The image to preprocess."
        },
        {
          "name": "resolution",
          "type": {
            "type": "int"
          },
          "default": 512,
          "title": "Resolution",
          "description": "The width of the image to generate.",
          "min": 64.0,
          "max": 16384.0
        },
        {
          "name": "rm_nearest",
          "type": {
            "type": "float"
          },
          "default": 0.0,
          "title": "Rm Nearest",
          "description": "The nearest depth to remove.",
          "min": 0.0,
          "max": 100.0
        },
        {
          "name": "rm_background",
          "type": {
            "type": "float"
          },
          "default": 0.0,
          "title": "Rm Background",
          "description": "The background depth to remove.",
          "min": 0.0,
          "max": 100.0
        },
        {
          "name": "boost",
          "type": {
            "type": "enum",
            "values": [
              "enable",
              "disable"
            ],
            "type_name": "nodetool.nodes.comfy.comfy_node.EnableDisable"
          },
          "default": "disable",
          "title": "Boost",
          "description": "Whether to boost the depth map."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "image"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "image",
        "resolution",
        "rm_nearest",
        "rm_background",
        "boost"
      ],
      "is_dynamic": false
    },
    {
      "title": "MIDASDepth Map Preprocessor",
      "description": "MIDAS depth map detection preprocessor.",
      "namespace": "comfy.controlnet.normal_and_depth",
      "node_type": "comfy.controlnet.normal_and_depth.MIDASDepthMapPreprocessor",
      "layout": "default",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {},
          "title": "Image",
          "description": "The image to preprocess."
        },
        {
          "name": "resolution",
          "type": {
            "type": "int"
          },
          "default": 512,
          "title": "Resolution",
          "description": "The width of the image to generate.",
          "min": 64.0,
          "max": 16384.0
        },
        {
          "name": "a",
          "type": {
            "type": "float"
          },
          "default": 6.283185307179586,
          "title": "A",
          "description": "Parameter 'a' for the MIDAS Depth Map Preprocessor.",
          "min": 0.0,
          "max": 15.707963267948966
        },
        {
          "name": "bg_threshold",
          "type": {
            "type": "float"
          },
          "default": 0.1,
          "title": "Bg Threshold",
          "description": "Background threshold for the MIDAS Depth Map Preprocessor.",
          "min": 0.0,
          "max": 1.0
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "image"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "image",
        "resolution",
        "a",
        "bg_threshold"
      ],
      "is_dynamic": false
    },
    {
      "title": "MIDASNormal Map Preprocessor",
      "description": "Preprocesses an image for MIDAS normal map detection.",
      "namespace": "comfy.controlnet.normal_and_depth",
      "node_type": "comfy.controlnet.normal_and_depth.MIDASNormalMapPreprocessor",
      "layout": "default",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {},
          "title": "Image",
          "description": "The image to preprocess."
        },
        {
          "name": "resolution",
          "type": {
            "type": "int"
          },
          "default": 512,
          "title": "Resolution",
          "description": "The width of the image to generate.",
          "min": 64.0,
          "max": 16384.0
        },
        {
          "name": "a",
          "type": {
            "type": "float"
          },
          "default": 6.283185307179586,
          "title": "A",
          "description": "Parameter 'a' for the MIDAS Normal Map Preprocessor.",
          "min": 0.0,
          "max": 15.707963267948966
        },
        {
          "name": "bg_threshold",
          "type": {
            "type": "float"
          },
          "default": 0.1,
          "title": "Bg Threshold",
          "description": "Background threshold for the MIDAS Normal Map Preprocessor.",
          "min": 0.0,
          "max": 1.0
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "image"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "image",
        "resolution",
        "a",
        "bg_threshold"
      ],
      "is_dynamic": false
    },
    {
      "title": "Metric 3 D Depth Map Preprocessor",
      "description": "",
      "namespace": "comfy.controlnet.normal_and_depth",
      "node_type": "comfy.controlnet.normal_and_depth.Metric3D_Depth_Map_Preprocessor",
      "layout": "default",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {},
          "title": "Image",
          "description": "The image to preprocess."
        },
        {
          "name": "resolution",
          "type": {
            "type": "int"
          },
          "default": 512,
          "title": "Resolution",
          "description": "The width of the image to generate.",
          "min": 64.0,
          "max": 16384.0
        },
        {
          "name": "backbone",
          "type": {
            "type": "enum",
            "values": [
              "vit-small",
              "vit-large",
              "vit-giant2"
            ],
            "type_name": "nodetool.nodes.comfy.controlnet.normal_and_depth.Metric3D_Depth_Map_Backbone"
          },
          "default": "vit-small",
          "title": "Backbone",
          "description": "The backbone to use."
        },
        {
          "name": "fx",
          "type": {
            "type": "int"
          },
          "default": 1000,
          "title": "Fx",
          "description": "The fx to use.",
          "min": 1.0,
          "max": 16384.0
        },
        {
          "name": "fy",
          "type": {
            "type": "int"
          },
          "default": 1000,
          "title": "Fy",
          "description": "The fy to use.",
          "min": 1.0,
          "max": 16384.0
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "image"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "image",
        "resolution",
        "backbone",
        "fx",
        "fy"
      ],
      "is_dynamic": false
    },
    {
      "title": "Zoe Depth Map Preprocessor",
      "description": "Zoe depth map detection preprocessor.",
      "namespace": "comfy.controlnet.normal_and_depth",
      "node_type": "comfy.controlnet.normal_and_depth.ZoeDepthMapPreprocessor",
      "layout": "default",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {},
          "title": "Image",
          "description": "The image to preprocess."
        },
        {
          "name": "resolution",
          "type": {
            "type": "int"
          },
          "default": 512,
          "title": "Resolution",
          "description": "The width of the image to generate.",
          "min": 64.0,
          "max": 16384.0
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "image"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "image",
        "resolution"
      ],
      "is_dynamic": false
    },
    {
      "title": "Zoe Depth Anything Preprocessor",
      "description": "Zoe depth anything preprocessor.",
      "namespace": "comfy.controlnet.normal_and_depth",
      "node_type": "comfy.controlnet.normal_and_depth.Zoe_DepthAnythingPreprocessor",
      "layout": "default",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {},
          "title": "Image",
          "description": "The image to preprocess."
        },
        {
          "name": "resolution",
          "type": {
            "type": "int"
          },
          "default": 512,
          "title": "Resolution",
          "description": "The width of the image to generate.",
          "min": 64.0,
          "max": 16384.0
        },
        {
          "name": "environment",
          "type": {
            "type": "enum",
            "values": [
              "indoor",
              "outdoor"
            ],
            "type_name": "nodetool.nodes.comfy.controlnet.normal_and_depth.ZoeDepthAnythingEnvironment"
          },
          "default": "indoor",
          "title": "Environment",
          "description": "The environment to use."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "image"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "image",
        "resolution",
        "environment"
      ],
      "is_dynamic": false
    },
    {
      "title": "Flip Sigmas",
      "description": "Flip an array of sigmas.",
      "namespace": "comfy.sampling.sigmas",
      "node_type": "comfy.sampling.sigmas.FlipSigmas",
      "layout": "default",
      "properties": [
        {
          "name": "sigmas",
          "type": {
            "type": "comfy.sigmas"
          },
          "default": {},
          "title": "Sigmas",
          "description": "The array of sigmas to flip."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "comfy.sigmas"
          },
          "name": "sigmas"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "sigmas"
      ],
      "is_dynamic": false
    },
    {
      "title": "Split Sigmas",
      "description": "Split an array of sigmas into two arrays.",
      "namespace": "comfy.sampling.sigmas",
      "node_type": "comfy.sampling.sigmas.SplitSigmas",
      "layout": "default",
      "properties": [
        {
          "name": "sigmas",
          "type": {
            "type": "comfy.sigmas"
          },
          "default": {},
          "title": "Sigmas",
          "description": "The array of sigmas to split."
        },
        {
          "name": "step",
          "type": {
            "type": "int"
          },
          "default": 0,
          "title": "Step",
          "description": "The specific step at which to split the sigmas array."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "comfy.sigmas"
          },
          "name": "sigmas"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "sigmas",
        "step"
      ],
      "is_dynamic": false
    },
    {
      "title": "Differential Diffusion",
      "description": "Implements differential diffusion by modifying the model's denoise mask function. Adapted from https://github.com/exx8/differential-diffusion",
      "namespace": "comfy.sampling.__init__",
      "node_type": "comfy.sampling.__init__.DifferentialDiffusion",
      "layout": "default",
      "properties": [
        {
          "name": "model",
          "type": {
            "type": "comfy.unet"
          },
          "default": {},
          "title": "Model",
          "description": "The model to modify."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "comfy.unet"
          },
          "name": "model"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "model"
      ],
      "is_dynamic": false
    },
    {
      "title": "KSampler",
      "description": "The KSampler uses the provided model and positive and negative conditioning to generate a new version of the given latent. First the latent is noised up according to the given seed and denoise strength, erasing some of the latent image. then this noise is removed using the given Model and the positive and negative conditioning as guidance, \"dreaming\" up new details in places where the image was erased by noise.",
      "namespace": "comfy.sampling.__init__",
      "node_type": "comfy.sampling.__init__.KSampler",
      "layout": "default",
      "properties": [
        {
          "name": "model",
          "type": {
            "type": "comfy.unet"
          },
          "default": {},
          "title": "Model",
          "description": "The model to use."
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": 0,
          "title": "Seed",
          "description": "The seed to use."
        },
        {
          "name": "seed_control_mode",
          "type": {
            "type": "enum",
            "values": [
              "fixed",
              "randomize",
              "increment",
              "decrement"
            ],
            "type_name": "nodetool.nodes.comfy.sampling.__init__.SeedControlMode"
          },
          "default": "fixed",
          "title": "Seed Control Mode",
          "description": "The seed control mode to use."
        },
        {
          "name": "steps",
          "type": {
            "type": "int"
          },
          "default": 20,
          "title": "Steps",
          "description": "The number of steps to use."
        },
        {
          "name": "cfg",
          "type": {
            "type": "float"
          },
          "default": 8.0,
          "title": "Cfg",
          "description": "The cfg to use."
        },
        {
          "name": "sampler_name",
          "type": {
            "type": "enum",
            "values": [
              "ddim",
              "uni_pc",
              "uni_pc_bh2",
              "euler",
              "euler_ancestral",
              "heun",
              "heunpp2",
              "dpm_2",
              "dpm_2_ancestral",
              "lms",
              "dpm_fast",
              "dpm_adaptive",
              "dpmpp_2s_ancestral",
              "dpmpp_sde",
              "dpmpp_sde_gpu",
              "dpmpp_2m",
              "dpmpp_2m_sde",
              "dpmpp_2m_sde_gpu",
              "dpmpp_3m_sde",
              "dpmpp_3m_sde_gpu",
              "ddpm",
              "lcm"
            ],
            "type_name": "nodetool.nodes.comfy.sampling.__init__.SamplerEnum"
          },
          "default": "ddim",
          "title": "Sampler Name",
          "description": "The sampler to use."
        },
        {
          "name": "scheduler",
          "type": {
            "type": "enum",
            "values": [
              "normal",
              "karras",
              "exponential",
              "sgm_uniform",
              "simple",
              "ddim_uniform"
            ],
            "type_name": "nodetool.nodes.comfy.sampling.__init__.SchedulerEnum"
          },
          "default": "normal",
          "title": "Scheduler",
          "description": "The scheduler to use."
        },
        {
          "name": "positive",
          "type": {
            "type": "comfy.conditioning"
          },
          "default": {},
          "title": "Positive",
          "description": "The positive conditioning to use."
        },
        {
          "name": "negative",
          "type": {
            "type": "comfy.conditioning"
          },
          "default": {},
          "title": "Negative",
          "description": "The negative conditioning to use."
        },
        {
          "name": "latent_image",
          "type": {
            "type": "comfy.latent"
          },
          "default": {},
          "title": "Latent Image",
          "description": "The latent image to use."
        },
        {
          "name": "denoise",
          "type": {
            "type": "float"
          },
          "default": 1.0,
          "title": "Denoise",
          "description": "The denoise to use."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "comfy.latent"
          },
          "name": "latent"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "model",
        "seed",
        "seed_control_mode",
        "steps",
        "cfg",
        "sampler_name",
        "scheduler",
        "positive",
        "negative",
        "latent_image",
        "denoise"
      ],
      "is_dynamic": false
    },
    {
      "title": "KSampler (Advanced)",
      "description": "The KSampler Advanced node is the more advanced version of the KSampler node. While the KSampler node always adds noise to the latent followed by completely denoising the noised up latent, the KSampler Advanced node provides extra settings to control this behavior. The KSampler Advanced node can be told not to add noise into the latent with the add_noise setting. It can also be made to return partially denoised images via the return_with_leftover_noise setting. Unlike the KSampler node, this node does not have a denoise setting but this process is instead controlled by the start_at_step and end_at_step settings. This makes it possible to e.g. hand over a partially denoised latent to a separate KSampler Advanced node to finish the process.",
      "namespace": "comfy.sampling.__init__",
      "node_type": "comfy.sampling.__init__.KSamplerAdvanced",
      "layout": "default",
      "properties": [
        {
          "name": "model",
          "type": {
            "type": "comfy.unet"
          },
          "default": {},
          "title": "Model",
          "description": "The model to use."
        },
        {
          "name": "add_noise",
          "type": {
            "type": "enum",
            "values": [
              "enable",
              "disable"
            ],
            "type_name": "nodetool.nodes.comfy.comfy_node.EnableDisable"
          },
          "default": "enable",
          "title": "Add Noise",
          "description": "Enable or disable noise addition."
        },
        {
          "name": "noise_seed",
          "type": {
            "type": "int"
          },
          "default": 0,
          "title": "Noise Seed",
          "description": "The seed for noise generation."
        },
        {
          "name": "steps",
          "type": {
            "type": "int"
          },
          "default": 20,
          "title": "Steps",
          "description": "The number of steps to use during sampling."
        },
        {
          "name": "cfg",
          "type": {
            "type": "float"
          },
          "default": 8.0,
          "title": "Cfg",
          "description": "The configuration value for the sampler."
        },
        {
          "name": "sampler_name",
          "type": {
            "type": "enum",
            "values": [
              "ddim",
              "uni_pc",
              "uni_pc_bh2",
              "euler",
              "euler_ancestral",
              "heun",
              "heunpp2",
              "dpm_2",
              "dpm_2_ancestral",
              "lms",
              "dpm_fast",
              "dpm_adaptive",
              "dpmpp_2s_ancestral",
              "dpmpp_sde",
              "dpmpp_sde_gpu",
              "dpmpp_2m",
              "dpmpp_2m_sde",
              "dpmpp_2m_sde_gpu",
              "dpmpp_3m_sde",
              "dpmpp_3m_sde_gpu",
              "ddpm",
              "lcm"
            ],
            "type_name": "nodetool.nodes.comfy.sampling.__init__.SamplerEnum"
          },
          "default": "ddim",
          "title": "Sampler Name",
          "description": "The name of the sampler to use."
        },
        {
          "name": "scheduler",
          "type": {
            "type": "enum",
            "values": [
              "normal",
              "karras",
              "exponential",
              "sgm_uniform",
              "simple",
              "ddim_uniform"
            ],
            "type_name": "nodetool.nodes.comfy.sampling.__init__.SchedulerEnum"
          },
          "default": "normal",
          "title": "Scheduler",
          "description": "The scheduler to use."
        },
        {
          "name": "positive",
          "type": {
            "type": "comfy.conditioning"
          },
          "default": {},
          "title": "Positive",
          "description": "The positive conditioning influence."
        },
        {
          "name": "negative",
          "type": {
            "type": "comfy.conditioning"
          },
          "default": {},
          "title": "Negative",
          "description": "The negative conditioning influence."
        },
        {
          "name": "latent_image",
          "type": {
            "type": "comfy.latent"
          },
          "default": {},
          "title": "Latent Image",
          "description": "The starting latent image."
        },
        {
          "name": "start_at_step",
          "type": {
            "type": "int"
          },
          "default": 0,
          "title": "Start At Step",
          "description": "The step at which to start the sampling process."
        },
        {
          "name": "end_at_step",
          "type": {
            "type": "int"
          },
          "default": 10000,
          "title": "End At Step",
          "description": "The step at which to end the sampling process."
        },
        {
          "name": "return_with_leftover_noise",
          "type": {
            "type": "enum",
            "values": [
              "enable",
              "disable"
            ],
            "type_name": "nodetool.nodes.comfy.comfy_node.EnableDisable"
          },
          "default": "disable",
          "title": "Return With Leftover Noise",
          "description": "Whether to return with leftover noise or not."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "comfy.latent"
          },
          "name": "latent"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "model",
        "add_noise",
        "noise_seed",
        "steps",
        "cfg",
        "sampler_name",
        "scheduler",
        "positive",
        "negative",
        "latent_image",
        "start_at_step",
        "end_at_step",
        "return_with_leftover_noise"
      ],
      "is_dynamic": false
    },
    {
      "title": "Basic Guider",
      "description": "The Basic Guider node provides a simple guidance mechanism for the sampling process. It uses a single conditioning input to guide the model's generation.\n    sampling, guidance, basic\n    Use cases:\n    - Simple guidance for image generation\n    - Single conditioning input scenarios\n    - Basic control over the sampling process",
      "namespace": "comfy.sampling.guiders",
      "node_type": "comfy.sampling.guiders.BasicGuider",
      "layout": "default",
      "properties": [
        {
          "name": "model",
          "type": {
            "type": "comfy.unet"
          },
          "default": {},
          "title": "Model",
          "description": "The model used by the sampler."
        },
        {
          "name": "conditioning",
          "type": {
            "type": "comfy.conditioning"
          },
          "default": {},
          "title": "Conditioning",
          "description": "The conditioning."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "comfy.guider"
          },
          "name": "guider"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "model",
        "conditioning"
      ],
      "is_dynamic": false
    },
    {
      "title": "CFGGuider",
      "description": "The CFG (Classifier-Free Guidance) Guider node implements the classifier-free guidance method for controlling the generation process. It allows for separate positive and negative conditioning, along with a CFG scale parameter.\n    sampling, guidance, cfg\n    Use cases:\n    - Advanced control over the sampling process\n    - Combining multiple conditioning inputs\n    - Creating diverse image variations",
      "namespace": "comfy.sampling.guiders",
      "node_type": "comfy.sampling.guiders.CFGGuider",
      "layout": "default",
      "properties": [
        {
          "name": "model",
          "type": {
            "type": "comfy.unet"
          },
          "default": {},
          "title": "Model",
          "description": "The model used by the sampler."
        },
        {
          "name": "positive",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Positive",
          "description": "The positive conditioning."
        },
        {
          "name": "negative",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Negative",
          "description": "The negative conditioning."
        },
        {
          "name": "cfg",
          "type": {
            "type": "float"
          },
          "default": 8.0,
          "title": "Cfg",
          "description": "The cfg (classifier-free guidance) parameter."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "comfy.guider"
          },
          "name": "guider"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "model",
        "positive",
        "negative",
        "cfg"
      ],
      "is_dynamic": false
    },
    {
      "title": "Dual CFGGuider",
      "description": "The Dual CFG Guider node extends the CFG guidance method by allowing two separate conditioning inputs, each with its own CFG scale. This can be useful for more complex guidance scenarios or when combining multiple concepts.\n    sampling, guidance, cfg, dual\n    Use cases:\n    - Advanced control over the sampling process\n    - Combining multiple conditioning inputs\n    - Creating diverse image variations",
      "namespace": "comfy.sampling.guiders",
      "node_type": "comfy.sampling.guiders.DualCFGGuider",
      "layout": "default",
      "properties": [
        {
          "name": "model",
          "type": {
            "type": "comfy.unet"
          },
          "default": {},
          "title": "Model",
          "description": "The model used by the sampler."
        },
        {
          "name": "cond1",
          "type": {
            "type": "comfy.conditioning"
          },
          "default": {},
          "title": "Cond1",
          "description": "The first conditioning."
        },
        {
          "name": "cond2",
          "type": {
            "type": "comfy.conditioning"
          },
          "default": {},
          "title": "Cond2",
          "description": "The second conditioning."
        },
        {
          "name": "negative",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Negative",
          "description": "The negative conditioning."
        },
        {
          "name": "cfg_conds",
          "type": {
            "type": "float"
          },
          "default": 8.0,
          "title": "Cfg Conds",
          "description": "The cfg (classifier-free guidance) parameter."
        },
        {
          "name": "cfg_conds2_negative",
          "type": {
            "type": "float"
          },
          "default": 8.0,
          "title": "Cfg Conds2 Negative",
          "description": "The cfg (classifier-free guidance) parameter for the second conditioning."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "comfy.guider"
          },
          "name": "guider"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "model",
        "cond1",
        "cond2",
        "negative",
        "cfg_conds",
        "cfg_conds2_negative"
      ],
      "is_dynamic": false
    },
    {
      "title": "Video Linear CFGGuidance",
      "description": "The Video Linear CFG Guidance node applies a linear CFG guidance scheme specifically designed for video generation tasks. It allows setting a minimum CFG value to control the strength of the guidance throughout the video frames.\n    sampling, guidance, cfg, video\n    Use cases:\n    - Creating consistent video outputs\n    - Controlling the strength of guidance across frames\n    - Enhancing video generation with CFG",
      "namespace": "comfy.sampling.guiders",
      "node_type": "comfy.sampling.guiders.VideoLinearCFGGuidance",
      "layout": "default",
      "properties": [
        {
          "name": "model",
          "type": {
            "type": "comfy.unet"
          },
          "default": {},
          "title": "Model",
          "description": "The model to apply guidance to."
        },
        {
          "name": "min_cfg",
          "type": {
            "type": "float"
          },
          "default": 1.0,
          "title": "Min Cfg",
          "description": "The minimum CFG value.",
          "min": 0.0,
          "max": 100.0
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "comfy.unet"
          },
          "name": "model"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "model",
        "min_cfg"
      ],
      "is_dynamic": false
    },
    {
      "title": "Video Triangle CFGGuidance",
      "description": "The Video Triangle CFG Guidance node applies a triangular CFG guidance scheme for video generation. This can create a varying strength of guidance across video frames, potentially leading to more dynamic or consistent video outputs.\n    sampling, guidance, cfg, video\n    Use cases:\n    - Creating dynamic video outputs\n    - Controlling the strength of guidance across frames\n    - Enhancing video generation with CFG",
      "namespace": "comfy.sampling.guiders",
      "node_type": "comfy.sampling.guiders.VideoTriangleCFGGuidance",
      "layout": "default",
      "properties": [
        {
          "name": "model",
          "type": {
            "type": "comfy.unet"
          },
          "default": {},
          "title": "Model",
          "description": "The model to apply guidance to."
        },
        {
          "name": "min_cfg",
          "type": {
            "type": "float"
          },
          "default": 1.0,
          "title": "Min Cfg",
          "description": "The minimum CFG value.",
          "min": 0.0,
          "max": 100.0
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "comfy.unet"
          },
          "name": "model"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "model",
        "min_cfg"
      ],
      "is_dynamic": false
    },
    {
      "title": "Add Noise",
      "description": "Add noise to an image.",
      "namespace": "comfy.sampling.noise",
      "node_type": "comfy.sampling.noise.AddNoise",
      "layout": "default",
      "properties": [
        {
          "name": "model",
          "type": {
            "type": "comfy.unet"
          },
          "default": {},
          "title": "Model",
          "description": "The model used by the sampler."
        },
        {
          "name": "noise",
          "type": {
            "type": "comfy.noise"
          },
          "default": {},
          "title": "Noise",
          "description": "The noise to add."
        },
        {
          "name": "sigmas",
          "type": {
            "type": "float"
          },
          "default": 8.0,
          "title": "Sigmas",
          "description": "The sigmas used in sampling."
        },
        {
          "name": "latent_image",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Latent Image",
          "description": "The latent image to sample from."
        }
      ],
      "outputs": [],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "model",
        "noise",
        "sigmas",
        "latent_image"
      ],
      "is_dynamic": false
    },
    {
      "title": "Disable Noise",
      "description": "Disable noise generation.",
      "namespace": "comfy.sampling.noise",
      "node_type": "comfy.sampling.noise.DisableNoise",
      "layout": "default",
      "properties": [],
      "outputs": [],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [],
      "is_dynamic": false
    },
    {
      "title": "Random Noise",
      "description": "Generate random noise.",
      "namespace": "comfy.sampling.noise",
      "node_type": "comfy.sampling.noise.RandomNoise",
      "layout": "default",
      "properties": [
        {
          "name": "noise_seed",
          "type": {
            "type": "int"
          },
          "default": 0,
          "title": "Noise Seed",
          "description": "The seed for the noise generation."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "comfy.noise"
          },
          "name": "noise"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "noise_seed"
      ],
      "is_dynamic": false
    },
    {
      "title": "KSampler Select",
      "description": "Select a specific sampler for the diffusion process with different performance characteristics and output qualities.\n    sampling, diffusion\n    Use cases:\n    - Experimenting with different sampling methods for optimal image quality\n    - Balancing speed vs quality in image generation\n    - Testing model behavior with different sampling algorithms",
      "namespace": "comfy.sampling.samplers",
      "node_type": "comfy.sampling.samplers.KSamplerSelect",
      "layout": "default",
      "properties": [
        {
          "name": "sampler_name",
          "type": {
            "type": "enum",
            "values": [
              "ddim",
              "uni_pc",
              "uni_pc_bh2",
              "euler",
              "euler_ancestral",
              "heun",
              "heunpp2",
              "dpm_2",
              "dpm_2_ancestral",
              "lms",
              "dpm_fast",
              "dpm_adaptive",
              "dpmpp_2s_ancestral",
              "dpmpp_sde",
              "dpmpp_sde_gpu",
              "dpmpp_2m",
              "dpmpp_2m_sde",
              "dpmpp_2m_sde_gpu",
              "dpmpp_3m_sde",
              "dpmpp_3m_sde_gpu",
              "ddpm",
              "lcm"
            ],
            "type_name": "nodetool.nodes.comfy.sampling.SamplerEnum"
          },
          "default": "ddim",
          "title": "Sampler Name",
          "description": "The name of the sampler."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "comfy.sampler"
          },
          "name": "sampler"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "sampler_name"
      ],
      "is_dynamic": false
    },
    {
      "title": "Sampler Custom",
      "description": "Customizable sampling process with fine-grained control over noise, CFG, and conditioning parameters.\n    sampling, cfg, noise, conditioning\n    Use cases:\n    - Advanced sampling control for complex image generation tasks\n    - Customizing sampling parameters for specific models or tasks\n    - Fine-tuning sampling for specific effects or styles",
      "namespace": "comfy.sampling.samplers",
      "node_type": "comfy.sampling.samplers.SamplerCustom",
      "layout": "default",
      "properties": [
        {
          "name": "model",
          "type": {
            "type": "comfy.unet"
          },
          "default": {},
          "title": "Model",
          "description": "The model used by the sampler."
        },
        {
          "name": "add_noise",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Add Noise",
          "description": "Whether to add noise or not."
        },
        {
          "name": "noise_seed",
          "type": {
            "type": "int"
          },
          "default": 0,
          "title": "Noise Seed",
          "description": "The seed for the noise generation."
        },
        {
          "name": "cfg",
          "type": {
            "type": "float"
          },
          "default": 8.0,
          "title": "Cfg",
          "description": "The cfg (classifier-free guidance) parameter."
        },
        {
          "name": "positive",
          "type": {
            "type": "comfy.conditioning"
          },
          "default": {},
          "title": "Positive",
          "description": "The positive conditioning."
        },
        {
          "name": "negative",
          "type": {
            "type": "comfy.conditioning"
          },
          "default": {},
          "title": "Negative",
          "description": "The negative conditioning."
        },
        {
          "name": "sampler",
          "type": {
            "type": "comfy.sampler"
          },
          "default": {},
          "title": "Sampler",
          "description": "The sampler to use."
        },
        {
          "name": "sigmas",
          "type": {
            "type": "comfy.sigmas"
          },
          "default": {},
          "title": "Sigmas",
          "description": "The sigmas used in sampling."
        },
        {
          "name": "latent_image",
          "type": {
            "type": "comfy.latent"
          },
          "default": {},
          "title": "Latent Image",
          "description": "The latent image to sample from."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "comfy.latent"
          },
          "name": "latent"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "model",
        "add_noise",
        "noise_seed",
        "cfg",
        "positive",
        "negative",
        "sampler",
        "sigmas",
        "latent_image"
      ],
      "is_dynamic": false
    },
    {
      "title": "Sampler Custom Advanced",
      "description": "Advanced sampling implementation with separate control over noise, guidance, and multiple output options.\n    sampling, noise, guidance, cfg\n    Use cases:\n    - Complex image generation requiring precise noise control\n    - Workflows needing access to intermediate denoised results\n    - Advanced guidance-based sampling applications",
      "namespace": "comfy.sampling.samplers",
      "node_type": "comfy.sampling.samplers.SamplerCustomAdvanced",
      "layout": "default",
      "properties": [
        {
          "name": "noise",
          "type": {
            "type": "comfy.noise"
          },
          "default": {},
          "title": "Noise",
          "description": "The noise to apply."
        },
        {
          "name": "guider",
          "type": {
            "type": "comfy.guider"
          },
          "default": {},
          "title": "Guider",
          "description": "The guider to apply."
        },
        {
          "name": "sampler",
          "type": {
            "type": "comfy.sampler"
          },
          "default": {},
          "title": "Sampler",
          "description": "The sampler to use."
        },
        {
          "name": "sigmas",
          "type": {
            "type": "comfy.sigmas"
          },
          "default": {},
          "title": "Sigmas",
          "description": "The sigmas used in sampling."
        },
        {
          "name": "latent_image",
          "type": {
            "type": "comfy.latent"
          },
          "default": {},
          "title": "Latent Image",
          "description": "The latent image to sample from."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "comfy.latent"
          },
          "name": "output"
        },
        {
          "type": {
            "type": "comfy.latent"
          },
          "name": "denoised_output"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "noise",
        "guider",
        "sampler",
        "sigmas",
        "latent_image"
      ],
      "is_dynamic": false
    },
    {
      "title": "Sampler DPMPP 2 M SDE",
      "description": "Advanced DPMPP (2M) SDE sampler implementation offering high-quality results with fewer steps.\n    sampling, diffusion, sde, dpmpp\n    Use cases:\n    - High-quality image generation with reduced step count\n    - Performance-optimized sampling for production workflows\n    - Advanced noise control with GPU/CPU options",
      "namespace": "comfy.sampling.samplers",
      "node_type": "comfy.sampling.samplers.SamplerDPMPP_2M_SDE",
      "layout": "default",
      "properties": [
        {
          "name": "solver_type",
          "type": {
            "type": "enum",
            "values": [
              "midpoint",
              "heun"
            ],
            "type_name": "nodetool.nodes.comfy.sampling.samplers.SolverTypeEnum"
          },
          "default": "midpoint",
          "title": "Solver Type",
          "description": "The type of solver."
        },
        {
          "name": "eta",
          "type": {
            "type": "float"
          },
          "default": 1.0,
          "title": "Eta",
          "description": "The eta parameter."
        },
        {
          "name": "s_noise",
          "type": {
            "type": "float"
          },
          "default": 1.0,
          "title": "S Noise",
          "description": "The scale noise factor."
        },
        {
          "name": "noise_device",
          "type": {
            "type": "enum",
            "values": [
              "gpu",
              "cpu"
            ],
            "type_name": "nodetool.nodes.comfy.sampling.samplers.DeviceEnum"
          },
          "default": "gpu",
          "title": "Noise Device",
          "description": "The device for noise generation, either 'gpu' or 'cpu'."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "comfy.sampler"
          },
          "name": "sampler"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "solver_type",
        "eta",
        "s_noise",
        "noise_device"
      ],
      "is_dynamic": false
    },
    {
      "title": "Sampler DPMPP SDE",
      "description": "Implementation of DPMPP SDE sampler with configurable noise and performance parameters.\n    sampling, diffusion, sde, dpmpp\n    Use cases:\n    - Efficient image generation with controllable noise levels\n    - Fine-tuning sampling parameters for specific image styles\n    - Balancing quality and speed with custom parameters",
      "namespace": "comfy.sampling.samplers",
      "node_type": "comfy.sampling.samplers.SamplerDPMPP_SDE",
      "layout": "default",
      "properties": [
        {
          "name": "eta",
          "type": {
            "type": "float"
          },
          "default": 1.0,
          "title": "Eta",
          "description": "The eta parameter."
        },
        {
          "name": "s_noise",
          "type": {
            "type": "float"
          },
          "default": 1.0,
          "title": "S Noise",
          "description": "The scale noise factor."
        },
        {
          "name": "r",
          "type": {
            "type": "float"
          },
          "default": 0.5,
          "title": "R",
          "description": "The r parameter."
        },
        {
          "name": "noise_device",
          "type": {
            "type": "enum",
            "values": [
              "gpu",
              "cpu"
            ],
            "type_name": "nodetool.nodes.comfy.sampling.samplers.DeviceEnum"
          },
          "default": "gpu",
          "title": "Noise Device",
          "description": "The device for noise generation, either 'gpu' or 'cpu'."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "comfy.sampler"
          },
          "name": "sampler"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "eta",
        "s_noise",
        "r",
        "noise_device"
      ],
      "is_dynamic": false
    },
    {
      "title": "Basic Scheduler",
      "description": "The Basic Scheduler node provides a simple scheduling mechanism for the sampling process.\n    It allows selection of different scheduler types and control over steps and denoising.",
      "namespace": "comfy.sampling.schedulers",
      "node_type": "comfy.sampling.schedulers.BasicScheduler",
      "layout": "default",
      "properties": [
        {
          "name": "model",
          "type": {
            "type": "comfy.unet"
          },
          "default": {},
          "title": "Model",
          "description": "The model to use."
        },
        {
          "name": "scheduler",
          "type": {
            "type": "enum",
            "values": [
              "normal",
              "karras",
              "exponential",
              "sgm_uniform",
              "simple",
              "ddim_uniform"
            ],
            "type_name": "nodetool.nodes.comfy.sampling.SchedulerEnum"
          },
          "default": "normal",
          "title": "Scheduler",
          "description": "The scheduler name."
        },
        {
          "name": "steps",
          "type": {
            "type": "int"
          },
          "default": 20,
          "title": "Steps",
          "description": "The number of steps."
        },
        {
          "name": "denoise",
          "type": {
            "type": "float"
          },
          "default": 1.0,
          "title": "Denoise",
          "description": "The denoising factor."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "comfy.sigmas"
          },
          "name": "sigmas"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "model",
        "scheduler",
        "steps",
        "denoise"
      ],
      "is_dynamic": false
    },
    {
      "title": "Exponential Scheduler",
      "description": "The Exponential Scheduler node provides an exponential decay schedule for the sampling process,\n    which can offer a balance between speed and quality.",
      "namespace": "comfy.sampling.schedulers",
      "node_type": "comfy.sampling.schedulers.ExponentialScheduler",
      "layout": "default",
      "properties": [
        {
          "name": "steps",
          "type": {
            "type": "int"
          },
          "default": 20,
          "title": "Steps",
          "description": "The number of steps."
        },
        {
          "name": "sigma_max",
          "type": {
            "type": "float"
          },
          "default": 14.614642,
          "title": "Sigma Max",
          "description": "The maximum sigma value."
        },
        {
          "name": "sigma_min",
          "type": {
            "type": "float"
          },
          "default": 0.0291675,
          "title": "Sigma Min",
          "description": "The minimum sigma value."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "comfy.sigmas"
          },
          "name": "sigmas"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "steps",
        "sigma_max",
        "sigma_min"
      ],
      "is_dynamic": false
    },
    {
      "title": "Karras Scheduler",
      "description": "The Karras Scheduler node implements the Karras et al. noise schedule, which can provide\n    improved sampling quality, especially for fewer sampling steps.",
      "namespace": "comfy.sampling.schedulers",
      "node_type": "comfy.sampling.schedulers.KarrasScheduler",
      "layout": "default",
      "properties": [
        {
          "name": "steps",
          "type": {
            "type": "int"
          },
          "default": 20,
          "title": "Steps",
          "description": "The number of steps."
        },
        {
          "name": "sigma_max",
          "type": {
            "type": "float"
          },
          "default": 14.614642,
          "title": "Sigma Max",
          "description": "The maximum sigma value."
        },
        {
          "name": "sigma_min",
          "type": {
            "type": "float"
          },
          "default": 0.0291675,
          "title": "Sigma Min",
          "description": "The minimum sigma value."
        },
        {
          "name": "rho",
          "type": {
            "type": "float"
          },
          "default": 7.0,
          "title": "Rho",
          "description": "The rho value."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "comfy.sigmas"
          },
          "name": "sigmas"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "steps",
        "sigma_max",
        "sigma_min",
        "rho"
      ],
      "is_dynamic": false
    },
    {
      "title": "LTXV Scheduler",
      "description": "Custom scheduler for LTXV models.\n    sampling, custom, scheduler, ltxv\n\n    Use cases:\n    - Generate custom sigma schedules for sampling\n    - Adjust sigmas based on latent tokens\n    - Fine-tune sampling parameters for video models",
      "namespace": "comfy.sampling.schedulers",
      "node_type": "comfy.sampling.schedulers.LTXVScheduler",
      "layout": "default",
      "properties": [
        {
          "name": "steps",
          "type": {
            "type": "int"
          },
          "default": 20,
          "title": "Steps",
          "description": "Number of steps.",
          "min": 1.0,
          "max": 10000.0
        },
        {
          "name": "max_shift",
          "type": {
            "type": "float"
          },
          "default": 2.05,
          "title": "Max Shift",
          "description": "Maximum shift parameter.",
          "min": 0.0,
          "max": 100.0
        },
        {
          "name": "base_shift",
          "type": {
            "type": "float"
          },
          "default": 0.95,
          "title": "Base Shift",
          "description": "Base shift parameter.",
          "min": 0.0,
          "max": 100.0
        },
        {
          "name": "stretch",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Stretch",
          "description": "Stretch sigmas to fit terminal value."
        },
        {
          "name": "terminal",
          "type": {
            "type": "float"
          },
          "default": 0.1,
          "title": "Terminal",
          "description": "Terminal value for sigmas.",
          "min": 0.0,
          "max": 0.99
        },
        {
          "name": "latent",
          "type": {
            "type": "comfy.latent"
          },
          "title": "Latent",
          "description": "Optional latent input."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "comfy.sigmas"
          },
          "name": "sigmas"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "steps",
        "max_shift",
        "base_shift",
        "stretch",
        "terminal",
        "latent"
      ],
      "is_dynamic": false
    },
    {
      "title": "Polyexponential Scheduler",
      "description": "The Polyexponential Scheduler node implements a more flexible scheduling mechanism,\n    allowing for fine-tuned control over the noise schedule through the rho parameter.",
      "namespace": "comfy.sampling.schedulers",
      "node_type": "comfy.sampling.schedulers.PolyexponentialScheduler",
      "layout": "default",
      "properties": [
        {
          "name": "steps",
          "type": {
            "type": "int"
          },
          "default": 20,
          "title": "Steps",
          "description": "The number of steps to compute the sigmas."
        },
        {
          "name": "sigma_max",
          "type": {
            "type": "float"
          },
          "default": 14.614642,
          "title": "Sigma Max",
          "description": "The maximum sigma value."
        },
        {
          "name": "sigma_min",
          "type": {
            "type": "float"
          },
          "default": 0.0291675,
          "title": "Sigma Min",
          "description": "The minimum sigma value."
        },
        {
          "name": "rho",
          "type": {
            "type": "float"
          },
          "default": 1.0,
          "title": "Rho",
          "description": "The rho parameter for the scheduler."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "comfy.sigmas"
          },
          "name": "sigmas"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "steps",
        "sigma_max",
        "sigma_min",
        "rho"
      ],
      "is_dynamic": false
    },
    {
      "title": "SDTurbo Scheduler",
      "description": "The SDTurbo Scheduler node is designed for very fast inference, often used with\n    specific models trained for few-step generation. It's particularly useful for\n    real-time or near-real-time applications.",
      "namespace": "comfy.sampling.schedulers",
      "node_type": "comfy.sampling.schedulers.SDTurboScheduler",
      "layout": "default",
      "properties": [
        {
          "name": "model",
          "type": {
            "type": "comfy.unet"
          },
          "default": {},
          "title": "Model",
          "description": "The model for which to use the scheduler."
        },
        {
          "name": "steps",
          "type": {
            "type": "int"
          },
          "default": 1,
          "title": "Steps",
          "description": "The number of steps for the scheduler."
        },
        {
          "name": "denoise",
          "type": {
            "type": "float"
          },
          "default": 1.0,
          "title": "Denoise",
          "description": "The denoising factor to apply in the scheduler."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "comfy.sigmas"
          },
          "name": "sigmas"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "model",
        "steps",
        "denoise"
      ],
      "is_dynamic": false
    },
    {
      "title": "VPScheduler",
      "description": "The VP (Variance Preserving) Scheduler node implements a variance preserving stochastic differential equation (SDE) based scheduler, which can provide high-quality results for certain types of models and generation tasks.\n    sampling, custom, scheduler\n\n    Use cases:\n    - Generate custom sigma schedules for sampling\n    - Fine-tune sampling parameters for specific models\n    - Experiment with variance preserving noise schedules",
      "namespace": "comfy.sampling.schedulers",
      "node_type": "comfy.sampling.schedulers.VPScheduler",
      "layout": "default",
      "properties": [
        {
          "name": "steps",
          "type": {
            "type": "int"
          },
          "default": 20,
          "title": "Steps",
          "description": "The number of steps to compute the sigmas."
        },
        {
          "name": "beta_d",
          "type": {
            "type": "float"
          },
          "default": 19.9,
          "title": "Beta D",
          "description": "beta_d parameter for the VP scheduler."
        },
        {
          "name": "beta_min",
          "type": {
            "type": "float"
          },
          "default": 0.1,
          "title": "Beta Min",
          "description": "beta_min parameter for the VP scheduler."
        },
        {
          "name": "eps_s",
          "type": {
            "type": "float"
          },
          "default": 0.001,
          "title": "Eps S",
          "description": "eps_s parameter for the VP scheduler."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "comfy.sigmas"
          },
          "name": "sigmas"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "steps",
        "beta_d",
        "beta_min",
        "eps_s"
      ],
      "is_dynamic": false
    },
    {
      "title": "Image Scale",
      "description": "Scale an image to a given size.",
      "namespace": "comfy.image.upscaling",
      "node_type": "comfy.image.upscaling.ImageScale",
      "layout": "default",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {},
          "title": "Image",
          "description": "The image to scale."
        },
        {
          "name": "upscale_method",
          "type": {
            "type": "enum",
            "values": [
              "nearest_exact",
              "bilinear",
              "area",
              "bicubic",
              "lanczos"
            ],
            "type_name": "nodetool.nodes.comfy.image.upscaling.UpscaleMethod"
          },
          "default": "nearest_exact",
          "title": "Upscale Method",
          "description": "The method to use for upscaling the image."
        },
        {
          "name": "width",
          "type": {
            "type": "int"
          },
          "default": 512,
          "title": "Width",
          "description": "The target width for scaling."
        },
        {
          "name": "height",
          "type": {
            "type": "int"
          },
          "default": 512,
          "title": "Height",
          "description": "The target height for scaling."
        },
        {
          "name": "crop",
          "type": {
            "type": "enum",
            "values": [
              "disabled",
              "center"
            ],
            "type_name": "nodetool.nodes.comfy.image.upscaling.CropMethod"
          },
          "default": "disabled",
          "title": "Crop",
          "description": "The method to use if cropping is required."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "image"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "image",
        "upscale_method",
        "width",
        "height",
        "crop"
      ],
      "is_dynamic": false
    },
    {
      "title": "Image Scale By",
      "description": "Scale an image by a given factor.",
      "namespace": "comfy.image.upscaling",
      "node_type": "comfy.image.upscaling.ImageScaleBy",
      "layout": "default",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {},
          "title": "Image",
          "description": "The image to scale."
        },
        {
          "name": "upscale_method",
          "type": {
            "type": "enum",
            "values": [
              "nearest_exact",
              "bilinear",
              "area",
              "bicubic",
              "lanczos"
            ],
            "type_name": "nodetool.nodes.comfy.image.upscaling.UpscaleMethod"
          },
          "default": "nearest_exact",
          "title": "Upscale Method",
          "description": "The method to use for upscaling the image."
        },
        {
          "name": "scale_by",
          "type": {
            "type": "float"
          },
          "default": 1.0,
          "title": "Scale By",
          "description": "The scaling factor by which to scale the image."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "image"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "image",
        "upscale_method",
        "scale_by"
      ],
      "is_dynamic": false
    },
    {
      "title": "Image Upscale With Model",
      "description": "Upscale an image using a given model.",
      "namespace": "comfy.image.upscaling",
      "node_type": "comfy.image.upscaling.ImageUpscaleWithModel",
      "layout": "default",
      "properties": [
        {
          "name": "upscale_model",
          "type": {
            "type": "comfy.upscale_model"
          },
          "default": "",
          "title": "Upscale Model",
          "description": "The model to use for upscaling the image."
        },
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {},
          "title": "Image",
          "description": "The image to upscale."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "image"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "upscale_model",
        "image"
      ],
      "is_dynamic": false
    },
    {
      "title": "Repeat Image Batch",
      "description": "Repeat an image a given number of times.",
      "namespace": "comfy.image.batch",
      "node_type": "comfy.image.batch.RepeatImageBatch",
      "layout": "default",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {},
          "title": "Image",
          "description": "The image to repeat."
        },
        {
          "name": "amount",
          "type": {
            "type": "int"
          },
          "default": 1,
          "title": "Amount",
          "description": "The number of times to repeat the image."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "image"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "image",
        "amount"
      ],
      "is_dynamic": false
    },
    {
      "title": "Image Composite Masked",
      "description": "The Image Composite Masked node can be used to composite an image onto another image using a mask.",
      "namespace": "comfy.image.__init__",
      "node_type": "comfy.image.__init__.ImageCompositeMasked",
      "layout": "default",
      "properties": [
        {
          "name": "destination",
          "type": {
            "type": "image"
          },
          "default": {},
          "title": "Destination",
          "description": "The destination image."
        },
        {
          "name": "source",
          "type": {
            "type": "image"
          },
          "default": {},
          "title": "Source",
          "description": "The source image."
        },
        {
          "name": "x",
          "type": {
            "type": "int"
          },
          "default": 0,
          "title": "X",
          "description": "The x position."
        },
        {
          "name": "y",
          "type": {
            "type": "int"
          },
          "default": 0,
          "title": "Y",
          "description": "The y position."
        },
        {
          "name": "resize_source",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Resize Source",
          "description": "Whether to resize the source."
        },
        {
          "name": "mask",
          "type": {
            "type": "comfy.mask"
          },
          "title": "Mask",
          "description": "The mask to use."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "image"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "destination",
        "source",
        "x",
        "y",
        "resize_source",
        "mask"
      ],
      "is_dynamic": false
    },
    {
      "title": "Pad Image for Outpainting",
      "description": "The Pad Image for Outpainting node can be used to to add padding to an image for outpainting. This image can then be given to an inpaint diffusion model via the VAE Encode for Inpainting.",
      "namespace": "comfy.image.__init__",
      "node_type": "comfy.image.__init__.ImagePadForOutpaint",
      "layout": "default",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {},
          "title": "Image",
          "description": "The image to pad."
        },
        {
          "name": "left",
          "type": {
            "type": "int"
          },
          "default": 0,
          "title": "Left",
          "description": "The padding size on the left side."
        },
        {
          "name": "top",
          "type": {
            "type": "int"
          },
          "default": 0,
          "title": "Top",
          "description": "The padding size on the top side."
        },
        {
          "name": "right",
          "type": {
            "type": "int"
          },
          "default": 0,
          "title": "Right",
          "description": "The padding size on the right side."
        },
        {
          "name": "bottom",
          "type": {
            "type": "int"
          },
          "default": 0,
          "title": "Bottom",
          "description": "The padding size on the bottom side."
        },
        {
          "name": "feathering",
          "type": {
            "type": "int"
          },
          "default": 40,
          "title": "Feathering",
          "description": "The feathering value for softening the edges of the padding."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "image"
        },
        {
          "type": {
            "type": "comfy.mask"
          },
          "name": "mask"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "image",
        "left",
        "top",
        "right",
        "bottom",
        "feathering"
      ],
      "is_dynamic": false
    },
    {
      "title": "Load Image",
      "description": "The Load Image node can be used to to load an image. Images can be uploaded in the asset manager or by dropping an image onto the node. Once the image has been uploaded they can be selected inside the node.",
      "namespace": "comfy.image.__init__",
      "node_type": "comfy.image.__init__.LoadImage",
      "layout": "default",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {},
          "title": "Image",
          "description": "The image to load."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "image"
        },
        {
          "type": {
            "type": "comfy.mask"
          },
          "name": "mask"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "image"
      ],
      "is_dynamic": false
    },
    {
      "title": "Load Image Mask",
      "description": "Load an Image and extract a mask from it.",
      "namespace": "comfy.image.__init__",
      "node_type": "comfy.image.__init__.LoadImageMask",
      "layout": "default",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {},
          "title": "Image",
          "description": "The image to load."
        },
        {
          "name": "channel",
          "type": {
            "type": "enum",
            "values": [
              "alpha",
              "red",
              "green",
              "blue"
            ],
            "type_name": "nodetool.nodes.comfy.image.__init__.ColorChannel"
          },
          "default": "alpha",
          "title": "Channel",
          "description": "The color channel to use."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "comfy.mask"
          },
          "name": "mask"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "image",
        "channel"
      ],
      "is_dynamic": false
    },
    {
      "title": "Save Image",
      "description": "The Save Image node can be used to save images. To simply preview an image inside the node graph use the Preview Image node. It can be hard to keep track of all the images that you generate. To help with organizing your images you can pass specially formatted strings to an output node with a file_prefix widget.",
      "namespace": "comfy.image.__init__",
      "node_type": "comfy.image.__init__.SaveImage",
      "layout": "default",
      "properties": [
        {
          "name": "images",
          "type": {
            "type": "image"
          },
          "default": {},
          "title": "Images",
          "description": "The image to save."
        },
        {
          "name": "filename_prefix",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Filename Prefix",
          "description": "The prefix for the filename where the image will be saved."
        }
      ],
      "outputs": [],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "images",
        "filename_prefix"
      ],
      "is_dynamic": false
    },
    {
      "title": "Save Animated PNG",
      "description": "Save a list of images as an animated PNG.",
      "namespace": "comfy.image.animation",
      "node_type": "comfy.image.animation.SaveAnimatedPNG",
      "layout": "default",
      "properties": [
        {
          "name": "images",
          "type": {
            "type": "list",
            "type_args": [
              {
                "type": "image"
              }
            ]
          },
          "default": [],
          "title": "Images",
          "description": "list of images to save as animated PNG."
        },
        {
          "name": "filename_prefix",
          "type": {
            "type": "str"
          },
          "default": "ComfyUI",
          "title": "Filename Prefix",
          "description": "Prefix for the filename."
        },
        {
          "name": "fps",
          "type": {
            "type": "float"
          },
          "default": 6.0,
          "title": "Fps",
          "description": "Frames per second."
        },
        {
          "name": "compress_level",
          "type": {
            "type": "int"
          },
          "default": 4,
          "title": "Compress Level",
          "description": "PNG compression level."
        },
        {
          "name": "hidden_fields",
          "type": {
            "type": "dict",
            "type_args": [
              {
                "type": "str"
              },
              {
                "type": "any"
              }
            ]
          },
          "default": {},
          "title": "Hidden Fields",
          "description": "Hidden fields like prompt and extra PNG information."
        }
      ],
      "outputs": [],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "images",
        "filename_prefix",
        "fps",
        "compress_level",
        "hidden_fields"
      ],
      "is_dynamic": false
    },
    {
      "title": "Save Animated WEBP",
      "description": "Save a list of images as an animated WEBP.",
      "namespace": "comfy.image.animation",
      "node_type": "comfy.image.animation.SaveAnimatedWEBP",
      "layout": "default",
      "properties": [
        {
          "name": "images",
          "type": {
            "type": "list",
            "type_args": [
              {
                "type": "image"
              }
            ]
          },
          "default": [],
          "title": "Images",
          "description": "list of images to save as animated WEBP."
        },
        {
          "name": "filename_prefix",
          "type": {
            "type": "str"
          },
          "default": "ComfyUI",
          "title": "Filename Prefix",
          "description": "Prefix for the filename."
        },
        {
          "name": "fps",
          "type": {
            "type": "float"
          },
          "default": 6.0,
          "title": "Fps",
          "description": "Frames per second."
        },
        {
          "name": "lossless",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Lossless",
          "description": "Whether to use lossless compression."
        },
        {
          "name": "quality",
          "type": {
            "type": "int"
          },
          "default": 80,
          "title": "Quality",
          "description": "Quality of the WEBP."
        },
        {
          "name": "method",
          "type": {
            "type": "enum"
          },
          "default": "default",
          "title": "Method",
          "description": "Compression method to use."
        }
      ],
      "outputs": [],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "images",
        "filename_prefix",
        "fps",
        "lossless",
        "quality",
        "method"
      ],
      "is_dynamic": false
    },
    {
      "title": "Image Crop",
      "description": "Crop an image to a given size.",
      "namespace": "comfy.image.transform",
      "node_type": "comfy.image.transform.ImageCrop",
      "layout": "default",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {},
          "title": "Image",
          "description": "The image to crop."
        },
        {
          "name": "width",
          "type": {
            "type": "int"
          },
          "default": 512,
          "title": "Width",
          "description": "Width of the crop."
        },
        {
          "name": "height",
          "type": {
            "type": "int"
          },
          "default": 512,
          "title": "Height",
          "description": "Height of the crop."
        },
        {
          "name": "x",
          "type": {
            "type": "int"
          },
          "default": 0,
          "title": "X",
          "description": "X position where the crop starts."
        },
        {
          "name": "y",
          "type": {
            "type": "int"
          },
          "default": 0,
          "title": "Y",
          "description": "Y position where the crop starts."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "image"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "image",
        "width",
        "height",
        "x",
        "y"
      ],
      "is_dynamic": false
    },
    {
      "title": "Crop Mask",
      "description": "The Crop Mask node can be used to crop a mask to a new shape.",
      "namespace": "comfy.mask.__init__",
      "node_type": "comfy.mask.__init__.CropMask",
      "layout": "default",
      "properties": [
        {
          "name": "mask",
          "type": {
            "type": "comfy.mask"
          },
          "default": {},
          "title": "Mask",
          "description": "The mask to crop."
        },
        {
          "name": "x",
          "type": {
            "type": "int"
          },
          "default": 0,
          "title": "X",
          "description": "The x position for cropping."
        },
        {
          "name": "y",
          "type": {
            "type": "int"
          },
          "default": 0,
          "title": "Y",
          "description": "The y position for cropping."
        },
        {
          "name": "width",
          "type": {
            "type": "int"
          },
          "default": 512,
          "title": "Width",
          "description": "Width of the crop."
        },
        {
          "name": "height",
          "type": {
            "type": "int"
          },
          "default": 512,
          "title": "Height",
          "description": "Height of the crop."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "comfy.mask"
          },
          "name": "mask"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "mask",
        "x",
        "y",
        "width",
        "height"
      ],
      "is_dynamic": false
    },
    {
      "title": "Feather Mask",
      "description": "The Feather Mask node can be used to feather a mask.",
      "namespace": "comfy.mask.__init__",
      "node_type": "comfy.mask.__init__.FeatherMask",
      "layout": "default",
      "properties": [
        {
          "name": "mask",
          "type": {
            "type": "comfy.mask"
          },
          "default": {},
          "title": "Mask",
          "description": "The mask to feather."
        },
        {
          "name": "left",
          "type": {
            "type": "int"
          },
          "default": 0,
          "title": "Left",
          "description": "Feather amount on the left."
        },
        {
          "name": "top",
          "type": {
            "type": "int"
          },
          "default": 0,
          "title": "Top",
          "description": "Feather amount on the top."
        },
        {
          "name": "right",
          "type": {
            "type": "int"
          },
          "default": 0,
          "title": "Right",
          "description": "Feather amount on the right."
        },
        {
          "name": "bottom",
          "type": {
            "type": "int"
          },
          "default": 0,
          "title": "Bottom",
          "description": "Feather amount on the bottom."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "comfy.mask"
          },
          "name": "mask"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "mask",
        "left",
        "top",
        "right",
        "bottom"
      ],
      "is_dynamic": false
    },
    {
      "title": "Grow Mask",
      "description": "The Grow Mask node can be used to grow a mask.",
      "namespace": "comfy.mask.__init__",
      "node_type": "comfy.mask.__init__.GrowMask",
      "layout": "default",
      "properties": [
        {
          "name": "mask",
          "type": {
            "type": "comfy.mask"
          },
          "default": {},
          "title": "Mask",
          "description": "The mask to grow."
        },
        {
          "name": "expand",
          "type": {
            "type": "int"
          },
          "default": 0,
          "title": "Expand",
          "description": "The amount to expand the mask."
        },
        {
          "name": "tapered_corners",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Tapered Corners",
          "description": "Whether to taper the corners."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "comfy.mask"
          },
          "name": "mask"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "mask",
        "expand",
        "tapered_corners"
      ],
      "is_dynamic": false
    },
    {
      "title": "Image Color To Mask",
      "description": "The Image Color to Mask node can be used to extract a mask from an image based on a specific color.",
      "namespace": "comfy.mask.__init__",
      "node_type": "comfy.mask.__init__.ImageColorToMask",
      "layout": "default",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {},
          "title": "Image",
          "description": "The image to extract the color mask."
        },
        {
          "name": "color",
          "type": {
            "type": "int"
          },
          "default": 0,
          "title": "Color",
          "description": "The color to use for the mask."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "comfy.mask"
          },
          "name": "mask"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "image",
        "color"
      ],
      "is_dynamic": false
    },
    {
      "title": "Convert Image to Mask",
      "description": "The Convert Image yo Mask node can be used to convert a specific channel of an image into a mask.",
      "namespace": "comfy.mask.__init__",
      "node_type": "comfy.mask.__init__.ImageToMask",
      "layout": "default",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {},
          "title": "Image",
          "description": "The image to extract the mask."
        },
        {
          "name": "channel",
          "type": {
            "type": "enum",
            "values": [
              "red",
              "green",
              "blue",
              "alpha"
            ],
            "type_name": "nodetool.nodes.comfy.mask.__init__.ChannelEnum"
          },
          "default": "red",
          "title": "Channel",
          "description": "The channel to use for the mask."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "comfy.mask"
          },
          "name": "mask"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "image",
        "channel"
      ],
      "is_dynamic": false
    },
    {
      "title": "Invert Mask",
      "description": "The Invert Mask node can be used to invert a mask.",
      "namespace": "comfy.mask.__init__",
      "node_type": "comfy.mask.__init__.InvertMask",
      "layout": "default",
      "properties": [
        {
          "name": "mask",
          "type": {
            "type": "comfy.mask"
          },
          "default": {},
          "title": "Mask",
          "description": "The mask to invert."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "comfy.mask"
          },
          "name": "mask"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "mask"
      ],
      "is_dynamic": false
    },
    {
      "title": "Mask Composite",
      "description": "The Mask Composite node can be used to paste one mask into another.",
      "namespace": "comfy.mask.__init__",
      "node_type": "comfy.mask.__init__.MaskComposite",
      "layout": "default",
      "properties": [
        {
          "name": "destination",
          "type": {
            "type": "comfy.mask"
          },
          "default": {},
          "title": "Destination",
          "description": "The destination mask."
        },
        {
          "name": "source",
          "type": {
            "type": "comfy.mask"
          },
          "default": {},
          "title": "Source",
          "description": "The source mask."
        },
        {
          "name": "x",
          "type": {
            "type": "int"
          },
          "default": 0,
          "title": "X",
          "description": "The x position."
        },
        {
          "name": "y",
          "type": {
            "type": "int"
          },
          "default": 0,
          "title": "Y",
          "description": "The y position."
        },
        {
          "name": "operation",
          "type": {
            "type": "enum",
            "values": [
              "multiply",
              "add",
              "subtract",
              "and",
              "or",
              "xor"
            ],
            "type_name": "nodetool.nodes.comfy.mask.__init__.OperationEnum"
          },
          "default": "multiply",
          "title": "Operation",
          "description": "The operation to use."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "comfy.mask"
          },
          "name": "mask"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "destination",
        "source",
        "x",
        "y",
        "operation"
      ],
      "is_dynamic": false
    },
    {
      "title": "Convert Mask to Image",
      "description": "The Convert Mask to Image node can be used to convert a mask to a grey scale image.",
      "namespace": "comfy.mask.__init__",
      "node_type": "comfy.mask.__init__.MaskToImage",
      "layout": "default",
      "properties": [
        {
          "name": "mask",
          "type": {
            "type": "comfy.mask"
          },
          "default": {},
          "title": "Mask",
          "description": "The mask to convert."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "image"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "mask"
      ],
      "is_dynamic": false
    },
    {
      "title": "Solid Mask",
      "description": "The Solid Mask node can be used to create a solid masking containing a single value.",
      "namespace": "comfy.mask.__init__",
      "node_type": "comfy.mask.__init__.SolidMask",
      "layout": "default",
      "properties": [
        {
          "name": "value",
          "type": {
            "type": "float"
          },
          "default": 1.0,
          "title": "Value",
          "description": "The value for the solid mask."
        },
        {
          "name": "width",
          "type": {
            "type": "int"
          },
          "default": 512,
          "title": "Width",
          "description": "Width of the solid mask."
        },
        {
          "name": "height",
          "type": {
            "type": "int"
          },
          "default": 512,
          "title": "Height",
          "description": "Height of the solid mask."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "comfy.mask"
          },
          "name": "mask"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "value",
        "width",
        "height"
      ],
      "is_dynamic": false
    },
    {
      "title": "Join Image With Alpha",
      "description": "The Join Image with Alpha node can be used to combine an image and an alpha mask into a single image with transparency. This is useful for creating images with varying levels of opacity or for preparing images for compositing operations.",
      "namespace": "comfy.mask.compositing",
      "node_type": "comfy.mask.compositing.JoinImageWithAlpha",
      "layout": "default",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {},
          "title": "Image",
          "description": "The image to join with an alpha channel."
        },
        {
          "name": "alpha",
          "type": {
            "type": "comfy.mask"
          },
          "default": {},
          "title": "Alpha",
          "description": "The alpha channel (mask) to join with the image."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "image"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "image",
        "alpha"
      ],
      "is_dynamic": false
    },
    {
      "title": "Porter Duff Image Composite",
      "description": "The Porter-Duff Image Composite node can be used to combine two images using various compositing modes. This allows for complex image blending operations, useful for creating layered effects or combining multiple image elements.",
      "namespace": "comfy.mask.compositing",
      "node_type": "comfy.mask.compositing.PorterDuffImageComposite",
      "layout": "default",
      "properties": [
        {
          "name": "source",
          "type": {
            "type": "image"
          },
          "default": {},
          "title": "Source",
          "description": "The source image."
        },
        {
          "name": "source_alpha",
          "type": {
            "type": "comfy.mask"
          },
          "default": {},
          "title": "Source Alpha",
          "description": "The source alpha (mask)."
        },
        {
          "name": "destination",
          "type": {
            "type": "image"
          },
          "default": {},
          "title": "Destination",
          "description": "The destination image."
        },
        {
          "name": "destination_alpha",
          "type": {
            "type": "comfy.mask"
          },
          "default": {},
          "title": "Destination Alpha",
          "description": "The destination alpha (mask)."
        },
        {
          "name": "mode",
          "type": {
            "type": "enum",
            "values": [
              "ADD",
              "CLEAR",
              "DARKEN",
              "DST",
              "DST_ATOP",
              "DST_IN",
              "DST_OUT",
              "DST_OVER",
              "LIGHTEN",
              "MULTIPLY",
              "OVERLAY",
              "SCREEN",
              "SRC",
              "SRC_ATOP",
              "SRC_IN",
              "SRC_OUT",
              "SRC_OVER",
              "XOR"
            ],
            "type_name": "nodetool.nodes.comfy.mask.compositing.PorterDuffModeEnum"
          },
          "default": "DST",
          "title": "Mode",
          "description": "The Porter-Duff compositing mode to use."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "image"
        },
        {
          "type": {
            "type": "comfy.mask"
          },
          "name": "mask"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "source",
        "source_alpha",
        "destination",
        "destination_alpha",
        "mode"
      ],
      "is_dynamic": false
    },
    {
      "title": "Split Image With Alpha",
      "description": "The Split Image with Alpha node can be used to separate an image with an alpha channel into its color components and alpha mask. This is useful when you need to manipulate the image and its transparency separately.",
      "namespace": "comfy.mask.compositing",
      "node_type": "comfy.mask.compositing.SplitImageWithAlpha",
      "layout": "default",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {},
          "title": "Image",
          "description": "The image with an alpha channel to split."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "image"
        },
        {
          "type": {
            "type": "comfy.mask"
          },
          "name": "mask"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "image"
      ],
      "is_dynamic": false
    },
    {
      "title": "Stable Cascade Empty Latent Image",
      "description": "The Stable Cascade Empty Latent Image node can be used to create an empty latent image.",
      "namespace": "comfy.latent.stable_cascade",
      "node_type": "comfy.latent.stable_cascade.StableCascade_EmptyLatentImage",
      "layout": "default",
      "properties": [
        {
          "name": "width",
          "type": {
            "type": "int"
          },
          "default": 1024,
          "title": "Width",
          "description": "The width of the latent image.",
          "min": 256.0,
          "max": 16384.0
        },
        {
          "name": "height",
          "type": {
            "type": "int"
          },
          "default": 1024,
          "title": "Height",
          "description": "The height of the latent image.",
          "min": 256.0,
          "max": 16384.0
        },
        {
          "name": "compression",
          "type": {
            "type": "int"
          },
          "default": 42,
          "title": "Compression",
          "description": "The compression factor for the latent image.",
          "min": 4.0,
          "max": 128.0
        },
        {
          "name": "batch_size",
          "type": {
            "type": "int"
          },
          "default": 1,
          "title": "Batch Size",
          "description": "The batch size for the latent images.",
          "min": 1.0,
          "max": 4096.0
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "comfy.latent"
          },
          "name": "stage_c"
        },
        {
          "type": {
            "type": "comfy.latent"
          },
          "name": "stage_b"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "width",
        "height",
        "compression",
        "batch_size"
      ],
      "is_dynamic": false
    },
    {
      "title": "Stable Cascade Stage B Conditioning",
      "description": "The Stable Cascade Stage B Conditioning node can be used to condition the stage B latent image.",
      "namespace": "comfy.latent.stable_cascade",
      "node_type": "comfy.latent.stable_cascade.StableCascade_StageB_Conditioning",
      "layout": "default",
      "properties": [
        {
          "name": "conditioning",
          "type": {
            "type": "comfy.conditioning"
          },
          "default": {},
          "title": "Conditioning",
          "description": "The input conditioning."
        },
        {
          "name": "stage_c",
          "type": {
            "type": "comfy.latent"
          },
          "default": {},
          "title": "Stage C",
          "description": "The stage C latent."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "comfy.conditioning"
          },
          "name": "conditioning"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "conditioning",
        "stage_c"
      ],
      "is_dynamic": false
    },
    {
      "title": "Stable Cascade Stage C VAE Encode",
      "description": "The Stable Cascade Stage C VAE Encode node can be used to encode an image into a latent image.",
      "namespace": "comfy.latent.stable_cascade",
      "node_type": "comfy.latent.stable_cascade.StableCascade_StageC_VAEEncode",
      "layout": "default",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {},
          "title": "Image",
          "description": "The input image to encode."
        },
        {
          "name": "vae",
          "type": {
            "type": "comfy.vae"
          },
          "default": {},
          "title": "Vae",
          "description": "The VAE model to use for encoding."
        },
        {
          "name": "compression",
          "type": {
            "type": "int"
          },
          "default": 42,
          "title": "Compression",
          "description": "The compression factor for the latent image.",
          "min": 4.0,
          "max": 128.0
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "comfy.latent"
          },
          "name": "stage_c"
        },
        {
          "type": {
            "type": "comfy.latent"
          },
          "name": "stage_b"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "image",
        "vae",
        "compression"
      ],
      "is_dynamic": false
    },
    {
      "title": "Stable Cascade Super Resolution Controlnet",
      "description": "The Stable Cascade Super Resolution Controlnet node can be used to encode an image into a latent image.",
      "namespace": "comfy.latent.stable_cascade",
      "node_type": "comfy.latent.stable_cascade.StableCascade_SuperResolutionControlnet",
      "layout": "default",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {},
          "title": "Image",
          "description": "The input image for super-resolution."
        },
        {
          "name": "vae",
          "type": {
            "type": "comfy.vae"
          },
          "default": {},
          "title": "Vae",
          "description": "The VAE model to use for encoding."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "controlnet_input"
        },
        {
          "type": {
            "type": "comfy.latent"
          },
          "name": "stage_c"
        },
        {
          "type": {
            "type": "comfy.latent"
          },
          "name": "stage_b"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "image",
        "vae"
      ],
      "is_dynamic": false
    },
    {
      "title": "Latent Add",
      "description": "The Latent Add node can be used to add two sets of latent samples together. This operation allows for combining different latent representations, potentially creating interesting hybrid results.",
      "namespace": "comfy.latent.advanced",
      "node_type": "comfy.latent.advanced.LatentAdd",
      "layout": "default",
      "properties": [
        {
          "name": "samples1",
          "type": {
            "type": "comfy.latent"
          },
          "default": {},
          "title": "Samples1",
          "description": "The first set of latent samples to add."
        },
        {
          "name": "samples2",
          "type": {
            "type": "comfy.latent"
          },
          "default": {},
          "title": "Samples2",
          "description": "The second set of latent samples to add."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "comfy.latent"
          },
          "name": "latent"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "samples1",
        "samples2"
      ],
      "is_dynamic": false
    },
    {
      "title": "Latent Interpolate",
      "description": "The Latent Interpolate node can be used to create a smooth transition between two sets of latent samples. This allows for blending different latent representations, potentially creating intermediate results.",
      "namespace": "comfy.latent.advanced",
      "node_type": "comfy.latent.advanced.LatentInterpolate",
      "layout": "default",
      "properties": [
        {
          "name": "samples1",
          "type": {
            "type": "comfy.latent"
          },
          "default": {},
          "title": "Samples1",
          "description": "The first set of latent samples for interpolation."
        },
        {
          "name": "samples2",
          "type": {
            "type": "comfy.latent"
          },
          "default": {},
          "title": "Samples2",
          "description": "The second set of latent samples for interpolation."
        },
        {
          "name": "ratio",
          "type": {
            "type": "float"
          },
          "default": 1.0,
          "title": "Ratio",
          "description": "The ratio for interpolation, controlling the blend between samples1 and samples2."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "comfy.latent"
          },
          "name": "latent"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "samples1",
        "samples2",
        "ratio"
      ],
      "is_dynamic": false
    },
    {
      "title": "Latent Multiply",
      "description": "The Latent Multiply node can be used to scale the values of latent samples by a specified multiplier. This operation can amplify or diminish certain features in the latent representation.",
      "namespace": "comfy.latent.advanced",
      "node_type": "comfy.latent.advanced.LatentMultiply",
      "layout": "default",
      "properties": [
        {
          "name": "samples",
          "type": {
            "type": "comfy.latent"
          },
          "default": {},
          "title": "Samples",
          "description": "The latent samples to multiply."
        },
        {
          "name": "multiplier",
          "type": {
            "type": "float"
          },
          "default": 1.0,
          "title": "Multiplier",
          "description": "The multiplier for the latent samples."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "comfy.latent"
          },
          "name": "latent"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "samples",
        "multiplier"
      ],
      "is_dynamic": false
    },
    {
      "title": "Latent Subtract",
      "description": "The Latent Subtract node can be used to subtract one set of latent samples from another. This operation can be useful for removing certain features or characteristics represented in the latent space.",
      "namespace": "comfy.latent.advanced",
      "node_type": "comfy.latent.advanced.LatentSubtract",
      "layout": "default",
      "properties": [
        {
          "name": "samples1",
          "type": {
            "type": "comfy.latent"
          },
          "default": {},
          "title": "Samples1",
          "description": "The first set of latent samples to subtract from."
        },
        {
          "name": "samples2",
          "type": {
            "type": "comfy.latent"
          },
          "default": {},
          "title": "Samples2",
          "description": "The second set of latent samples to subtract."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "comfy.latent"
          },
          "name": "latent"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "samples1",
        "samples2"
      ],
      "is_dynamic": false
    },
    {
      "title": "Set Latent Noise Mask",
      "description": "The Set Latent Noise Mask node can be used to add a mask to the latent images for inpainting. When the noise mask is set a sampler node will only operate on the masked area. If a single mask is provided, all the latents in the batch will use this mask.",
      "namespace": "comfy.latent.inpaint",
      "node_type": "comfy.latent.inpaint.SetLatentNoiseMask",
      "layout": "default",
      "properties": [
        {
          "name": "samples",
          "type": {
            "type": "comfy.latent"
          },
          "default": {},
          "title": "Samples",
          "description": "The latent samples to set the noise mask for."
        },
        {
          "name": "mask",
          "type": {
            "type": "comfy.mask"
          },
          "default": {},
          "title": "Mask",
          "description": "The mask to use for the noise."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "comfy.latent"
          },
          "name": "latent"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "samples",
        "mask"
      ],
      "is_dynamic": false
    },
    {
      "title": "Latent Batch",
      "description": "The Latent Batch node can be used to batch latent images.",
      "namespace": "comfy.latent.batch",
      "node_type": "comfy.latent.batch.LatentBatch",
      "layout": "default",
      "properties": [
        {
          "name": "samples1",
          "type": {
            "type": "comfy.latent"
          },
          "default": {},
          "title": "Samples1",
          "description": "The first set of latent samples for the batch process."
        },
        {
          "name": "samples2",
          "type": {
            "type": "comfy.latent"
          },
          "default": {},
          "title": "Samples2",
          "description": "The second set of latent samples for the batch process."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "comfy.latent"
          },
          "name": "latent"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "samples1",
        "samples2"
      ],
      "is_dynamic": false
    },
    {
      "title": "Latent From Batch",
      "description": "The Latent From Batch node can be used to pick a slice from a batch of latents. This is useful when a specific latent image or images inside the batch need to be isolated in the workflow.",
      "namespace": "comfy.latent.batch",
      "node_type": "comfy.latent.batch.LatentFromBatch",
      "layout": "default",
      "properties": [
        {
          "name": "samples",
          "type": {
            "type": "comfy.latent"
          },
          "default": {},
          "title": "Samples",
          "description": "The batch of latent samples."
        },
        {
          "name": "batch_index",
          "type": {
            "type": "int"
          },
          "default": 0,
          "title": "Batch Index",
          "description": "The index of the sample in the batch.",
          "min": 0.0,
          "max": 63.0
        },
        {
          "name": "length",
          "type": {
            "type": "int"
          },
          "default": 1,
          "title": "Length",
          "description": "The length of latent samples to extract.",
          "min": 1.0,
          "max": 64.0
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "comfy.latent"
          },
          "name": "latent"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "samples",
        "batch_index",
        "length"
      ],
      "is_dynamic": false
    },
    {
      "title": "Repeat Latent Batch",
      "description": "The Repeat Latent Batch node can be used to repeat a batch of latent images. This can e.g. be used to create multiple variations of an image in an image to image workflow.",
      "namespace": "comfy.latent.batch",
      "node_type": "comfy.latent.batch.RepeatLatentBatch",
      "layout": "default",
      "properties": [
        {
          "name": "samples",
          "type": {
            "type": "comfy.latent"
          },
          "default": {},
          "title": "Samples",
          "description": "The latent samples to repeat."
        },
        {
          "name": "amount",
          "type": {
            "type": "int"
          },
          "default": 1,
          "title": "Amount",
          "description": "The amount of times to repeat each sample."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "comfy.latent"
          },
          "name": "latent"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "samples",
        "amount"
      ],
      "is_dynamic": false
    },
    {
      "title": "Empty Latent Image",
      "description": "The Empty Latent Image node can be used to create a new set of empty latent images. These latents can then be used inside e.g. a text2image workflow by noising and denoising them with a sampler node.",
      "namespace": "comfy.latent.__init__",
      "node_type": "comfy.latent.__init__.EmptyLatentImage",
      "layout": "default",
      "properties": [
        {
          "name": "width",
          "type": {
            "type": "int"
          },
          "default": 512,
          "title": "Width",
          "description": "The width of the latent image to generate.",
          "min": 16.0,
          "max": 16384.0
        },
        {
          "name": "height",
          "type": {
            "type": "int"
          },
          "default": 512,
          "title": "Height",
          "description": "The height of the latent image to generate.",
          "min": 16.0,
          "max": 16384.0
        },
        {
          "name": "batch_size",
          "type": {
            "type": "int"
          },
          "default": 1,
          "title": "Batch Size",
          "description": "The batch size of the latent image to generate.",
          "min": 1.0,
          "max": 16384.0
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "comfy.latent"
          },
          "name": "latent"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "width",
        "height",
        "batch_size"
      ],
      "is_dynamic": false
    },
    {
      "title": "Empty SD3 Latent Image",
      "description": "The Empty SD3 Latent Image node can be used to create a new set of empty latent images. These latents can then be used inside e.g. a text2image workflow by noising and denoising them with a sampler node.",
      "namespace": "comfy.latent.__init__",
      "node_type": "comfy.latent.__init__.EmptySD3LatentImage",
      "layout": "default",
      "properties": [
        {
          "name": "width",
          "type": {
            "type": "int"
          },
          "default": 1024,
          "title": "Width",
          "description": "The width of the latent image.",
          "min": 16.0,
          "max": 16384.0
        },
        {
          "name": "height",
          "type": {
            "type": "int"
          },
          "default": 1024,
          "title": "Height",
          "description": "The height of the latent image.",
          "min": 16.0,
          "max": 16384.0
        },
        {
          "name": "batch_size",
          "type": {
            "type": "int"
          },
          "default": 1,
          "title": "Batch Size",
          "description": "The batch size.",
          "min": 1.0,
          "max": 4096.0
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "comfy.latent"
          },
          "name": "latent"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "width",
        "height",
        "batch_size"
      ],
      "is_dynamic": false
    },
    {
      "title": "Latent Blend",
      "description": "The Latent Blend node can be used to blend two sets of latent samples. This allows for smooth transitions or combinations of different latent representations.",
      "namespace": "comfy.latent.__init__",
      "node_type": "comfy.latent.__init__.LatentBlend",
      "layout": "default",
      "properties": [
        {
          "name": "samples1",
          "type": {
            "type": "comfy.latent"
          },
          "default": {},
          "title": "Samples1",
          "description": "The first set of latent samples."
        },
        {
          "name": "samples2",
          "type": {
            "type": "comfy.latent"
          },
          "default": {},
          "title": "Samples2",
          "description": "The second set of latent samples."
        },
        {
          "name": "blend_factor",
          "type": {
            "type": "float"
          },
          "default": 0.5,
          "title": "Blend Factor",
          "description": "The blend factor between samples."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "comfy.latent"
          },
          "name": "latent"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "samples1",
        "samples2",
        "blend_factor"
      ],
      "is_dynamic": false
    },
    {
      "title": "Latent Composite",
      "description": "The Latent Composite node can be used to paste one latent into another.",
      "namespace": "comfy.latent.__init__",
      "node_type": "comfy.latent.__init__.LatentComposite",
      "layout": "default",
      "properties": [
        {
          "name": "samples_to",
          "type": {
            "type": "comfy.latent"
          },
          "default": {},
          "title": "Samples To",
          "description": "The first latent sample."
        },
        {
          "name": "samples_from",
          "type": {
            "type": "comfy.latent"
          },
          "default": {},
          "title": "Samples From",
          "description": "The second latent sample."
        },
        {
          "name": "x",
          "type": {
            "type": "int"
          },
          "default": 0,
          "title": "X",
          "description": "The x-coordinate for compositing."
        },
        {
          "name": "y",
          "type": {
            "type": "int"
          },
          "default": 0,
          "title": "Y",
          "description": "The y-coordinate for compositing."
        },
        {
          "name": "feather",
          "type": {
            "type": "int"
          },
          "default": 0,
          "title": "Feather",
          "description": "The feather amount for compositing edges."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "comfy.latent"
          },
          "name": "latent"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "samples_to",
        "samples_from",
        "x",
        "y",
        "feather"
      ],
      "is_dynamic": false
    },
    {
      "title": "Latent Composite Masked",
      "description": "The Latent Composite Masked node can be used to paste a masked latent into another.",
      "namespace": "comfy.latent.__init__",
      "node_type": "comfy.latent.__init__.LatentCompositeMasked",
      "layout": "default",
      "properties": [
        {
          "name": "destination",
          "type": {
            "type": "comfy.latent"
          },
          "default": {},
          "title": "Destination",
          "description": "The destination latent."
        },
        {
          "name": "source",
          "type": {
            "type": "comfy.latent"
          },
          "default": {},
          "title": "Source",
          "description": "The source latent."
        },
        {
          "name": "x",
          "type": {
            "type": "int"
          },
          "default": 0,
          "title": "X",
          "description": "The x position."
        },
        {
          "name": "y",
          "type": {
            "type": "int"
          },
          "default": 0,
          "title": "Y",
          "description": "The y position."
        },
        {
          "name": "resize_source",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Resize Source",
          "description": "Whether to resize the source."
        },
        {
          "name": "mask",
          "type": {
            "type": "comfy.mask"
          },
          "default": {},
          "title": "Mask",
          "description": "The mask to use."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "comfy.latent"
          },
          "name": "latent"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "destination",
        "source",
        "x",
        "y",
        "resize_source",
        "mask"
      ],
      "is_dynamic": false
    },
    {
      "title": "Crop Latent",
      "description": "The Crop Latent node can be used to crop latent images.",
      "namespace": "comfy.latent.__init__",
      "node_type": "comfy.latent.__init__.LatentCrop",
      "layout": "default",
      "properties": [
        {
          "name": "samples",
          "type": {
            "type": "comfy.latent"
          },
          "default": {},
          "title": "Samples",
          "description": "The latent samples to crop."
        },
        {
          "name": "x",
          "type": {
            "type": "int"
          },
          "default": 0,
          "title": "X",
          "description": "The x-coordinate for cropping."
        },
        {
          "name": "y",
          "type": {
            "type": "int"
          },
          "default": 0,
          "title": "Y",
          "description": "The y-coordinate for cropping."
        },
        {
          "name": "width",
          "type": {
            "type": "int"
          },
          "default": 512,
          "title": "Width",
          "description": "The width of the crop."
        },
        {
          "name": "height",
          "type": {
            "type": "int"
          },
          "default": 512,
          "title": "Height",
          "description": "The height of the crop."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "comfy.latent"
          },
          "name": "latent"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "samples",
        "x",
        "y",
        "width",
        "height"
      ],
      "is_dynamic": false
    },
    {
      "title": "Flip Latent",
      "description": "The Flip Latent node can be used to flip latent images.",
      "namespace": "comfy.latent.__init__",
      "node_type": "comfy.latent.__init__.LatentFlip",
      "layout": "default",
      "properties": [
        {
          "name": "samples",
          "type": {
            "type": "comfy.latent"
          },
          "default": {},
          "title": "Samples",
          "description": "The latent samples to flip."
        },
        {
          "name": "horizontal",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Horizontal",
          "description": "Whether to flip horizontally."
        },
        {
          "name": "vertical",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Vertical",
          "description": "Whether to flip vertically."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "comfy.latent"
          },
          "name": "latent"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "samples",
        "horizontal",
        "vertical"
      ],
      "is_dynamic": false
    },
    {
      "title": "Rotate Latent",
      "description": "The Rotate Latent node can be used to rotate latent images.",
      "namespace": "comfy.latent.__init__",
      "node_type": "comfy.latent.__init__.LatentRotate",
      "layout": "default",
      "properties": [
        {
          "name": "samples",
          "type": {
            "type": "comfy.latent"
          },
          "default": {},
          "title": "Samples",
          "description": "The latent samples to rotate."
        },
        {
          "name": "angle",
          "type": {
            "type": "float"
          },
          "default": 0.0,
          "title": "Angle",
          "description": "The angle to rotate the latent by."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "comfy.latent"
          },
          "name": "latent"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "samples",
        "angle"
      ],
      "is_dynamic": false
    },
    {
      "title": "Upscale Latent",
      "description": "The Upscale Latent node can be used to resize latent images.",
      "namespace": "comfy.latent.__init__",
      "node_type": "comfy.latent.__init__.LatentUpscale",
      "layout": "default",
      "properties": [
        {
          "name": "samples",
          "type": {
            "type": "comfy.latent"
          },
          "default": {},
          "title": "Samples",
          "description": "The latent samples to upscale."
        },
        {
          "name": "upscale_method",
          "type": {
            "type": "enum",
            "values": [
              "nearest_exact",
              "bilinear",
              "area",
              "bicubic",
              "bislerp"
            ],
            "type_name": "nodetool.nodes.comfy.latent.__init__.UpScaleMethod"
          },
          "default": "nearest_exact",
          "title": "Upscale Method",
          "description": "The method to use for upscaling."
        },
        {
          "name": "width",
          "type": {
            "type": "int"
          },
          "default": 512,
          "title": "Width",
          "description": "The target width after upscaling.",
          "min": 0.0,
          "max": 16384.0
        },
        {
          "name": "height",
          "type": {
            "type": "int"
          },
          "default": 512,
          "title": "Height",
          "description": "The target height after upscaling.",
          "min": 0.0,
          "max": 16384.0
        },
        {
          "name": "crop",
          "type": {
            "type": "enum",
            "values": [
              "disabled",
              "center"
            ],
            "type_name": "nodetool.nodes.comfy.latent.__init__.CropMethod"
          },
          "default": "disabled",
          "title": "Crop",
          "description": "The method to use for cropping."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "comfy.latent"
          },
          "name": "latent"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "samples",
        "upscale_method",
        "width",
        "height",
        "crop"
      ],
      "is_dynamic": false
    },
    {
      "title": "Upscale Latent By",
      "description": "The Upscale Latent node can be used to resize latent images.",
      "namespace": "comfy.latent.__init__",
      "node_type": "comfy.latent.__init__.LatentUpscaleBy",
      "layout": "default",
      "properties": [
        {
          "name": "samples",
          "type": {
            "type": "comfy.latent"
          },
          "default": {},
          "title": "Samples",
          "description": "The latent samples to upscale."
        },
        {
          "name": "upscale_method",
          "type": {
            "type": "enum",
            "values": [
              "nearest_exact",
              "bilinear",
              "area",
              "bicubic",
              "bislerp"
            ],
            "type_name": "nodetool.nodes.comfy.latent.__init__.UpScaleMethod"
          },
          "default": "nearest_exact",
          "title": "Upscale Method",
          "description": "The method to use for upscaling."
        },
        {
          "name": "scale_by",
          "type": {
            "type": "float"
          },
          "default": 1.5,
          "title": "Scale By",
          "description": "The factor by which to scale.",
          "min": 0.01,
          "max": 8.0
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "comfy.latent"
          },
          "name": "latent"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "samples",
        "upscale_method",
        "scale_by"
      ],
      "is_dynamic": false
    },
    {
      "title": "Save Latent",
      "description": "Save a latent to a file in the specified folder.\n    latent, save, file, storage\n\n    Use cases:\n    - Persist latent data for later use\n    - Export latent results from a workflow\n    - Save intermediate latent outputs for debugging",
      "namespace": "comfy.latent.__init__",
      "node_type": "comfy.latent.__init__.SaveLatent",
      "layout": "default",
      "properties": [
        {
          "name": "samples",
          "type": {
            "type": "comfy.latent"
          },
          "default": {},
          "title": "Samples",
          "description": "The latent samples to save."
        },
        {
          "name": "folder",
          "type": {
            "type": "folder"
          },
          "default": {},
          "title": "Folder",
          "description": "The folder to save the latent in."
        },
        {
          "name": "name",
          "type": {
            "type": "str"
          },
          "default": "latent.latent",
          "title": "Name",
          "description": "The name of the asset to save."
        }
      ],
      "outputs": [],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "samples",
        "folder",
        "name"
      ],
      "is_dynamic": false
    },
    {
      "title": "VAE Decode",
      "description": "The VAE Decode node can be used to decode latent space images back into pixel space images, using the provided VAE.",
      "namespace": "comfy.latent.__init__",
      "node_type": "comfy.latent.__init__.VAEDecode",
      "layout": "default",
      "properties": [
        {
          "name": "samples",
          "type": {
            "type": "comfy.latent"
          },
          "default": {},
          "title": "Samples",
          "description": "The latent samples to decode."
        },
        {
          "name": "vae",
          "type": {
            "type": "comfy.vae"
          },
          "default": {},
          "title": "Vae",
          "description": "The VAE to use."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "image"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "samples",
        "vae"
      ],
      "is_dynamic": false
    },
    {
      "title": "VAEDecode Tiled",
      "description": "The VAE Decode node can be used to decode latent space images back into pixel space images, using the provided VAE.\n    The tiled version of the node is useful for decoding large images that would otherwise exceed the memory limits of the system.",
      "namespace": "comfy.latent.__init__",
      "node_type": "comfy.latent.__init__.VAEDecodeTiled",
      "layout": "default",
      "properties": [
        {
          "name": "samples",
          "type": {
            "type": "comfy.latent"
          },
          "default": {},
          "title": "Samples",
          "description": "The latent samples to decode."
        },
        {
          "name": "vae",
          "type": {
            "type": "comfy.vae"
          },
          "default": {},
          "title": "Vae",
          "description": "The VAE to use for decoding."
        },
        {
          "name": "tile_size",
          "type": {
            "type": "int"
          },
          "default": 512,
          "title": "Tile Size",
          "description": "The size of the tiles to decode.",
          "min": 320.0,
          "max": 4096.0
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "image"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "samples",
        "vae",
        "tile_size"
      ],
      "is_dynamic": false
    },
    {
      "title": "VAE Encode",
      "description": "The VAE Encode node can be used to encode pixel space images into latent space images, using the provided VAE.",
      "namespace": "comfy.latent.__init__",
      "node_type": "comfy.latent.__init__.VAEEncode",
      "layout": "default",
      "properties": [
        {
          "name": "pixels",
          "type": {
            "type": "image"
          },
          "default": {},
          "title": "Pixels",
          "description": "The image to encode."
        },
        {
          "name": "vae",
          "type": {
            "type": "comfy.vae"
          },
          "default": {},
          "title": "Vae",
          "description": "The VAE to use."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "comfy.latent"
          },
          "name": "latent"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "pixels",
        "vae"
      ],
      "is_dynamic": false
    },
    {
      "title": "VAEEncode For Inpaint",
      "description": "The VAE Encode for Inpaint node can be used to encode pixel space images into latent space specifically for inpainting tasks. It takes into account a mask to focus the encoding on specific areas of the image.",
      "namespace": "comfy.latent.__init__",
      "node_type": "comfy.latent.__init__.VAEEncodeForInpaint",
      "layout": "default",
      "properties": [
        {
          "name": "pixels",
          "type": {
            "type": "image"
          },
          "default": {},
          "title": "Pixels",
          "description": "The image pixels to encode for inpainting."
        },
        {
          "name": "vae",
          "type": {
            "type": "comfy.vae"
          },
          "default": {},
          "title": "Vae",
          "description": "The VAE to use for encoding."
        },
        {
          "name": "mask",
          "type": {
            "type": "comfy.mask"
          },
          "default": {},
          "title": "Mask",
          "description": "The mask to apply for inpainting."
        },
        {
          "name": "grow_mask_by",
          "type": {
            "type": "int"
          },
          "default": 6,
          "title": "Grow Mask By",
          "description": "Amount to grow the mask by.",
          "min": 0.0,
          "max": 64.0
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "comfy.latent"
          },
          "name": "latent"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "pixels",
        "vae",
        "mask",
        "grow_mask_by"
      ],
      "is_dynamic": false
    },
    {
      "title": "VAEEncode Tiled",
      "description": "The VAE Encode Tiled node can be used to encode pixel space images into latent space images using a tiled approach. This is useful for encoding large images that might exceed memory limits when processed all at once.",
      "namespace": "comfy.latent.__init__",
      "node_type": "comfy.latent.__init__.VAEEncodeTiled",
      "layout": "default",
      "properties": [
        {
          "name": "pixels",
          "type": {
            "type": "image"
          },
          "default": {},
          "title": "Pixels",
          "description": "The image pixels to encode."
        },
        {
          "name": "vae",
          "type": {
            "type": "comfy.vae"
          },
          "default": {},
          "title": "Vae",
          "description": "The VAE to use for encoding."
        },
        {
          "name": "tile_size",
          "type": {
            "type": "int"
          },
          "default": 512,
          "title": "Tile Size",
          "description": "The size of the tiles to encode.",
          "min": 320.0,
          "max": 4096.0
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "comfy.latent"
          },
          "name": "latent"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "pixels",
        "vae",
        "tile_size"
      ],
      "is_dynamic": false
    },
    {
      "title": "Latent Crop",
      "description": "The Latent Crop node can be used to crop a specific area from latent samples. This operation allows for focusing on particular regions in the latent space, which can be useful for generating or manipulating specific parts of an image.",
      "namespace": "comfy.latent.transform",
      "node_type": "comfy.latent.transform.LatentCrop",
      "layout": "default",
      "properties": [
        {
          "name": "samples",
          "type": {
            "type": "comfy.latent"
          },
          "default": {},
          "title": "Samples",
          "description": "The latent samples to crop."
        },
        {
          "name": "width",
          "type": {
            "type": "int"
          },
          "default": 512,
          "title": "Width",
          "description": "The width of the crop."
        },
        {
          "name": "height",
          "type": {
            "type": "int"
          },
          "default": 512,
          "title": "Height",
          "description": "The height of the crop."
        },
        {
          "name": "x",
          "type": {
            "type": "int"
          },
          "default": 0,
          "title": "X",
          "description": "The x-coordinate for the top-left corner of the crop area."
        },
        {
          "name": "y",
          "type": {
            "type": "int"
          },
          "default": 0,
          "title": "Y",
          "description": "The y-coordinate for the top-left corner of the crop area."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "comfy.latent"
          },
          "name": "latent"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "samples",
        "width",
        "height",
        "x",
        "y"
      ],
      "is_dynamic": false
    },
    {
      "title": "Latent Flip",
      "description": "The Latent Flip node can be used to flip latent samples either horizontally or vertically. This operation allows for mirror transformations in the latent space, which can create interesting variations of the generated images.",
      "namespace": "comfy.latent.transform",
      "node_type": "comfy.latent.transform.LatentFlip",
      "layout": "default",
      "properties": [
        {
          "name": "samples",
          "type": {
            "type": "comfy.latent"
          },
          "default": {},
          "title": "Samples",
          "description": "The latent samples to flip."
        },
        {
          "name": "flip_method",
          "type": {
            "type": "enum",
            "values": [
              "y-axis: horizontally",
              "x-axis: vertically"
            ],
            "type_name": "nodetool.nodes.comfy.latent.transform.FlipMethod"
          },
          "default": "y-axis: horizontally",
          "title": "Flip Method",
          "description": "The method to use for flipping."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "comfy.latent"
          },
          "name": "latent"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "samples",
        "flip_method"
      ],
      "is_dynamic": false
    },
    {
      "title": "Latent Rotate",
      "description": "The Latent Rotate node can be used to rotate latent samples by a specified degree. This allows for orientation adjustments in the latent space, which can be useful for aligning or reorienting generated images.",
      "namespace": "comfy.latent.transform",
      "node_type": "comfy.latent.transform.LatentRotate",
      "layout": "default",
      "properties": [
        {
          "name": "samples",
          "type": {
            "type": "comfy.latent"
          },
          "default": {},
          "title": "Samples",
          "description": "The latent samples to rotate."
        },
        {
          "name": "rotation",
          "type": {
            "type": "enum",
            "values": [
              "none",
              "90 degrees",
              "180 degrees",
              "270 degrees"
            ],
            "type_name": "nodetool.nodes.comfy.latent.transform.Rotation"
          },
          "default": "none",
          "title": "Rotation",
          "description": "The degree of rotation to apply."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "comfy.latent"
          },
          "name": "latent"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "samples",
        "rotation"
      ],
      "is_dynamic": false
    },
    {
      "title": "Empty LTXV Latent Video",
      "description": "Generates an empty latent video tensor.\n    latent, video, ltxv\n\n    Use cases:\n    - Initialize a latent tensor for video generation\n    - Prepare inputs for LTXV-based models",
      "namespace": "comfy.latent.video",
      "node_type": "comfy.latent.video.EmptyLTXVLatentVideo",
      "layout": "default",
      "properties": [
        {
          "name": "width",
          "type": {
            "type": "int"
          },
          "default": 768,
          "title": "Width",
          "description": "Width of the latent video.",
          "min": 64.0,
          "max": 16384.0
        },
        {
          "name": "height",
          "type": {
            "type": "int"
          },
          "default": 512,
          "title": "Height",
          "description": "Height of the latent video.",
          "min": 64.0,
          "max": 16384.0
        },
        {
          "name": "length",
          "type": {
            "type": "int"
          },
          "default": 97,
          "title": "Length",
          "description": "Length (frames) of the latent video.",
          "min": 1.0,
          "max": 16384.0
        },
        {
          "name": "batch_size",
          "type": {
            "type": "int"
          },
          "default": 1,
          "title": "Batch Size",
          "description": "Batch size.",
          "min": 1.0,
          "max": 4096.0
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "comfy.latent"
          },
          "name": "latent"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "width",
        "height",
        "length",
        "batch_size"
      ],
      "is_dynamic": false
    },
    {
      "title": "Empty Mochi Latent Video",
      "description": "The Empty Mochi Latent Video node creates a new set of empty latent\n    images specifically formatted for video processing.",
      "namespace": "comfy.latent.video",
      "node_type": "comfy.latent.video.EmptyMochiLatentVideo",
      "layout": "default",
      "properties": [
        {
          "name": "width",
          "type": {
            "type": "int"
          },
          "default": 848,
          "title": "Width",
          "description": "The width of the latent video to generate.",
          "min": 16.0,
          "max": 16384.0
        },
        {
          "name": "height",
          "type": {
            "type": "int"
          },
          "default": 480,
          "title": "Height",
          "description": "The height of the latent video to generate.",
          "min": 16.0,
          "max": 16384.0
        },
        {
          "name": "length",
          "type": {
            "type": "int"
          },
          "default": 25,
          "title": "Length",
          "description": "The number of frames in the video.",
          "min": 7.0,
          "max": 16384.0
        },
        {
          "name": "batch_size",
          "type": {
            "type": "int"
          },
          "default": 1,
          "title": "Batch Size",
          "description": "The batch size of the latent video to generate.",
          "min": 1.0,
          "max": 4096.0
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "comfy.latent"
          },
          "name": "latent"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "width",
        "height",
        "length",
        "batch_size"
      ],
      "is_dynamic": false
    },
    {
      "title": "Mask Batch",
      "description": "Combine multiple masks into a batch.\n    mask, batch, combine\n\n    Use cases:\n    - Prepare multiple masks for batch processing\n    - Combine masks from different sources\n    - Create mask sequences for animations",
      "namespace": "comfy.essentials.mask",
      "node_type": "comfy.essentials.mask.MaskBatch",
      "layout": "default",
      "properties": [
        {
          "name": "mask1",
          "type": {
            "type": "comfy.mask"
          },
          "default": {},
          "title": "Mask1",
          "description": "First mask to batch."
        },
        {
          "name": "mask2",
          "type": {
            "type": "comfy.mask"
          },
          "default": {},
          "title": "Mask2",
          "description": "Second mask to batch."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "comfy.mask"
          },
          "name": "mask"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "mask1",
        "mask2"
      ],
      "is_dynamic": false
    },
    {
      "title": "Mask Blur",
      "description": "Apply Gaussian blur to a mask.\n    mask, blur, smoothing\n\n    Use cases:\n    - Soften mask edges for smoother transitions\n    - Reduce noise or artifacts in masks\n    - Create gradient effects in masks",
      "namespace": "comfy.essentials.mask",
      "node_type": "comfy.essentials.mask.MaskBlur",
      "layout": "default",
      "properties": [
        {
          "name": "mask",
          "type": {
            "type": "comfy.mask"
          },
          "default": {},
          "title": "Mask",
          "description": "The input mask to blur."
        },
        {
          "name": "amount",
          "type": {
            "type": "int"
          },
          "default": 6,
          "title": "Amount",
          "description": "Blur amount.",
          "min": 0.0,
          "max": 256.0
        },
        {
          "name": "device",
          "type": {
            "type": "str"
          },
          "default": "auto",
          "title": "Device",
          "description": "Device to perform blur on."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "comfy.mask"
          },
          "name": "mask"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "mask",
        "amount",
        "device"
      ],
      "is_dynamic": false
    },
    {
      "title": "Mask Bounding Box",
      "description": "Compute the bounding box of a mask.\n    mask, bounding box, crop\n\n    Use cases:\n    - Focus processing on relevant parts of a mask\n    - Automatically crop masks to content\n    - Extract region of interest from masks",
      "namespace": "comfy.essentials.mask",
      "node_type": "comfy.essentials.mask.MaskBoundingBox",
      "layout": "default",
      "properties": [
        {
          "name": "mask",
          "type": {
            "type": "comfy.mask"
          },
          "default": {},
          "title": "Mask",
          "description": "The input mask."
        },
        {
          "name": "padding",
          "type": {
            "type": "int"
          },
          "default": 0,
          "title": "Padding",
          "description": "Padding around bounding box.",
          "min": 0.0,
          "max": 4096.0
        },
        {
          "name": "blur",
          "type": {
            "type": "int"
          },
          "default": 0,
          "title": "Blur",
          "description": "Blur amount for mask edges.",
          "min": 0.0,
          "max": 256.0
        },
        {
          "name": "image_optional",
          "type": {
            "type": "image"
          },
          "title": "Image Optional",
          "description": "Optional image to crop alongside mask."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "comfy.mask"
          },
          "name": "mask"
        },
        {
          "type": {
            "type": "image"
          },
          "name": "image"
        },
        {
          "type": {
            "type": "int"
          },
          "name": "x"
        },
        {
          "type": {
            "type": "int"
          },
          "name": "y"
        },
        {
          "type": {
            "type": "int"
          },
          "name": "width"
        },
        {
          "type": {
            "type": "int"
          },
          "name": "height"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "mask",
        "padding",
        "blur",
        "image_optional"
      ],
      "is_dynamic": false
    },
    {
      "title": "Mask Expand Batch",
      "description": "Expand a mask batch to a specified size.\n    mask, batch, expand\n\n    Use cases:\n    - Increase the number of masks in a batch\n    - Replicate masks for extended animations\n    - Adjust mask batch size for compatibility",
      "namespace": "comfy.essentials.mask",
      "node_type": "comfy.essentials.mask.MaskExpandBatch",
      "layout": "default",
      "properties": [
        {
          "name": "mask",
          "type": {
            "type": "comfy.mask"
          },
          "default": {},
          "title": "Mask",
          "description": "The mask batch to expand."
        },
        {
          "name": "size",
          "type": {
            "type": "int"
          },
          "default": 16,
          "title": "Size",
          "description": "Target batch size.",
          "min": 1.0
        },
        {
          "name": "method",
          "type": {
            "type": "str"
          },
          "default": "expand",
          "title": "Method",
          "description": "Method for expanding the batch."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "comfy.mask"
          },
          "name": "mask"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "mask",
        "size",
        "method"
      ],
      "is_dynamic": false
    },
    {
      "title": "Mask Fix",
      "description": "Apply various fixes and adjustments to a mask.\n    mask, fix, adjust\n\n    Use cases:\n    - Clean up noisy or imperfect masks\n    - Refine mask edges and shapes\n    - Prepare masks for specific processing requirements",
      "namespace": "comfy.essentials.mask",
      "node_type": "comfy.essentials.mask.MaskFix",
      "layout": "default",
      "properties": [
        {
          "name": "mask",
          "type": {
            "type": "comfy.mask"
          },
          "default": {},
          "title": "Mask",
          "description": "The input mask to fix."
        },
        {
          "name": "erode_dilate",
          "type": {
            "type": "int"
          },
          "default": 0,
          "title": "Erode Dilate",
          "description": "Erode (negative) or dilate (positive) mask.",
          "min": -256.0,
          "max": 256.0
        },
        {
          "name": "fill_holes",
          "type": {
            "type": "int"
          },
          "default": 0,
          "title": "Fill Holes",
          "description": "Size of holes to fill.",
          "min": 0.0,
          "max": 128.0
        },
        {
          "name": "remove_isolated_pixels",
          "type": {
            "type": "int"
          },
          "default": 0,
          "title": "Remove Isolated Pixels",
          "description": "Size of isolated pixel areas to remove.",
          "min": 0.0,
          "max": 32.0
        },
        {
          "name": "smooth",
          "type": {
            "type": "int"
          },
          "default": 0,
          "title": "Smooth",
          "description": "Smoothing amount for mask edges.",
          "min": 0.0,
          "max": 256.0
        },
        {
          "name": "blur",
          "type": {
            "type": "int"
          },
          "default": 0,
          "title": "Blur",
          "description": "Blur amount for entire mask.",
          "min": 0.0,
          "max": 256.0
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "comfy.mask"
          },
          "name": "mask"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "mask",
        "erode_dilate",
        "fill_holes",
        "remove_isolated_pixels",
        "smooth",
        "blur"
      ],
      "is_dynamic": false
    },
    {
      "title": "Mask Flip",
      "description": "Flip a mask along specified axis.\n    mask, flip, mirror\n\n    Use cases:\n    - Create symmetrical masks\n    - Correct orientation of imported masks\n    - Generate variations of existing masks",
      "namespace": "comfy.essentials.mask",
      "node_type": "comfy.essentials.mask.MaskFlip",
      "layout": "default",
      "properties": [
        {
          "name": "mask",
          "type": {
            "type": "comfy.mask"
          },
          "default": {},
          "title": "Mask",
          "description": "The input mask to flip."
        },
        {
          "name": "axis",
          "type": {
            "type": "str"
          },
          "default": "x",
          "title": "Axis",
          "description": "Axis to flip along: 'x', 'y', or 'xy'."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "comfy.mask"
          },
          "name": "mask"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "mask",
        "axis"
      ],
      "is_dynamic": false
    },
    {
      "title": "Mask From Color",
      "description": "Create a mask from a specific color in an image.\n    mask, color, extraction\n\n    Use cases:\n    - Extract objects of a specific color\n    - Create masks for color-coded regions\n    - Isolate elements based on color information",
      "namespace": "comfy.essentials.mask",
      "node_type": "comfy.essentials.mask.MaskFromColor",
      "layout": "default",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {},
          "title": "Image",
          "description": "The input image."
        },
        {
          "name": "red",
          "type": {
            "type": "int"
          },
          "default": 255,
          "title": "Red",
          "description": "Red component of target color.",
          "min": 0.0,
          "max": 255.0
        },
        {
          "name": "green",
          "type": {
            "type": "int"
          },
          "default": 255,
          "title": "Green",
          "description": "Green component of target color.",
          "min": 0.0,
          "max": 255.0
        },
        {
          "name": "blue",
          "type": {
            "type": "int"
          },
          "default": 255,
          "title": "Blue",
          "description": "Blue component of target color.",
          "min": 0.0,
          "max": 255.0
        },
        {
          "name": "threshold",
          "type": {
            "type": "int"
          },
          "default": 0,
          "title": "Threshold",
          "description": "Color matching threshold.",
          "min": 0.0,
          "max": 127.0
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "comfy.mask"
          },
          "name": "mask"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "image",
        "red",
        "green",
        "blue",
        "threshold"
      ],
      "is_dynamic": false
    },
    {
      "title": "Mask From Segmentation",
      "description": "Generate masks from image segmentation.\n    mask, segmentation, color quantization\n\n    Use cases:\n    - Create masks for distinct regions in an image\n    - Separate image elements based on color\n    - Prepare masks for selective processing",
      "namespace": "comfy.essentials.mask",
      "node_type": "comfy.essentials.mask.MaskFromSegmentation",
      "layout": "default",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {},
          "title": "Image",
          "description": "The input image to segment."
        },
        {
          "name": "segments",
          "type": {
            "type": "int"
          },
          "default": 6,
          "title": "Segments",
          "description": "Number of color segments.",
          "min": 1.0,
          "max": 16.0
        },
        {
          "name": "remove_isolated_pixels",
          "type": {
            "type": "int"
          },
          "default": 0,
          "title": "Remove Isolated Pixels",
          "description": "Size of isolated pixel areas to remove.",
          "min": 0.0,
          "max": 32.0
        },
        {
          "name": "remove_small_masks",
          "type": {
            "type": "float"
          },
          "default": 0.0,
          "title": "Remove Small Masks",
          "description": "Relative size of small masks to remove.",
          "min": 0.0,
          "max": 1.0
        },
        {
          "name": "fill_holes",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Fill Holes",
          "description": "Whether to fill holes in masks."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "comfy.mask"
          },
          "name": "mask"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "image",
        "segments",
        "remove_isolated_pixels",
        "remove_small_masks",
        "fill_holes"
      ],
      "is_dynamic": false
    },
    {
      "title": "Mask Preview",
      "description": "Generate a preview image of a mask.\n    mask, preview, visualization\n\n    Use cases:\n    - Visualize mask content during workflow\n    - Debug mask generation steps\n    - Export mask as viewable image",
      "namespace": "comfy.essentials.mask",
      "node_type": "comfy.essentials.mask.MaskPreview",
      "layout": "default",
      "properties": [
        {
          "name": "mask",
          "type": {
            "type": "comfy.mask"
          },
          "default": {},
          "title": "Mask",
          "description": "The mask to preview."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "image"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "mask"
      ],
      "is_dynamic": false
    },
    {
      "title": "Transition Mask",
      "description": "Generate a sequence of transition masks.\n    mask, transition, animation\n\n    Use cases:\n    - Create smooth transitions between images or videos\n    - Generate mask sequences for special effects\n    - Produce animated mask patterns",
      "namespace": "comfy.essentials.mask",
      "node_type": "comfy.essentials.mask.TransitionMask",
      "layout": "default",
      "properties": [
        {
          "name": "width",
          "type": {
            "type": "int"
          },
          "default": 512,
          "title": "Width",
          "description": "Width of the mask.",
          "min": 1.0,
          "max": 8192.0
        },
        {
          "name": "height",
          "type": {
            "type": "int"
          },
          "default": 512,
          "title": "Height",
          "description": "Height of the mask.",
          "min": 1.0,
          "max": 8192.0
        },
        {
          "name": "frames",
          "type": {
            "type": "int"
          },
          "default": 16,
          "title": "Frames",
          "description": "Total number of frames.",
          "min": 1.0,
          "max": 9999.0
        },
        {
          "name": "start_frame",
          "type": {
            "type": "int"
          },
          "default": 0,
          "title": "Start Frame",
          "description": "Frame to start transition.",
          "min": 0.0
        },
        {
          "name": "end_frame",
          "type": {
            "type": "int"
          },
          "default": 9999,
          "title": "End Frame",
          "description": "Frame to end transition.",
          "min": 0.0
        },
        {
          "name": "transition_type",
          "type": {
            "type": "str"
          },
          "default": "horizontal slide",
          "title": "Transition Type",
          "description": "Type of transition effect."
        },
        {
          "name": "timing_function",
          "type": {
            "type": "str"
          },
          "default": "linear",
          "title": "Timing Function",
          "description": "Timing function for transition."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "comfy.mask"
          },
          "name": "mask"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "width",
        "height",
        "frames",
        "start_frame",
        "end_frame",
        "transition_type",
        "timing_function"
      ],
      "is_dynamic": false
    },
    {
      "title": "Batch Count",
      "description": "Count the number of items in a batch.\n    batch, count, size\n\n    Use cases:\n    - Determine the size of batched data\n    - Verify batch dimensions in workflows\n    - Adapt processing based on batch size",
      "namespace": "comfy.essentials.misc",
      "node_type": "comfy.essentials.misc.BatchCount",
      "layout": "default",
      "properties": [
        {
          "name": "batch",
          "type": {
            "type": "any"
          },
          "title": "Batch",
          "description": "Batch to count items from."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "int"
          },
          "name": "count"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "batch"
      ],
      "is_dynamic": false
    },
    {
      "title": "Console Debug",
      "description": "Output debug information to the console.\n    debug, logging, console\n\n    Use cases:\n    - Print variable values for debugging\n    - Log intermediate results in complex workflows\n    - Verify data flow through nodes",
      "namespace": "comfy.essentials.misc",
      "node_type": "comfy.essentials.misc.ConsoleDebug",
      "layout": "default",
      "properties": [
        {
          "name": "value",
          "type": {
            "type": "any"
          },
          "title": "Value",
          "description": "Value to debug."
        },
        {
          "name": "prefix",
          "type": {
            "type": "str"
          },
          "default": "Value:",
          "title": "Prefix",
          "description": "Prefix for the debug output."
        }
      ],
      "outputs": [],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "value",
        "prefix"
      ],
      "is_dynamic": false
    },
    {
      "title": "Debug Tensor Shape",
      "description": "Output the shape of a tensor for debugging.\n    debug, tensor, shape\n\n    Use cases:\n    - Verify tensor dimensions in workflows\n    - Debug shape mismatches in tensor operations\n    - Inspect complex nested tensor structures",
      "namespace": "comfy.essentials.misc",
      "node_type": "comfy.essentials.misc.DebugTensorShape",
      "layout": "default",
      "properties": [
        {
          "name": "tensor",
          "type": {
            "type": "any"
          },
          "title": "Tensor",
          "description": "Tensor or structure containing tensors to inspect."
        }
      ],
      "outputs": [],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "tensor"
      ],
      "is_dynamic": false
    },
    {
      "title": "Model Compile",
      "description": "Compile a PyTorch model for optimized execution.\n    model, compilation, optimization\n\n    Use cases:\n    - Optimize model performance\n    - Prepare models for specific execution environments\n    - Fine-tune model compilation settings",
      "namespace": "comfy.essentials.misc",
      "node_type": "comfy.essentials.misc.ModelCompile",
      "layout": "default",
      "properties": [
        {
          "name": "model",
          "type": {
            "type": "comfy.unet"
          },
          "title": "Model",
          "description": "Model to compile."
        },
        {
          "name": "fullgraph",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Fullgraph",
          "description": "Use full graph compilation."
        },
        {
          "name": "dynamic",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Dynamic",
          "description": "Use dynamic shape compilation."
        },
        {
          "name": "mode",
          "type": {
            "type": "str"
          },
          "default": "default",
          "title": "Mode",
          "description": "Compilation mode."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "comfy.unet"
          },
          "name": "model"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "model",
        "fullgraph",
        "dynamic",
        "mode"
      ],
      "is_dynamic": false
    },
    {
      "title": "Remove Latent Mask",
      "description": "Remove the noise mask from a latent sample.\n    latent, mask, cleanup\n\n    Use cases:\n    - Clean up latent representations\n    - Prepare latents for specific processing steps\n    - Remove unwanted mask information",
      "namespace": "comfy.essentials.misc",
      "node_type": "comfy.essentials.misc.RemoveLatentMask",
      "layout": "default",
      "properties": [
        {
          "name": "samples",
          "type": {
            "type": "comfy.latent"
          },
          "title": "Samples",
          "description": "Latent samples to process."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "comfy.latent"
          },
          "name": "latent"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "samples"
      ],
      "is_dynamic": false
    },
    {
      "title": "SDXLEmpty Latent Size Picker",
      "description": "Create empty latents with specific sizes for SDXL.\n    latent, size, SDXL\n\n    Use cases:\n    - Initialize latent spaces for SDXL UNets\n    - Prepare custom-sized latents for generation\n    - Set up batch processing with specific dimensions",
      "namespace": "comfy.essentials.misc",
      "node_type": "comfy.essentials.misc.SDXLEmptyLatentSizePicker",
      "layout": "default",
      "properties": [
        {
          "name": "resolution",
          "type": {
            "type": "str"
          },
          "default": "1024x1024 (1.0)",
          "title": "Resolution",
          "description": "Predefined resolution option."
        },
        {
          "name": "batch_size",
          "type": {
            "type": "int"
          },
          "default": 1,
          "title": "Batch Size",
          "description": "Number of latents in the batch.",
          "min": 1.0,
          "max": 4096.0
        },
        {
          "name": "width_override",
          "type": {
            "type": "int"
          },
          "default": 0,
          "title": "Width Override",
          "description": "Custom width (if non-zero).",
          "min": 0.0,
          "max": 8192.0
        },
        {
          "name": "height_override",
          "type": {
            "type": "int"
          },
          "default": 0,
          "title": "Height Override",
          "description": "Custom height (if non-zero).",
          "min": 0.0,
          "max": 8192.0
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "comfy.latent"
          },
          "name": "latent"
        },
        {
          "type": {
            "type": "int"
          },
          "name": "width"
        },
        {
          "type": {
            "type": "int"
          },
          "name": "height"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "resolution",
        "batch_size",
        "width_override",
        "height_override"
      ],
      "is_dynamic": false
    },
    {
      "title": "Simple Comparison",
      "description": "Perform a comparison between two values.\n    comparison, logic, equality\n\n    Use cases:\n    - Compare numeric or other values\n    - Create boolean flags based on comparisons\n    - Implement decision logic in workflows",
      "namespace": "comfy.essentials.misc",
      "node_type": "comfy.essentials.misc.SimpleComparison",
      "layout": "default",
      "properties": [
        {
          "name": "a",
          "type": {
            "type": "any"
          },
          "default": 0,
          "title": "A",
          "description": "First value to compare."
        },
        {
          "name": "b",
          "type": {
            "type": "any"
          },
          "default": 0,
          "title": "B",
          "description": "Second value to compare."
        },
        {
          "name": "comparison",
          "type": {
            "type": "str"
          },
          "default": "==",
          "title": "Comparison",
          "description": "Comparison operator."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "bool"
          },
          "name": "result"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "a",
        "b",
        "comparison"
      ],
      "is_dynamic": false
    },
    {
      "title": "Simple Condition",
      "description": "Perform a simple conditional operation.\n    condition, branching, logic\n\n    Use cases:\n    - Implement basic if-else logic\n    - Route between two possible values based on a condition\n    - Create dynamic workflows with branching",
      "namespace": "comfy.essentials.misc",
      "node_type": "comfy.essentials.misc.SimpleCondition",
      "layout": "default",
      "properties": [
        {
          "name": "evaluate",
          "type": {
            "type": "any"
          },
          "default": 0,
          "title": "Evaluate",
          "description": "Condition to evaluate."
        },
        {
          "name": "on_true",
          "type": {
            "type": "any"
          },
          "default": 0,
          "title": "On True",
          "description": "Value to return if condition is true."
        },
        {
          "name": "on_false",
          "type": {
            "type": "any"
          },
          "default": 0,
          "title": "On False",
          "description": "Value to return if condition is false."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "any"
          },
          "name": "value"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "evaluate",
        "on_true",
        "on_false"
      ],
      "is_dynamic": false
    },
    {
      "title": "Simple Math",
      "description": "Perform custom mathematical operations.\n    math, calculation, expression\n\n    Use cases:\n    - Evaluate complex mathematical expressions\n    - Combine multiple numeric inputs\n    - Implement custom numeric logic",
      "namespace": "comfy.essentials.misc",
      "node_type": "comfy.essentials.misc.SimpleMath",
      "layout": "default",
      "properties": [
        {
          "name": "a",
          "type": {
            "type": "union",
            "type_args": [
              {
                "type": "int"
              },
              {
                "type": "float"
              }
            ]
          },
          "default": 0.0,
          "title": "A",
          "description": "First optional value."
        },
        {
          "name": "b",
          "type": {
            "type": "union",
            "type_args": [
              {
                "type": "int"
              },
              {
                "type": "float"
              }
            ]
          },
          "default": 0.0,
          "title": "B",
          "description": "Second optional value."
        },
        {
          "name": "c",
          "type": {
            "type": "union",
            "type_args": [
              {
                "type": "int"
              },
              {
                "type": "float"
              }
            ]
          },
          "default": 0.0,
          "title": "C",
          "description": "Third optional value."
        },
        {
          "name": "value",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Value",
          "description": "Mathematical expression to evaluate."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "int"
          },
          "name": "int_result"
        },
        {
          "type": {
            "type": "float"
          },
          "name": "float_result"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "a",
        "b",
        "c",
        "value"
      ],
      "is_dynamic": false
    },
    {
      "title": "Simple Math Boolean",
      "description": "Represent a boolean value.\n    boolean, toggle, switch, condition, logic\n\n    Use cases:\n    - Provide on/off switches for features\n    - Control conditional logic\n    - Toggle between two states",
      "namespace": "comfy.essentials.misc",
      "node_type": "comfy.essentials.misc.SimpleMathBoolean",
      "layout": "default",
      "properties": [
        {
          "name": "value",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Value",
          "description": "Boolean value."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "bool"
          },
          "name": "value"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "value"
      ],
      "is_dynamic": false
    },
    {
      "title": "Simple Math Condition",
      "description": "Perform conditional mathematical operations.\n    condition, math, branching\n\n    Use cases:\n    - Implement if-else logic with mathematical outcomes\n    - Create dynamic value selection based on conditions\n    - Combine conditional and mathematical operations",
      "namespace": "comfy.essentials.misc",
      "node_type": "comfy.essentials.misc.SimpleMathCondition",
      "layout": "default",
      "properties": [
        {
          "name": "a",
          "type": {
            "type": "any"
          },
          "default": 0.0,
          "title": "A",
          "description": "First optional value."
        },
        {
          "name": "b",
          "type": {
            "type": "any"
          },
          "default": 0.0,
          "title": "B",
          "description": "Second optional value."
        },
        {
          "name": "c",
          "type": {
            "type": "any"
          },
          "default": 0.0,
          "title": "C",
          "description": "Third optional value."
        },
        {
          "name": "evaluate",
          "type": {
            "type": "any"
          },
          "default": 0,
          "title": "Evaluate",
          "description": "Condition to evaluate."
        },
        {
          "name": "on_true",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "On True",
          "description": "Expression to evaluate if condition is true."
        },
        {
          "name": "on_false",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "On False",
          "description": "Expression to evaluate if condition is false."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "int"
          },
          "name": "int_result"
        },
        {
          "type": {
            "type": "float"
          },
          "name": "float_result"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "a",
        "b",
        "c",
        "evaluate",
        "on_true",
        "on_false"
      ],
      "is_dynamic": false
    },
    {
      "title": "Simple Math Float",
      "description": "Represent a floating-point number.\n    float, number, value\n\n    Use cases:\n    - Input precise decimal values\n    - Represent fractional numbers in calculations\n    - Provide flexible numeric inputs",
      "namespace": "comfy.essentials.misc",
      "node_type": "comfy.essentials.misc.SimpleMathFloat",
      "layout": "default",
      "properties": [
        {
          "name": "value",
          "type": {
            "type": "float"
          },
          "default": 0.0,
          "title": "Value",
          "description": "Floating-point value."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "float"
          },
          "name": "value"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "value"
      ],
      "is_dynamic": false
    },
    {
      "title": "Simple Math Int",
      "description": "Represent an integer number.\n    integer, number, value\n\n    Use cases:\n    - Input whole number values\n    - Specify counts or indices\n    - Provide discrete numeric inputs",
      "namespace": "comfy.essentials.misc",
      "node_type": "comfy.essentials.misc.SimpleMathInt",
      "layout": "default",
      "properties": [
        {
          "name": "value",
          "type": {
            "type": "int"
          },
          "default": 0,
          "title": "Value",
          "description": "Integer value."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "int"
          },
          "name": "value"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "value"
      ],
      "is_dynamic": false
    },
    {
      "title": "Simple Math Percent",
      "description": "Represent a percentage value.\n    percent, ratio, proportion\n\n    Use cases:\n    - Input percentage values for scaling operations\n    - Represent probabilities or ratios\n    - Control strength of effects or blending",
      "namespace": "comfy.essentials.misc",
      "node_type": "comfy.essentials.misc.SimpleMathPercent",
      "layout": "default",
      "properties": [
        {
          "name": "value",
          "type": {
            "type": "float"
          },
          "default": 0.0,
          "title": "Value",
          "description": "Percentage value (0-1).",
          "min": 0.0,
          "max": 1.0
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "float"
          },
          "name": "value"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "value"
      ],
      "is_dynamic": false
    },
    {
      "title": "Simple Math Slider",
      "description": "Provide a slider for float input.\n    slider, float, range\n\n    Use cases:\n    - Intuitive input for ranged values\n    - Fine-tune parameters visually\n    - Provide bounded numeric inputs",
      "namespace": "comfy.essentials.misc",
      "node_type": "comfy.essentials.misc.SimpleMathSlider",
      "layout": "default",
      "properties": [
        {
          "name": "value",
          "type": {
            "type": "float"
          },
          "default": 0.5,
          "title": "Value",
          "description": "Slider value.",
          "min": 0.0,
          "max": 1.0
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "float"
          },
          "name": "value"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "value"
      ],
      "is_dynamic": false
    },
    {
      "title": "Draw Text",
      "description": "Draw text on an image or create a new image with text.\n    text, image, drawing\n\n    Use cases:\n    - Add captions or labels to images\n    - Create text-based images for graphics or designs\n    - Overlay text on existing images with customizable styles",
      "namespace": "comfy.essentials.text",
      "node_type": "comfy.essentials.text.DrawText",
      "layout": "default",
      "properties": [
        {
          "name": "text",
          "type": {
            "type": "str"
          },
          "default": "Hello, World!",
          "title": "Text",
          "description": "The text to draw"
        },
        {
          "name": "font",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Font",
          "description": "Font file name"
        },
        {
          "name": "size",
          "type": {
            "type": "int"
          },
          "default": 56,
          "title": "Size",
          "description": "Font size",
          "min": 1.0,
          "max": 9999.0
        },
        {
          "name": "color",
          "type": {
            "type": "str"
          },
          "default": "#FFFFFF",
          "title": "Color",
          "description": "Text color in hex format"
        },
        {
          "name": "background_color",
          "type": {
            "type": "str"
          },
          "default": "#00000000",
          "title": "Background Color",
          "description": "Background color in hex format"
        },
        {
          "name": "shadow_distance",
          "type": {
            "type": "int"
          },
          "default": 0,
          "title": "Shadow Distance",
          "description": "Shadow distance",
          "min": 0.0,
          "max": 100.0
        },
        {
          "name": "shadow_blur",
          "type": {
            "type": "int"
          },
          "default": 0,
          "title": "Shadow Blur",
          "description": "Shadow blur amount",
          "min": 0.0,
          "max": 100.0
        },
        {
          "name": "shadow_color",
          "type": {
            "type": "str"
          },
          "default": "#000000",
          "title": "Shadow Color",
          "description": "Shadow color in hex format"
        },
        {
          "name": "horizontal_align",
          "type": {
            "type": "enum",
            "values": [
              "left",
              "center",
              "right"
            ],
            "type_name": "nodetool.nodes.comfy.essentials.text.HorizontalAlign"
          },
          "default": "left",
          "title": "Horizontal Align",
          "description": "Horizontal alignment"
        },
        {
          "name": "vertical_align",
          "type": {
            "type": "enum",
            "values": [
              "top",
              "center",
              "bottom"
            ],
            "type_name": "nodetool.nodes.comfy.essentials.text.VerticalAlign"
          },
          "default": "top",
          "title": "Vertical Align",
          "description": "Vertical alignment"
        },
        {
          "name": "offset_x",
          "type": {
            "type": "int"
          },
          "default": 0,
          "title": "Offset X",
          "description": "Horizontal offset",
          "min": -10000.0,
          "max": 10000.0
        },
        {
          "name": "offset_y",
          "type": {
            "type": "int"
          },
          "default": 0,
          "title": "Offset Y",
          "description": "Vertical offset",
          "min": -10000.0,
          "max": 10000.0
        },
        {
          "name": "direction",
          "type": {
            "type": "enum",
            "values": [
              "ltr",
              "rtl"
            ],
            "type_name": "nodetool.nodes.comfy.essentials.text.Direction"
          },
          "default": "ltr",
          "title": "Direction",
          "description": "Text direction"
        },
        {
          "name": "img_composite",
          "type": {
            "type": "image",
            "optional": true
          },
          "title": "Img Composite",
          "description": "Optional background image"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "image"
        },
        {
          "type": {
            "type": "comfy.mask"
          },
          "name": "mask"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "text",
        "font",
        "size",
        "color",
        "background_color",
        "shadow_distance",
        "shadow_blur",
        "shadow_color",
        "horizontal_align",
        "vertical_align",
        "offset_x",
        "offset_y",
        "direction",
        "img_composite"
      ],
      "is_dynamic": false
    },
    {
      "title": "Flux Sampler Params",
      "description": "Set up parameters for Flux sampler.\n    sampling, flux, parameters\n\n    Use cases:\n    - Configure advanced sampling parameters\n    - Experiment with different sampling settings\n    - Fine-tune the sampling process for specific outputs",
      "namespace": "comfy.essentials.sampling",
      "node_type": "comfy.essentials.sampling.FluxSamplerParams",
      "layout": "default",
      "properties": [
        {
          "name": "model",
          "type": {
            "type": "comfy.unet"
          },
          "default": {},
          "title": "Model",
          "description": "The model to use"
        },
        {
          "name": "conditioning",
          "type": {
            "type": "comfy.conditioning"
          },
          "default": {},
          "title": "Conditioning",
          "description": "The conditioning to use"
        },
        {
          "name": "latent_image",
          "type": {
            "type": "comfy.latent"
          },
          "default": {},
          "title": "Latent Image",
          "description": "The input latent image"
        },
        {
          "name": "seed",
          "type": {
            "type": "str"
          },
          "default": "?",
          "title": "Seed",
          "description": "Sampling seed"
        },
        {
          "name": "sampler",
          "type": {
            "type": "str"
          },
          "default": "euler",
          "title": "Sampler",
          "description": "Sampler name"
        },
        {
          "name": "scheduler",
          "type": {
            "type": "str"
          },
          "default": "simple",
          "title": "Scheduler",
          "description": "Scheduler name"
        },
        {
          "name": "steps",
          "type": {
            "type": "str"
          },
          "default": "20",
          "title": "Steps",
          "description": "Number of steps"
        },
        {
          "name": "guidance",
          "type": {
            "type": "str"
          },
          "default": "3.5",
          "title": "Guidance",
          "description": "Guidance scale"
        },
        {
          "name": "max_shift",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Max Shift",
          "description": "Max shift"
        },
        {
          "name": "base_shift",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Base Shift",
          "description": "Base shift"
        },
        {
          "name": "denoise",
          "type": {
            "type": "str"
          },
          "default": "1.0",
          "title": "Denoise",
          "description": "Denoising strength"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "comfy.latent"
          },
          "name": "latent"
        },
        {
          "type": {
            "type": "dict"
          },
          "name": "params"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "model",
        "conditioning",
        "latent_image",
        "seed",
        "sampler",
        "scheduler",
        "steps",
        "guidance",
        "max_shift",
        "base_shift",
        "denoise"
      ],
      "is_dynamic": false
    },
    {
      "title": "Inject Latent Noise",
      "description": "Inject noise into a latent image.\n    latent, noise, injection\n\n    Use cases:\n    - Add controlled randomness to latent representations\n    - Create variations of latent images\n    - Augment latent space for more diverse outputs",
      "namespace": "comfy.essentials.sampling",
      "node_type": "comfy.essentials.sampling.InjectLatentNoise",
      "layout": "default",
      "properties": [
        {
          "name": "latent",
          "type": {
            "type": "comfy.latent"
          },
          "default": {},
          "title": "Latent",
          "description": "The input latent image"
        },
        {
          "name": "noise_seed",
          "type": {
            "type": "int"
          },
          "default": 0,
          "title": "Noise Seed",
          "description": "Seed for noise generation"
        },
        {
          "name": "noise_strength",
          "type": {
            "type": "float"
          },
          "default": 1.0,
          "title": "Noise Strength",
          "description": "Strength of injected noise"
        },
        {
          "name": "normalize",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Normalize",
          "description": "Whether to normalize the noise"
        },
        {
          "name": "mask",
          "type": {
            "type": "image",
            "optional": true
          },
          "title": "Mask",
          "description": "Optional mask for noise injection"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "comfy.latent"
          },
          "name": "latent"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "latent",
        "noise_seed",
        "noise_strength",
        "normalize",
        "mask"
      ],
      "is_dynamic": false
    },
    {
      "title": "KSampler Variations Stochastic",
      "description": "Generate variations of an image using stochastic sampling.\n    sampling, variations, stochastic\n\n    Use cases:\n    - Create diverse variations of an image\n    - Explore different sampling outcomes\n    - Generate multiple versions with subtle differences",
      "namespace": "comfy.essentials.sampling",
      "node_type": "comfy.essentials.sampling.KSamplerVariationsStochastic",
      "layout": "default",
      "properties": [
        {
          "name": "model",
          "type": {
            "type": "comfy.unet"
          },
          "default": {},
          "title": "Model",
          "description": "The model to use for sampling"
        },
        {
          "name": "latent_image",
          "type": {
            "type": "comfy.latent"
          },
          "default": {},
          "title": "Latent Image",
          "description": "The input latent image"
        },
        {
          "name": "noise_seed",
          "type": {
            "type": "int"
          },
          "default": 0,
          "title": "Noise Seed",
          "description": "Seed for noise generation"
        },
        {
          "name": "steps",
          "type": {
            "type": "int"
          },
          "default": 25,
          "title": "Steps",
          "description": "Number of sampling steps"
        },
        {
          "name": "cfg",
          "type": {
            "type": "float"
          },
          "default": 7.0,
          "title": "Cfg",
          "description": "Classifier-free guidance scale"
        },
        {
          "name": "sampler",
          "type": {
            "type": "str"
          },
          "default": "euler",
          "title": "Sampler",
          "description": "Sampler to use"
        },
        {
          "name": "scheduler",
          "type": {
            "type": "str"
          },
          "default": "normal",
          "title": "Scheduler",
          "description": "Scheduler to use"
        },
        {
          "name": "positive",
          "type": {
            "type": "comfy.conditioning"
          },
          "default": {},
          "title": "Positive",
          "description": "Positive conditioning"
        },
        {
          "name": "negative",
          "type": {
            "type": "comfy.conditioning"
          },
          "default": {},
          "title": "Negative",
          "description": "Negative conditioning"
        },
        {
          "name": "variation_seed",
          "type": {
            "type": "int"
          },
          "default": 0,
          "title": "Variation Seed",
          "description": "Seed for variations"
        },
        {
          "name": "variation_strength",
          "type": {
            "type": "float"
          },
          "default": 0.2,
          "title": "Variation Strength",
          "description": "Strength of variations"
        },
        {
          "name": "cfg_scale",
          "type": {
            "type": "float"
          },
          "default": 1.0,
          "title": "Cfg Scale",
          "description": "Scale for classifier-free guidance"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "comfy.latent"
          },
          "name": "latent"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "model",
        "latent_image",
        "noise_seed",
        "steps",
        "cfg",
        "sampler",
        "scheduler",
        "positive",
        "negative",
        "variation_seed",
        "variation_strength",
        "cfg_scale"
      ],
      "is_dynamic": false
    },
    {
      "title": "KSampler Variations With Noise",
      "description": "Generate variations by injecting noise during sampling.\n    sampling, variations, noise\n\n    Use cases:\n    - Add controlled randomness to sampling process\n    - Create variations with noise injection\n    - Fine-tune the balance between original and varied outputs",
      "namespace": "comfy.essentials.sampling",
      "node_type": "comfy.essentials.sampling.KSamplerVariationsWithNoise",
      "layout": "default",
      "properties": [
        {
          "name": "model",
          "type": {
            "type": "comfy.unet"
          },
          "default": {},
          "title": "Model",
          "description": "The model to use for sampling"
        },
        {
          "name": "latent_image",
          "type": {
            "type": "comfy.latent"
          },
          "default": {},
          "title": "Latent Image",
          "description": "The input latent image"
        },
        {
          "name": "main_seed",
          "type": {
            "type": "int"
          },
          "default": 0,
          "title": "Main Seed",
          "description": "Main seed for sampling"
        },
        {
          "name": "steps",
          "type": {
            "type": "int"
          },
          "default": 20,
          "title": "Steps",
          "description": "Number of sampling steps"
        },
        {
          "name": "cfg",
          "type": {
            "type": "float"
          },
          "default": 8.0,
          "title": "Cfg",
          "description": "Classifier-free guidance scale"
        },
        {
          "name": "sampler_name",
          "type": {
            "type": "str"
          },
          "default": "euler",
          "title": "Sampler Name",
          "description": "Name of sampler to use"
        },
        {
          "name": "scheduler",
          "type": {
            "type": "str"
          },
          "default": "normal",
          "title": "Scheduler",
          "description": "Name of scheduler to use"
        },
        {
          "name": "positive",
          "type": {
            "type": "comfy.conditioning"
          },
          "default": {},
          "title": "Positive",
          "description": "Positive conditioning"
        },
        {
          "name": "negative",
          "type": {
            "type": "comfy.conditioning"
          },
          "default": {},
          "title": "Negative",
          "description": "Negative conditioning"
        },
        {
          "name": "variation_strength",
          "type": {
            "type": "float"
          },
          "default": 0.17,
          "title": "Variation Strength",
          "description": "Strength of variations"
        },
        {
          "name": "variation_seed",
          "type": {
            "type": "int"
          },
          "default": 12345,
          "title": "Variation Seed",
          "description": "Seed for variations"
        },
        {
          "name": "denoise",
          "type": {
            "type": "float"
          },
          "default": 1.0,
          "title": "Denoise",
          "description": "Denoising strength"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "comfy.latent"
          },
          "name": "latent"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "model",
        "latent_image",
        "main_seed",
        "steps",
        "cfg",
        "sampler_name",
        "scheduler",
        "positive",
        "negative",
        "variation_strength",
        "variation_seed",
        "denoise"
      ],
      "is_dynamic": false
    },
    {
      "title": "Plot Parameters",
      "description": "Plot sampler parameters alongside generated images.\n    visualization, parameters, plot\n\n    Use cases:\n    - Visualize relationships between parameters and outputs\n    - Compare results across different sampling configurations\n    - Create visual summaries of sampling experiments",
      "namespace": "comfy.essentials.sampling",
      "node_type": "comfy.essentials.sampling.PlotParameters",
      "layout": "default",
      "properties": [
        {
          "name": "images",
          "type": {
            "type": "image"
          },
          "default": {},
          "title": "Images",
          "description": "The generated images"
        },
        {
          "name": "params",
          "type": {
            "type": "dict"
          },
          "default": {},
          "title": "Params",
          "description": "The sampling parameters"
        },
        {
          "name": "order_by",
          "type": {
            "type": "str"
          },
          "default": "none",
          "title": "Order By",
          "description": "Parameter to order by"
        },
        {
          "name": "cols_value",
          "type": {
            "type": "str"
          },
          "default": "none",
          "title": "Cols Value",
          "description": "Parameter for column grouping"
        },
        {
          "name": "cols_num",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Cols Num",
          "description": "Number of columns (-1 for auto)"
        },
        {
          "name": "add_prompt",
          "type": {
            "type": "str"
          },
          "default": "false",
          "title": "Add Prompt",
          "description": "Whether to add prompt text"
        },
        {
          "name": "add_params",
          "type": {
            "type": "str"
          },
          "default": "true",
          "title": "Add Params",
          "description": "Whether to add parameter text"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "image"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "images",
        "params",
        "order_by",
        "cols_value",
        "cols_num",
        "add_prompt",
        "add_params"
      ],
      "is_dynamic": false
    },
    {
      "title": "Sampler Select Helper",
      "description": "Helper node for selecting samplers.\n    sampling, selection, helper\n\n    Use cases:\n    - Simplify sampler selection in workflows\n    - Create preset sampler configurations\n    - Batch process with multiple samplers",
      "namespace": "comfy.essentials.sampling",
      "node_type": "comfy.essentials.sampling.SamplerSelectHelper",
      "layout": "default",
      "properties": [
        {
          "name": "samplers",
          "type": {
            "type": "list",
            "type_args": [
              {
                "type": "bool"
              }
            ]
          },
          "default": [],
          "title": "Samplers",
          "description": "List of boolean flags for samplers"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "str"
          },
          "name": "string"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "samplers"
      ],
      "is_dynamic": false
    },
    {
      "title": "Scheduler Select Helper",
      "description": "Helper node for selecting schedulers.\n    scheduling, selection, helper\n\n    Use cases:\n    - Simplify scheduler selection in workflows\n    - Create preset scheduler configurations\n    - Batch process with multiple schedulers",
      "namespace": "comfy.essentials.sampling",
      "node_type": "comfy.essentials.sampling.SchedulerSelectHelper",
      "layout": "default",
      "properties": [
        {
          "name": "schedulers",
          "type": {
            "type": "list",
            "type_args": [
              {
                "type": "bool"
              }
            ]
          },
          "default": [],
          "title": "Schedulers",
          "description": "List of boolean flags for schedulers"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "str"
          },
          "name": "string"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "schedulers"
      ],
      "is_dynamic": false
    },
    {
      "title": "Text Encode For Sampler Params",
      "description": "Encode text for use with sampler parameters.\n    text, encoding, sampling\n\n    Use cases:\n    - Prepare text inputs for advanced sampling techniques\n    - Encode multiple prompts for batch processing\n    - Create structured text inputs for sampling workflows",
      "namespace": "comfy.essentials.sampling",
      "node_type": "comfy.essentials.sampling.TextEncodeForSamplerParams",
      "layout": "default",
      "properties": [
        {
          "name": "text",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Text",
          "description": "The input text to encode"
        },
        {
          "name": "clip",
          "type": {
            "type": "comfy.clip"
          },
          "default": {},
          "title": "Clip",
          "description": "The CLIP model to use for encoding"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "comfy.conditioning"
          },
          "name": "conditioning"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "text",
        "clip"
      ],
      "is_dynamic": false
    },
    {
      "title": "CLIPText Encode SDXLSimplified",
      "description": "Encode text for SDXL models with simplified parameters.\n    text, encoding, SDXL\n\n    Use cases:\n    - Generate SDXL-compatible text embeddings\n    - Prepare text inputs for SDXL image generation\n    - Customize text encoding for SDXL workflows",
      "namespace": "comfy.essentials.conditioning",
      "node_type": "comfy.essentials.conditioning.CLIPTextEncodeSDXLSimplified",
      "layout": "default",
      "properties": [
        {
          "name": "width",
          "type": {
            "type": "int"
          },
          "default": 1024,
          "title": "Width",
          "description": "Width of the target image.",
          "min": 0.0,
          "max": 8192.0
        },
        {
          "name": "height",
          "type": {
            "type": "int"
          },
          "default": 1024,
          "title": "Height",
          "description": "Height of the target image.",
          "min": 0.0,
          "max": 8192.0
        },
        {
          "name": "size_cond_factor",
          "type": {
            "type": "int"
          },
          "default": 4,
          "title": "Size Cond Factor",
          "description": "Size conditioning factor.",
          "min": 1.0,
          "max": 16.0
        },
        {
          "name": "text",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Text",
          "description": "Input text to encode."
        },
        {
          "name": "clip",
          "type": {
            "type": "comfy.clip"
          },
          "default": {},
          "title": "Clip",
          "description": "CLIP model to use for encoding."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "comfy.conditioning"
          },
          "name": "conditioning"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "width",
        "height",
        "size_cond_factor",
        "text",
        "clip"
      ],
      "is_dynamic": false
    },
    {
      "title": "Conditioning Combine Multiple",
      "description": "Combine multiple conditioning inputs.\n    conditioning, combine, merge\n\n    Use cases:\n    - Merge different text embeddings\n    - Combine various conditioning signals\n    - Create complex conditioning for advanced image generation",
      "namespace": "comfy.essentials.conditioning",
      "node_type": "comfy.essentials.conditioning.ConditioningCombineMultiple",
      "layout": "default",
      "properties": [
        {
          "name": "conditioning_1",
          "type": {
            "type": "comfy.conditioning"
          },
          "default": {},
          "title": "Conditioning 1",
          "description": "First conditioning input."
        },
        {
          "name": "conditioning_2",
          "type": {
            "type": "comfy.conditioning"
          },
          "default": {},
          "title": "Conditioning 2",
          "description": "Second conditioning input."
        },
        {
          "name": "conditioning_3",
          "type": {
            "type": "comfy.conditioning"
          },
          "title": "Conditioning 3",
          "description": "Optional third conditioning input."
        },
        {
          "name": "conditioning_4",
          "type": {
            "type": "comfy.conditioning"
          },
          "title": "Conditioning 4",
          "description": "Optional fourth conditioning input."
        },
        {
          "name": "conditioning_5",
          "type": {
            "type": "comfy.conditioning"
          },
          "title": "Conditioning 5",
          "description": "Optional fifth conditioning input."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "comfy.conditioning"
          },
          "name": "conditioning"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "conditioning_1",
        "conditioning_2",
        "conditioning_3",
        "conditioning_4",
        "conditioning_5"
      ],
      "is_dynamic": false
    },
    {
      "title": "SD 3 Negative Conditioning",
      "description": "Generate negative conditioning for Stable Diffusion 3 models.\n    conditioning, negative, SD3\n\n    Use cases:\n    - Create negative prompts for SD3\n    - Fine-tune image generation by specifying what not to include\n    - Implement advanced prompt engineering techniques for SD3",
      "namespace": "comfy.essentials.conditioning",
      "node_type": "comfy.essentials.conditioning.SD3NegativeConditioning",
      "layout": "default",
      "properties": [
        {
          "name": "conditioning",
          "type": {
            "type": "comfy.conditioning"
          },
          "default": {},
          "title": "Conditioning",
          "description": "Input conditioning to modify."
        },
        {
          "name": "end",
          "type": {
            "type": "float"
          },
          "default": 0.1,
          "title": "End",
          "description": "End point for negative conditioning.",
          "min": 0.0,
          "max": 1.0
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "comfy.conditioning"
          },
          "name": "conditioning"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "conditioning",
        "end"
      ],
      "is_dynamic": false
    },
    {
      "title": "Image Batch Multiple",
      "description": "Combine multiple images into a batch.\n    batch, combine, multiple\n\n    Use cases:\n    - Prepare image sets for batch processing\n    - Merge images from different sources\n    - Create image collections for analysis",
      "namespace": "comfy.essentials.image",
      "node_type": "comfy.essentials.image.ImageBatchMultiple",
      "layout": "default",
      "properties": [
        {
          "name": "image_1",
          "type": {
            "type": "image"
          },
          "default": {},
          "title": "Image 1",
          "description": "First image in the batch"
        },
        {
          "name": "method",
          "type": {
            "type": "str"
          },
          "default": "lanczos",
          "title": "Method",
          "description": "Interpolation method for resizing"
        },
        {
          "name": "image_2",
          "type": {
            "type": "image",
            "optional": true
          },
          "title": "Image 2",
          "description": "Second image (optional)"
        },
        {
          "name": "image_3",
          "type": {
            "type": "image",
            "optional": true
          },
          "title": "Image 3",
          "description": "Third image (optional)"
        },
        {
          "name": "image_4",
          "type": {
            "type": "image",
            "optional": true
          },
          "title": "Image 4",
          "description": "Fourth image (optional)"
        },
        {
          "name": "image_5",
          "type": {
            "type": "image",
            "optional": true
          },
          "title": "Image 5",
          "description": "Fifth image (optional)"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "image"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "image_1",
        "method",
        "image_2",
        "image_3",
        "image_4",
        "image_5"
      ],
      "is_dynamic": false
    },
    {
      "title": "Image Color Match",
      "description": "Match the color distribution of one image to another.\n    color, match, transfer\n\n    Use cases:\n    - Harmonize colors across multiple images\n    - Apply color grading effects\n    - Correct color inconsistencies in image sets",
      "namespace": "comfy.essentials.image",
      "node_type": "comfy.essentials.image.ImageColorMatch",
      "layout": "default",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {},
          "title": "Image",
          "description": "Input image"
        },
        {
          "name": "reference",
          "type": {
            "type": "image"
          },
          "default": {},
          "title": "Reference",
          "description": "Reference image for color matching"
        },
        {
          "name": "color_space",
          "type": {
            "type": "str"
          },
          "default": "LAB",
          "title": "Color Space",
          "description": "Color space for matching"
        },
        {
          "name": "factor",
          "type": {
            "type": "float"
          },
          "default": 1.0,
          "title": "Factor",
          "description": "Strength of color matching",
          "min": 0.0,
          "max": 1.0
        },
        {
          "name": "device",
          "type": {
            "type": "str"
          },
          "default": "auto",
          "title": "Device",
          "description": "Computation device"
        },
        {
          "name": "batch_size",
          "type": {
            "type": "int"
          },
          "default": 0,
          "title": "Batch Size",
          "description": "Batch size for processing",
          "min": 0.0
        },
        {
          "name": "reference_mask",
          "type": {
            "type": "comfy.mask",
            "optional": true
          },
          "title": "Reference Mask",
          "description": "Optional mask for reference image"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "image"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "image",
        "reference",
        "color_space",
        "factor",
        "device",
        "batch_size",
        "reference_mask"
      ],
      "is_dynamic": false
    },
    {
      "title": "Image Composite",
      "description": "Composite one image onto another at specified coordinates.\n    composite, overlay, position\n\n    Use cases:\n    - Add watermarks or logos to images\n    - Create collages or image layouts\n    - Overlay elements on background images",
      "namespace": "comfy.essentials.image",
      "node_type": "comfy.essentials.image.ImageComposite",
      "layout": "default",
      "properties": [
        {
          "name": "destination",
          "type": {
            "type": "image"
          },
          "default": {},
          "title": "Destination",
          "description": "Destination image"
        },
        {
          "name": "source",
          "type": {
            "type": "image"
          },
          "default": {},
          "title": "Source",
          "description": "Source image to composite"
        },
        {
          "name": "x",
          "type": {
            "type": "int"
          },
          "default": 0,
          "title": "X",
          "description": "X coordinate for placement"
        },
        {
          "name": "y",
          "type": {
            "type": "int"
          },
          "default": 0,
          "title": "Y",
          "description": "Y coordinate for placement"
        },
        {
          "name": "offset_x",
          "type": {
            "type": "int"
          },
          "default": 0,
          "title": "Offset X",
          "description": "X offset"
        },
        {
          "name": "offset_y",
          "type": {
            "type": "int"
          },
          "default": 0,
          "title": "Offset Y",
          "description": "Y offset"
        },
        {
          "name": "mask",
          "type": {
            "type": "comfy.mask",
            "optional": true
          },
          "title": "Mask",
          "description": "Optional mask for compositing"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "image"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "destination",
        "source",
        "x",
        "y",
        "offset_x",
        "offset_y",
        "mask"
      ],
      "is_dynamic": false
    },
    {
      "title": "Image Composite From Mask Batch",
      "description": "Create a composite image from two images and a mask in batch.\n    composite, mask, batch\n\n    Use cases:\n    - Blend multiple image pairs using masks\n    - Create layered effects for image sets\n    - Batch process image compositions",
      "namespace": "comfy.essentials.image",
      "node_type": "comfy.essentials.image.ImageCompositeFromMaskBatch",
      "layout": "default",
      "properties": [
        {
          "name": "image_from",
          "type": {
            "type": "image"
          },
          "default": {},
          "title": "Image From",
          "description": "Source image batch"
        },
        {
          "name": "image_to",
          "type": {
            "type": "image"
          },
          "default": {},
          "title": "Image To",
          "description": "Destination image batch"
        },
        {
          "name": "mask",
          "type": {
            "type": "comfy.mask"
          },
          "default": {},
          "title": "Mask",
          "description": "Mask for compositing"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "image"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "image_from",
        "image_to",
        "mask"
      ],
      "is_dynamic": false
    },
    {
      "title": "Image Crop",
      "description": "Crop an image to specified dimensions and position.\n    crop, trim, extract\n\n    Use cases:\n    - Focus on specific areas of images\n    - Remove unwanted parts of images\n    - Create uniform image sizes from varied inputs",
      "namespace": "comfy.essentials.image",
      "node_type": "comfy.essentials.image.ImageCrop",
      "layout": "default",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {},
          "title": "Image",
          "description": "Input image"
        },
        {
          "name": "width",
          "type": {
            "type": "int"
          },
          "default": 256,
          "title": "Width",
          "description": "Crop width",
          "min": 0.0
        },
        {
          "name": "height",
          "type": {
            "type": "int"
          },
          "default": 256,
          "title": "Height",
          "description": "Crop height",
          "min": 0.0
        },
        {
          "name": "position",
          "type": {
            "type": "str"
          },
          "default": "center",
          "title": "Position",
          "description": "Crop position"
        },
        {
          "name": "x_offset",
          "type": {
            "type": "int"
          },
          "default": 0,
          "title": "X Offset",
          "description": "X offset for cropping"
        },
        {
          "name": "y_offset",
          "type": {
            "type": "int"
          },
          "default": 0,
          "title": "Y Offset",
          "description": "Y offset for cropping"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "image"
        },
        {
          "type": {
            "type": "int"
          },
          "name": "x"
        },
        {
          "type": {
            "type": "int"
          },
          "name": "y"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "image",
        "width",
        "height",
        "position",
        "x_offset",
        "y_offset"
      ],
      "is_dynamic": false
    },
    {
      "title": "Image Enhance Difference",
      "description": "Enhance the difference between two images.\n    image, difference, comparison\n\n    Use cases:\n    - Highlight changes between image versions\n    - Analyze image modifications\n    - Create visual effects based on image differences",
      "namespace": "comfy.essentials.image",
      "node_type": "comfy.essentials.image.ImageEnhanceDifference",
      "layout": "default",
      "properties": [
        {
          "name": "image1",
          "type": {
            "type": "image"
          },
          "default": {},
          "title": "Image1",
          "description": "The first image"
        },
        {
          "name": "image2",
          "type": {
            "type": "image"
          },
          "default": {},
          "title": "Image2",
          "description": "The second image"
        },
        {
          "name": "exponent",
          "type": {
            "type": "float"
          },
          "default": 0.75,
          "title": "Exponent",
          "description": "Exponent for difference calculation",
          "min": 0.0,
          "max": 1.0
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "image"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "image1",
        "image2",
        "exponent"
      ],
      "is_dynamic": false
    },
    {
      "title": "Image Expand Batch",
      "description": "Expand an image batch to a specified size.\n    batch, expand, resize\n\n    Use cases:\n    - Increase batch size for processing\n    - Duplicate images to meet batch requirements\n    - Adjust batch size for model input",
      "namespace": "comfy.essentials.image",
      "node_type": "comfy.essentials.image.ImageExpandBatch",
      "layout": "default",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {},
          "title": "Image",
          "description": "Input image batch"
        },
        {
          "name": "size",
          "type": {
            "type": "int"
          },
          "default": 16,
          "title": "Size",
          "description": "Target batch size",
          "min": 1.0
        },
        {
          "name": "method",
          "type": {
            "type": "str"
          },
          "default": "expand",
          "title": "Method",
          "description": "Method for expanding the batch"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "image"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "image",
        "size",
        "method"
      ],
      "is_dynamic": false
    },
    {
      "title": "Image Flip",
      "description": "Flip an image horizontally or vertically.\n    flip, mirror, rotate\n\n    Use cases:\n    - Create mirror images\n    - Augment data for machine learning\n    - Correct image orientations",
      "namespace": "comfy.essentials.image",
      "node_type": "comfy.essentials.image.ImageFlip",
      "layout": "default",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {},
          "title": "Image",
          "description": "Input image"
        },
        {
          "name": "axis",
          "type": {
            "type": "str"
          },
          "default": "x",
          "title": "Axis",
          "description": "Axis to flip (x, y, or xy)"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "image"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "image",
        "axis"
      ],
      "is_dynamic": false
    },
    {
      "title": "Image From Batch",
      "description": "Extract a subset of images from a batch.\n    batch, extract, subset\n\n    Use cases:\n    - Select specific images from a larger batch\n    - Divide a batch into smaller sets\n    - Isolate images for individual processing",
      "namespace": "comfy.essentials.image",
      "node_type": "comfy.essentials.image.ImageFromBatch",
      "layout": "default",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {},
          "title": "Image",
          "description": "Input image batch"
        },
        {
          "name": "start",
          "type": {
            "type": "int"
          },
          "default": 0,
          "title": "Start",
          "description": "Starting index",
          "min": 0.0
        },
        {
          "name": "length",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Length",
          "description": "Number of images to extract",
          "min": -1.0
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "image"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "image",
        "start",
        "length"
      ],
      "is_dynamic": false
    },
    {
      "title": "Image List To Batch",
      "description": "Convert a list of images to an image batch.\n    list, batch, convert\n\n    Use cases:\n    - Prepare individual images for batch processing\n    - Combine images from different sources into a batch\n    - Standardize image formats for model input",
      "namespace": "comfy.essentials.image",
      "node_type": "comfy.essentials.image.ImageListToBatch",
      "layout": "default",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "list",
            "type_args": [
              {
                "type": "image"
              }
            ]
          },
          "default": [],
          "title": "Image",
          "description": "List of input images"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "image"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "image"
      ],
      "is_dynamic": false
    },
    {
      "title": "Image Preview From Latent",
      "description": "Generate a preview image from a latent representation.\n    preview, latent, decode\n\n    Use cases:\n    - Visualize latent space representations\n    - Debug generative model outputs\n    - Create quick previews of latent manipulations",
      "namespace": "comfy.essentials.image",
      "node_type": "comfy.essentials.image.ImagePreviewFromLatent",
      "layout": "default",
      "properties": [
        {
          "name": "latent",
          "type": {
            "type": "comfy.latent"
          },
          "default": {},
          "title": "Latent",
          "description": "Input latent representation"
        },
        {
          "name": "vae",
          "type": {
            "type": "comfy.vae"
          },
          "default": {},
          "title": "Vae",
          "description": "VAE model for decoding"
        },
        {
          "name": "tile_size",
          "type": {
            "type": "int"
          },
          "default": 0,
          "title": "Tile Size",
          "description": "Tile size for decoding",
          "min": 0.0,
          "max": 4096.0
        },
        {
          "name": "image",
          "type": {
            "type": "str",
            "optional": true
          },
          "default": "none",
          "title": "Image",
          "description": "Optional input image"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "image"
        },
        {
          "type": {
            "type": "comfy.mask"
          },
          "name": "mask"
        },
        {
          "type": {
            "type": "int"
          },
          "name": "width"
        },
        {
          "type": {
            "type": "int"
          },
          "name": "height"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "latent",
        "vae",
        "tile_size",
        "image"
      ],
      "is_dynamic": false
    },
    {
      "title": "Image Resize",
      "description": "Resize an image to specified dimensions.\n    resize, scale, dimensions\n\n    Use cases:\n    - Standardize image sizes for processing\n    - Create thumbnails or previews\n    - Adjust images for specific display requirements",
      "namespace": "comfy.essentials.image",
      "node_type": "comfy.essentials.image.ImageResize",
      "layout": "default",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {},
          "title": "Image",
          "description": "Input image"
        },
        {
          "name": "width",
          "type": {
            "type": "int"
          },
          "default": 512,
          "title": "Width",
          "description": "Target width",
          "min": 0.0
        },
        {
          "name": "height",
          "type": {
            "type": "int"
          },
          "default": 512,
          "title": "Height",
          "description": "Target height",
          "min": 0.0
        },
        {
          "name": "interpolation",
          "type": {
            "type": "str"
          },
          "default": "nearest",
          "title": "Interpolation",
          "description": "Interpolation method"
        },
        {
          "name": "method",
          "type": {
            "type": "str"
          },
          "default": "stretch",
          "title": "Method",
          "description": "Resizing method"
        },
        {
          "name": "condition",
          "type": {
            "type": "str"
          },
          "default": "always",
          "title": "Condition",
          "description": "Condition for resizing"
        },
        {
          "name": "multiple_of",
          "type": {
            "type": "int"
          },
          "default": 0,
          "title": "Multiple Of",
          "description": "Ensure dimensions are multiple of this value",
          "min": 0.0
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "image"
        },
        {
          "type": {
            "type": "int"
          },
          "name": "width"
        },
        {
          "type": {
            "type": "int"
          },
          "name": "height"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "image",
        "width",
        "height",
        "interpolation",
        "method",
        "condition",
        "multiple_of"
      ],
      "is_dynamic": false
    },
    {
      "title": "Image Smart Sharpen",
      "description": "Apply intelligent sharpening to an image.\n    sharpen, enhance, detail\n\n    Use cases:\n    - Improve image clarity and detail\n    - Enhance edges while preserving smooth areas\n    - Prepare images for high-quality display or printing",
      "namespace": "comfy.essentials.image",
      "node_type": "comfy.essentials.image.ImageSmartSharpen",
      "layout": "default",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {},
          "title": "Image",
          "description": "Input image"
        },
        {
          "name": "noise_radius",
          "type": {
            "type": "int"
          },
          "default": 7,
          "title": "Noise Radius",
          "description": "Radius for noise reduction",
          "min": 1.0,
          "max": 25.0
        },
        {
          "name": "preserve_edges",
          "type": {
            "type": "float"
          },
          "default": 0.75,
          "title": "Preserve Edges",
          "description": "Edge preservation strength",
          "min": 0.0,
          "max": 1.0
        },
        {
          "name": "sharpen",
          "type": {
            "type": "float"
          },
          "default": 5.0,
          "title": "Sharpen",
          "description": "Sharpening intensity",
          "min": 0.0,
          "max": 25.0
        },
        {
          "name": "ratio",
          "type": {
            "type": "float"
          },
          "default": 0.5,
          "title": "Ratio",
          "description": "Blend ratio of sharpened and original image",
          "min": 0.0,
          "max": 1.0
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "image"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "image",
        "noise_radius",
        "preserve_edges",
        "sharpen",
        "ratio"
      ],
      "is_dynamic": false
    },
    {
      "title": "Image Tile",
      "description": "Divide an image into tiles.\n    tile, grid, partition\n\n    Use cases:\n    - Prepare images for tiled processing\n    - Create image mosaics\n    - Analyze image sections separately",
      "namespace": "comfy.essentials.image",
      "node_type": "comfy.essentials.image.ImageTile",
      "layout": "default",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {},
          "title": "Image",
          "description": "Input image"
        },
        {
          "name": "rows",
          "type": {
            "type": "int"
          },
          "default": 2,
          "title": "Rows",
          "description": "Number of rows",
          "min": 1.0,
          "max": 256.0
        },
        {
          "name": "cols",
          "type": {
            "type": "int"
          },
          "default": 2,
          "title": "Cols",
          "description": "Number of columns",
          "min": 1.0,
          "max": 256.0
        },
        {
          "name": "overlap",
          "type": {
            "type": "float"
          },
          "default": 0,
          "title": "Overlap",
          "description": "Overlap between tiles",
          "min": 0.0,
          "max": 0.5
        },
        {
          "name": "overlap_x",
          "type": {
            "type": "int"
          },
          "default": 0,
          "title": "Overlap X",
          "description": "X overlap in pixels",
          "min": 0.0
        },
        {
          "name": "overlap_y",
          "type": {
            "type": "int"
          },
          "default": 0,
          "title": "Overlap Y",
          "description": "Y overlap in pixels",
          "min": 0.0
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "image"
        },
        {
          "type": {
            "type": "int"
          },
          "name": "tile_width"
        },
        {
          "type": {
            "type": "int"
          },
          "name": "tile_height"
        },
        {
          "type": {
            "type": "int"
          },
          "name": "overlap_x"
        },
        {
          "type": {
            "type": "int"
          },
          "name": "overlap_y"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "image",
        "rows",
        "cols",
        "overlap",
        "overlap_x",
        "overlap_y"
      ],
      "is_dynamic": false
    },
    {
      "title": "Image Untile",
      "description": "Reconstruct an image from tiles.\n    untile, merge, reconstruct\n\n    Use cases:\n    - Combine processed image tiles\n    - Reconstruct images after tiled analysis\n    - Create panoramas from image sections",
      "namespace": "comfy.essentials.image",
      "node_type": "comfy.essentials.image.ImageUntile",
      "layout": "default",
      "properties": [
        {
          "name": "tiles",
          "type": {
            "type": "image"
          },
          "default": {},
          "title": "Tiles",
          "description": "Tiled image input"
        },
        {
          "name": "overlap_x",
          "type": {
            "type": "int"
          },
          "default": 0,
          "title": "Overlap X",
          "description": "X overlap between tiles",
          "min": 0.0
        },
        {
          "name": "overlap_y",
          "type": {
            "type": "int"
          },
          "default": 0,
          "title": "Overlap Y",
          "description": "Y overlap between tiles",
          "min": 0.0
        },
        {
          "name": "rows",
          "type": {
            "type": "int"
          },
          "default": 2,
          "title": "Rows",
          "description": "Number of rows",
          "min": 1.0,
          "max": 256.0
        },
        {
          "name": "cols",
          "type": {
            "type": "int"
          },
          "default": 2,
          "title": "Cols",
          "description": "Number of columns",
          "min": 1.0,
          "max": 256.0
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "image"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "tiles",
        "overlap_x",
        "overlap_y",
        "rows",
        "cols"
      ],
      "is_dynamic": false
    },
    {
      "title": "Noise From Image",
      "description": "Generate noise based on an input image.\n    noise, generate, image-based\n\n    Use cases:\n    - Create custom noise for image processing\n    - Generate texture-like noise patterns\n    - Produce image-specific distortion effects",
      "namespace": "comfy.essentials.image",
      "node_type": "comfy.essentials.image.NoiseFromImage",
      "layout": "default",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {},
          "title": "Image",
          "description": "Input image"
        },
        {
          "name": "noise_strength",
          "type": {
            "type": "float"
          },
          "default": 1.0,
          "title": "Noise Strength",
          "description": "Strength of noise",
          "min": 0.0,
          "max": 1.0
        },
        {
          "name": "noise_size",
          "type": {
            "type": "float"
          },
          "default": 1.0,
          "title": "Noise Size",
          "description": "Size of noise features",
          "min": 0.0,
          "max": 1.0
        },
        {
          "name": "color_noise",
          "type": {
            "type": "float"
          },
          "default": 0.2,
          "title": "Color Noise",
          "description": "Amount of color noise",
          "min": 0.0,
          "max": 1.0
        },
        {
          "name": "mask_strength",
          "type": {
            "type": "float"
          },
          "default": 0.5,
          "title": "Mask Strength",
          "description": "Strength of mask application",
          "min": 0.0,
          "max": 1.0
        },
        {
          "name": "mask_scale_diff",
          "type": {
            "type": "float"
          },
          "default": 0.0,
          "title": "Mask Scale Diff",
          "description": "Scale difference for mask",
          "min": 0.0,
          "max": 1.0
        },
        {
          "name": "mask_contrast",
          "type": {
            "type": "float"
          },
          "default": 1.0,
          "title": "Mask Contrast",
          "description": "Contrast of mask",
          "min": 0.0,
          "max": 100.0
        },
        {
          "name": "saturation",
          "type": {
            "type": "float"
          },
          "default": 2.0,
          "title": "Saturation",
          "description": "Saturation of noise",
          "min": 0.0,
          "max": 100.0
        },
        {
          "name": "contrast",
          "type": {
            "type": "float"
          },
          "default": 1.0,
          "title": "Contrast",
          "description": "Contrast of noise",
          "min": 0.0,
          "max": 100.0
        },
        {
          "name": "blur",
          "type": {
            "type": "float"
          },
          "default": 1.0,
          "title": "Blur",
          "description": "Blur amount for noise",
          "min": 0.0,
          "max": 10.0
        },
        {
          "name": "noise_mask",
          "type": {
            "type": "image",
            "optional": true
          },
          "title": "Noise Mask",
          "description": "Optional mask for noise application"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "image"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "image",
        "noise_strength",
        "noise_size",
        "color_noise",
        "mask_strength",
        "mask_scale_diff",
        "mask_contrast",
        "saturation",
        "contrast",
        "blur",
        "noise_mask"
      ],
      "is_dynamic": false
    },
    {
      "title": "Apply CLIPSeg",
      "description": "Apply CLIP segmentation to an image.\n    segmentation, CLIP, image analysis\n\n    Use cases:\n    - Perform semantic segmentation on images\n    - Extract specific objects or regions from images\n    - Create masks based on text prompts",
      "namespace": "comfy.essentials.segmentation",
      "node_type": "comfy.essentials.segmentation.ApplyCLIPSeg",
      "layout": "default",
      "properties": [
        {
          "name": "clip_seg",
          "type": {
            "type": "tuple",
            "type_args": [
              {
                "type": "any"
              },
              {
                "type": "any"
              }
            ]
          },
          "default": [
            null,
            null
          ],
          "title": "Clip Seg",
          "description": "The CLIP segmentation models"
        },
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {},
          "title": "Image",
          "description": "The input image to segment"
        },
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "Text prompt for segmentation"
        },
        {
          "name": "threshold",
          "type": {
            "type": "float"
          },
          "default": 0.4,
          "title": "Threshold",
          "description": "Segmentation threshold"
        },
        {
          "name": "smooth",
          "type": {
            "type": "int"
          },
          "default": 9,
          "title": "Smooth",
          "description": "Smoothing factor"
        },
        {
          "name": "dilate",
          "type": {
            "type": "int"
          },
          "default": 0,
          "title": "Dilate",
          "description": "Dilation factor"
        },
        {
          "name": "blur",
          "type": {
            "type": "int"
          },
          "default": 0,
          "title": "Blur",
          "description": "Blur factor"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "comfy.mask"
          },
          "name": "mask"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [
        "clip_seg",
        "image",
        "prompt",
        "threshold",
        "smooth",
        "dilate",
        "blur"
      ],
      "is_dynamic": false
    },
    {
      "title": "Load CLIPSeg Models",
      "description": "Load CLIP segmentation models.\n    segmentation, CLIP, model loading\n\n    Use cases:\n    - Prepare CLIP segmentation models for image analysis\n    - Load pre-trained models for semantic segmentation\n    - Initialize segmentation pipeline",
      "namespace": "comfy.essentials.segmentation",
      "node_type": "comfy.essentials.segmentation.LoadCLIPSegModels",
      "layout": "default",
      "properties": [],
      "outputs": [
        {
          "type": {
            "type": "tuple",
            "type_args": [
              {
                "type": "any"
              },
              {
                "type": "any"
              }
            ]
          },
          "name": "clip_seg"
        }
      ],
      "the_model_info": {},
      "recommended_models": [],
      "basic_fields": [],
      "is_dynamic": false
    }
  ]
}